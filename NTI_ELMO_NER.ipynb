{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NTI-ELMO-NER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mw2nLrRWbX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#шаг1: скачать репозиторий FactFuEval-2016 (https://github.com/dialogue-evaluation/factRuEval-2016)\n",
        "#шаг2: внутри репозитория создаем директории FactRuEval2016_results и FactRuEval2016_results/results_of_elmo_and_crf (для результатов)\n",
        "#шаг3: устанавливаем библиотеку deep_ner (pip install deep_ner) \n",
        "#в данном примере весь код из deep_ner вынесен в ноутбук для понимания зависимостей и возможного рефакторинга кода\n",
        "#шаг4: для обучения на наших текстах будем использовать предобученные ELMo эмбеддинги команды deeppavlov (http://docs.deeppavlov.ai/en/master/features/pretrained_vectors.html)\n",
        "\n",
        "#работа выполена в google.colab\n",
        "\n",
        "#!unzip factRuEval-2016-master.zip\n",
        "#!pip install deep_ner\n",
        "\n",
        "#требования по библиотекам:\n",
        "#nltk==3.4.5\n",
        "#numpy==1.18.1\n",
        "#scikit-learn==0.22.1\n",
        "#scipy==1.4.1\n",
        "#tensorboard==2.1.0\n",
        "#tensorflow==1.15.0\n",
        "#tensorflow-hub==0.8.0\n",
        "#bert-tensorflow==1.0.1\n",
        "#spacy-udpipe==0.2.0\n",
        "#spacy==2.2.3\n",
        "#pymorphy2==0.8\n",
        "#rusenttokenize==0.0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg-3Zvevfx0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from typing import Union, Tuple, List, Dict, Set\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as tfhub\n",
        "from logging import Logger\n",
        "import spacy_udpipe\n",
        "from spacy_udpipe import UDPipeLanguage\n",
        "from tensorflow.python.framework import ops\n",
        "\n",
        "\n",
        "import os\n",
        "import codecs\n",
        "import json\n",
        "import random\n",
        "import logging\n",
        "import re\n",
        "import tempfile\n",
        "import copy\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5YSujauW9Lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ELMo_NER(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, elmo_hub_module_handle: str, udpipe_lang: str, use_additional_features: bool = False,\n",
        "                 finetune_elmo: bool=False, batch_size: int = 32, max_seq_length: int = 32, lr: float = 1e-4,\n",
        "                 l2_reg: float = 1e-5, validation_fraction: float = 0.1, max_epochs: int = 10, patience: int = 3,\n",
        "                 gpu_memory_frac: float = 1.0, verbose: bool = False, random_seed: Union[int, None] = None):\n",
        "        self.udpipe_lang = udpipe_lang\n",
        "        self.use_additional_features = use_additional_features\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "        self.l2_reg = l2_reg\n",
        "        self.elmo_hub_module_handle = elmo_hub_module_handle\n",
        "        self.finetune_elmo = finetune_elmo\n",
        "        self.max_epochs = max_epochs\n",
        "        self.patience = patience\n",
        "        self.random_seed = random_seed\n",
        "        self.gpu_memory_frac = gpu_memory_frac\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.validation_fraction = validation_fraction\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def __del__(self):\n",
        "        if hasattr(self, 'classes_list_'):\n",
        "            del self.classes_list_\n",
        "        if hasattr(self, 'shapes_list_'):\n",
        "            del self.shapes_list_\n",
        "        if hasattr(self, 'nlp_'):\n",
        "            del self.nlp_\n",
        "        if hasattr(self, 'universal_pos_tags_dict_'):\n",
        "            del self.universal_pos_tags_dict_\n",
        "        if hasattr(self, 'universal_dependencies_dict_'):\n",
        "            del self.universal_dependencies_dict_\n",
        "        self.finalize_model()\n",
        "\n",
        "    def fit(self, X: Union[list, tuple, np.array], y: Union[list, tuple, np.array],\n",
        "            validation_data: Union[None, Tuple[Union[list, tuple, np.array], Union[list, tuple, np.array]]]=None):\n",
        "        self.check_params(\n",
        "            elmo_hub_module_handle=self.elmo_hub_module_handle, finetune_elmo=self.finetune_elmo,\n",
        "            batch_size=self.batch_size, max_seq_length=self.max_seq_length, lr=self.lr, l2_reg=self.l2_reg,\n",
        "            validation_fraction=self.validation_fraction, max_epochs=self.max_epochs, patience=self.patience,\n",
        "            gpu_memory_frac=self.gpu_memory_frac, verbose=self.verbose, random_seed=self.random_seed,\n",
        "            udpipe_lang=self.udpipe_lang, use_additional_features=self.use_additional_features\n",
        "        )\n",
        "        self.classes_list_ = self.check_Xy(X, 'X', y, 'y')\n",
        "        if hasattr(self, 'shapes_list_'):\n",
        "            del self.shapes_list_\n",
        "        self.finalize_model()\n",
        "        self.update_random_seed()\n",
        "        if validation_data is None:\n",
        "            if self.validation_fraction > 0.0:\n",
        "                train_index, test_index = split_dataset(y, self.validation_fraction, logger=elmo_ner_logger)\n",
        "                X_train_ = [X[idx] for idx in train_index]\n",
        "                y_train_ = [y[idx] for idx in train_index]\n",
        "                X_val_ = [X[idx] for idx in test_index]\n",
        "                y_val_ = [y[idx] for idx in test_index]\n",
        "                del train_index, test_index\n",
        "            else:\n",
        "                X_train_ = X\n",
        "                y_train_ = y\n",
        "                X_val_ = None\n",
        "                y_val_ = None\n",
        "        else:\n",
        "            if (not isinstance(validation_data, tuple)) and (not isinstance(validation_data, list)):\n",
        "                raise ValueError('')\n",
        "            if len(validation_data) != 2:\n",
        "                raise ValueError('')\n",
        "            classes_list_for_validation = self.check_Xy(validation_data[0], 'X_val', validation_data[1], 'y_val')\n",
        "            if not (set(classes_list_for_validation) <= set(self.classes_list_)):\n",
        "                raise ValueError('')\n",
        "            X_train_ = X\n",
        "            y_train_ = y\n",
        "            X_val_ = validation_data[0]\n",
        "            y_val_ = validation_data[1]\n",
        "        X_train_tokenized, y_train_tokenized, self.shapes_list_ = self.tokenize_all(X_train_, y_train_)\n",
        "        X_train_tokenized, y_train_tokenized = self.extend_Xy(X_train_tokenized, y_train_tokenized, shuffle=True)\n",
        "        if (X_val_ is not None) and (y_val_ is not None):\n",
        "            X_val_tokenized, y_val_tokenized, _ = self.tokenize_all(X_val_, y_val_, shapes_vocabulary=self.shapes_list_)\n",
        "            X_val_tokenized, y_val_tokenized = self.extend_Xy(X_val_tokenized, y_val_tokenized, shuffle=False)\n",
        "        else:\n",
        "            X_val_tokenized = None\n",
        "            y_val_tokenized = None\n",
        "        if self.verbose:\n",
        "            elmo_ner_logger.info('Number of shapes is {0}.'.format(len(self.shapes_list_)))\n",
        "        train_op, log_likelihood, logits_, transition_params_ = self.build_model()\n",
        "        n_batches = int(np.ceil(X_train_tokenized[0].shape[0] / float(self.batch_size)))\n",
        "        bounds_of_batches_for_training = []\n",
        "        for iteration in range(n_batches):\n",
        "            batch_start = iteration * self.batch_size\n",
        "            batch_end = min(batch_start + self.batch_size, X_train_tokenized[0].shape[0])\n",
        "            bounds_of_batches_for_training.append((batch_start,  batch_end))\n",
        "        if X_val_tokenized is None:\n",
        "            bounds_of_batches_for_validation = None\n",
        "        else:\n",
        "            n_batches = int(np.ceil(X_val_tokenized[0].shape[0] / float(self.batch_size)))\n",
        "            bounds_of_batches_for_validation = []\n",
        "            for iteration in range(n_batches):\n",
        "                batch_start = iteration * self.batch_size\n",
        "                batch_end = min(batch_start + self.batch_size, X_val_tokenized[0].shape[0])\n",
        "                bounds_of_batches_for_validation.append((batch_start, batch_end))\n",
        "        init = tf.global_variables_initializer()\n",
        "        init.run(session=self.sess_)\n",
        "        tmp_model_name = self.get_temp_model_name()\n",
        "        if self.verbose:\n",
        "            if X_val_tokenized is None:\n",
        "                elmo_ner_logger.info('Epoch   Log-likelihood')\n",
        "        n_epochs_without_improving = 0\n",
        "        try:\n",
        "            best_acc = None\n",
        "            for epoch in range(self.max_epochs):\n",
        "                random.shuffle(bounds_of_batches_for_training)\n",
        "                feed_dict_for_batch = None\n",
        "                for cur_batch in bounds_of_batches_for_training:\n",
        "                    X_batch = [X_train_tokenized[channel_idx][cur_batch[0]:cur_batch[1]]\n",
        "                               for channel_idx in range(len(X_train_tokenized))]\n",
        "                    y_batch = y_train_tokenized[cur_batch[0]:cur_batch[1]]\n",
        "                    feed_dict_for_batch = self.fill_feed_dict(X_batch, y_batch)\n",
        "                    self.sess_.run(train_op, feed_dict=feed_dict_for_batch)\n",
        "                acc_train = log_likelihood.eval(feed_dict=feed_dict_for_batch, session=self.sess_)\n",
        "                if bounds_of_batches_for_validation is not None:\n",
        "                    acc_test = 0.0\n",
        "                    y_pred = []\n",
        "                    for cur_batch in bounds_of_batches_for_validation:\n",
        "                        X_batch = [X_val_tokenized[channel_idx][cur_batch[0]:cur_batch[1]]\n",
        "                                   for channel_idx in range(len(X_val_tokenized))]\n",
        "                        y_batch = y_val_tokenized[cur_batch[0]:cur_batch[1]]\n",
        "                        feed_dict_for_batch = self.fill_feed_dict(X_batch, y_batch)\n",
        "                        acc_test_, logits, trans_params = self.sess_.run(\n",
        "                            [log_likelihood, logits_, transition_params_],\n",
        "                            feed_dict=feed_dict_for_batch\n",
        "                        )\n",
        "                        acc_test += acc_test_ * self.batch_size\n",
        "                        sequence_lengths = X_val_tokenized[1][cur_batch[0]:cur_batch[1]]\n",
        "                        for logit, sequence_length in zip(logits, sequence_lengths):\n",
        "                            logit = logit[:int(sequence_length)]\n",
        "                            viterbi_seq, viterbi_score = tf.contrib.crf.viterbi_decode(logit, trans_params)\n",
        "                            y_pred += [viterbi_seq]\n",
        "                    acc_test /= float(X_val_tokenized[0].shape[0])\n",
        "                    if self.verbose:\n",
        "                        elmo_ner_logger.info('Epoch {0}'.format(epoch))\n",
        "                        elmo_ner_logger.info('  Train log-likelihood.: {0: 10.8f}'.format(acc_train))\n",
        "                        elmo_ner_logger.info('  Val. log-likelihood:  {0: 10.8f}'.format(acc_test))\n",
        "                    pred_entities_val = []\n",
        "                    for sample_idx, labels_in_text in enumerate(y_pred[0:len(X_val_)]):\n",
        "                        n_tokens = len(labels_in_text)\n",
        "                        tokens = X_val_tokenized[0][sample_idx][:n_tokens]\n",
        "                        bounds_of_tokens = self.calculate_bounds_of_tokens(X_val_[sample_idx], tokens)\n",
        "                        new_entities = self.calculate_bounds_of_named_entities(bounds_of_tokens, self.classes_list_,\n",
        "                                                                               labels_in_text)\n",
        "                        pred_entities_val.append(new_entities)\n",
        "                    f1_test, precision_test, recall_test, quality_by_entities = calculate_prediction_quality(\n",
        "                        y_val_, pred_entities_val, self.classes_list_)\n",
        "                    if best_acc is None:\n",
        "                        best_acc = f1_test\n",
        "                        self.save_model(tmp_model_name)\n",
        "                        n_epochs_without_improving = 0\n",
        "                    elif f1_test > best_acc:\n",
        "                        best_acc = f1_test\n",
        "                        self.save_model(tmp_model_name)\n",
        "                        n_epochs_without_improving = 0\n",
        "                    else:\n",
        "                        n_epochs_without_improving += 1\n",
        "                    if self.verbose:\n",
        "                        elmo_ner_logger.info('  Val. quality for all entities:')\n",
        "                        elmo_ner_logger.info('      F1={0:>6.4f}, P={1:>6.4f}, R={2:>6.4f}'.format(\n",
        "                            f1_test, precision_test, recall_test))\n",
        "                        max_text_width = 0\n",
        "                        for ne_type in sorted(list(quality_by_entities.keys())):\n",
        "                            text_width = len(ne_type)\n",
        "                            if text_width > max_text_width:\n",
        "                                max_text_width = text_width\n",
        "                        for ne_type in sorted(list(quality_by_entities.keys())):\n",
        "                            elmo_ner_logger.info('    Val. quality for {0:>{1}}:'.format(ne_type, max_text_width))\n",
        "                            elmo_ner_logger.info('      F1={0:>6.4f}, P={1:>6.4f}, R={2:>6.4f})'.format(\n",
        "                                quality_by_entities[ne_type][0], quality_by_entities[ne_type][1],\n",
        "                                quality_by_entities[ne_type][2]))\n",
        "                    del y_pred, pred_entities_val\n",
        "                else:\n",
        "                    if best_acc is None:\n",
        "                        best_acc = acc_train\n",
        "                        self.save_model(tmp_model_name)\n",
        "                        n_epochs_without_improving = 0\n",
        "                    elif acc_train > best_acc:\n",
        "                        best_acc = acc_train\n",
        "                        self.save_model(tmp_model_name)\n",
        "                        n_epochs_without_improving = 0\n",
        "                    else:\n",
        "                        n_epochs_without_improving += 1\n",
        "                    if self.verbose:\n",
        "                        elmo_ner_logger.info('{0:>5}   {1:>14.8f}'.format(epoch, acc_train))\n",
        "                if n_epochs_without_improving >= self.patience:\n",
        "                    if self.verbose:\n",
        "                        elmo_ner_logger.info('Epoch %05d: early stopping' % (epoch + 1))\n",
        "                    break\n",
        "            if best_acc is not None:\n",
        "                self.finalize_model()\n",
        "                self.load_model(tmp_model_name)\n",
        "                if self.verbose:\n",
        "                    if bounds_of_batches_for_validation is not None:\n",
        "                        acc_test = 0.0\n",
        "                        y_pred = []\n",
        "                        for cur_batch in bounds_of_batches_for_validation:\n",
        "                            X_batch = [X_val_tokenized[channel_idx][cur_batch[0]:cur_batch[1]] for channel_idx in\n",
        "                                       range(len(X_val_tokenized))]\n",
        "                            y_batch = y_val_tokenized[cur_batch[0]:cur_batch[1]]\n",
        "                            feed_dict_for_batch = self.fill_feed_dict(X_batch, y_batch)\n",
        "                            acc_test_, logits, trans_params = self.sess_.run(\n",
        "                                ['eval/Mean:0', 'outputs_of_NER/BiasAdd:0', 'transitions:0'],\n",
        "                                feed_dict=feed_dict_for_batch\n",
        "                            )\n",
        "                            acc_test += acc_test_ * self.batch_size\n",
        "                            sequence_lengths = X_val_tokenized[1][cur_batch[0]:cur_batch[1]]\n",
        "                            for logit, sequence_length in zip(logits, sequence_lengths):\n",
        "                                logit = logit[:int(sequence_length)]\n",
        "                                viterbi_seq, viterbi_score = tf.contrib.crf.viterbi_decode(logit, trans_params)\n",
        "                                y_pred += [viterbi_seq]\n",
        "                        acc_test /= float(X_val_tokenized[0].shape[0])\n",
        "                        pred_entities_val = []\n",
        "                        for sample_idx, labels_in_text in enumerate(y_pred[0:len(X_val_)]):\n",
        "                            n_tokens = len(labels_in_text)\n",
        "                            tokens = X_val_tokenized[0][sample_idx][:n_tokens]\n",
        "                            bounds_of_tokens = self.calculate_bounds_of_tokens(X_val_[sample_idx], tokens)\n",
        "                            new_entities = self.calculate_bounds_of_named_entities(bounds_of_tokens, self.classes_list_,\n",
        "                                                                                   labels_in_text)\n",
        "                            pred_entities_val.append(new_entities)\n",
        "                        f1_test, _, _, _ = calculate_prediction_quality(y_val_, pred_entities_val, self.classes_list_)\n",
        "                        elmo_ner_logger.info('Best val. F1 is {0:>8.6f}'.format(f1_test))\n",
        "                        elmo_ner_logger.info('Best val. log-likelihood is {0:>10.8f}'.format(acc_test))\n",
        "        finally:\n",
        "            for cur_name in self.find_all_model_files(tmp_model_name):\n",
        "                os.remove(cur_name)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X: Union[list, tuple, np.array]) -> List[Dict[str, List[Tuple[int, int]]]]:\n",
        "        self.check_params(\n",
        "            elmo_hub_module_handle=self.elmo_hub_module_handle, finetune_elmo=self.finetune_elmo,\n",
        "            batch_size=self.batch_size, max_seq_length=self.max_seq_length, lr=self.lr, l2_reg=self.l2_reg,\n",
        "            validation_fraction=self.validation_fraction, max_epochs=self.max_epochs, patience=self.patience,\n",
        "            gpu_memory_frac=self.gpu_memory_frac, verbose=self.verbose, random_seed=self.random_seed,\n",
        "            udpipe_lang=self.udpipe_lang, use_additional_features=self.use_additional_features\n",
        "        )\n",
        "        self.check_X(X, 'X')\n",
        "        self.is_fitted()\n",
        "        X_tokenized, _, _ = self.tokenize_all(X, shapes_vocabulary=self.shapes_list_)\n",
        "        n_samples = X_tokenized[0].shape[0]\n",
        "        X_tokenized = self.extend_Xy(X_tokenized)\n",
        "        n_batches = X_tokenized[0].shape[0] // self.batch_size\n",
        "        bounds_of_batches = []\n",
        "        for iteration in range(n_batches):\n",
        "            batch_start = iteration * self.batch_size\n",
        "            batch_end = batch_start + self.batch_size\n",
        "            bounds_of_batches.append((batch_start, batch_end))\n",
        "        y_pred = []\n",
        "        for cur_batch in bounds_of_batches:\n",
        "            feed_dict = self.fill_feed_dict(\n",
        "                [\n",
        "                    X_tokenized[channel_idx][cur_batch[0]:cur_batch[1]]\n",
        "                    for channel_idx in range(len(X_tokenized))\n",
        "                ]\n",
        "            )\n",
        "            logits, trans_params = self.sess_.run(['outputs_of_NER/BiasAdd:0', 'transitions:0'], feed_dict=feed_dict)\n",
        "            sequence_lengths = X_tokenized[1][cur_batch[0]:cur_batch[1]]\n",
        "            for logit, sequence_length in zip(logits, sequence_lengths):\n",
        "                logit = logit[:int(sequence_length)]\n",
        "                viterbi_seq, viterbi_score = tf.contrib.crf.viterbi_decode(logit, trans_params)\n",
        "                y_pred += [viterbi_seq]\n",
        "        del bounds_of_batches\n",
        "        recognized_entities_in_texts = []\n",
        "        for sample_idx, labels_in_text in enumerate(y_pred[0:n_samples]):\n",
        "            n_tokens = len(labels_in_text)\n",
        "            tokens = X_tokenized[0][sample_idx][:n_tokens]\n",
        "            bounds_of_tokens = self.calculate_bounds_of_tokens(X[sample_idx], tokens)\n",
        "            new_entities = self.calculate_bounds_of_named_entities(bounds_of_tokens, self.classes_list_, labels_in_text)\n",
        "            recognized_entities_in_texts.append(new_entities)\n",
        "        return recognized_entities_in_texts\n",
        "\n",
        "    def is_fitted(self):\n",
        "        check_is_fitted(self, ['classes_list_', 'shapes_list_', 'sess_'])\n",
        "\n",
        "    def score(self, X, y, sample_weight=None) -> float:\n",
        "        y_pred = self.predict(X)\n",
        "        return calculate_prediction_quality(y, y_pred, self.classes_list_)[0]\n",
        "\n",
        "    def fit_predict(self, X: Union[list, tuple, np.array],  y: Union[list, tuple, np.array], **kwargs):\n",
        "        return self.fit(X, y).predict(X)\n",
        "\n",
        "    def fill_feed_dict(self, X: List[np.array], y: np.array=None) -> dict:\n",
        "        if self.use_additional_features:\n",
        "            assert len(X) == 4\n",
        "        else:\n",
        "            assert len(X) == 2\n",
        "        assert len(X[0]) == self.batch_size\n",
        "        if self.use_additional_features:\n",
        "            feed_dict = {ph: x for ph, x in zip(['tokens:0', 'sequence_len:0', 'shape_features:0',\n",
        "                                                 'linguistic_features:0'], X)}\n",
        "        else:\n",
        "            feed_dict = {ph: x for ph, x in zip(['tokens:0', 'sequence_len:0'], X)}\n",
        "        if y is not None:\n",
        "            feed_dict['y_ph:0'] = y\n",
        "        return feed_dict\n",
        "\n",
        "    def extend_Xy(self, X: List[np.array], y: np.array = None,\n",
        "                  shuffle: bool = False) -> Union[List[np.array], Tuple[List[np.array], np.array]]:\n",
        "        n_samples = X[0].shape[0]\n",
        "        n_extend = n_samples % self.batch_size\n",
        "        if n_extend == 0:\n",
        "            if y is None:\n",
        "                return X\n",
        "            return X, y\n",
        "        n_extend = self.batch_size - n_extend\n",
        "        X_ext = [\n",
        "            np.concatenate(\n",
        "                (\n",
        "                    X[idx],\n",
        "                    np.full(\n",
        "                        shape=((n_extend, self.max_seq_length) if len(X[idx].shape) == 2 else\n",
        "                               ((n_extend,) if len(X[idx].shape) == 1 else\n",
        "                               (n_extend, self.max_seq_length, X[idx].shape[2]))),\n",
        "                        fill_value=X[idx][-1],\n",
        "                        dtype=X[idx].dtype\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "            for idx in range(len(X))\n",
        "        ]\n",
        "        if y is None:\n",
        "            if shuffle:\n",
        "                indices = np.arange(0, n_samples + n_extend, 1, dtype=np.int32)\n",
        "                np.random.shuffle(indices)\n",
        "                return [X_ext[idx][indices] for idx in range(len(X_ext))]\n",
        "            return X_ext\n",
        "        y_ext = np.concatenate(\n",
        "            (\n",
        "                y,\n",
        "                np.full(shape=(n_extend, self.max_seq_length), fill_value=y[-1], dtype=y.dtype)\n",
        "            )\n",
        "        )\n",
        "        if shuffle:\n",
        "            indices = np.arange(0, n_samples + n_extend, 1, dtype=np.int32)\n",
        "            return [X_ext[idx][indices] for idx in range(len(X_ext))], y_ext[indices]\n",
        "        return X_ext, y_ext\n",
        "\n",
        "    def tokenize_all(self, X: Union[list, tuple, np.array], y: Union[list, tuple, np.array] = None,\n",
        "                     shapes_vocabulary: Union[tuple, None] = None) -> Tuple[List[np.ndarray], Union[np.ndarray, None],\n",
        "                                                                            tuple]:\n",
        "        if shapes_vocabulary is not None:\n",
        "            if len(shapes_vocabulary) < 1:\n",
        "                raise ValueError('Shapes vocabulary is empty!')\n",
        "        tokens_of_texts = []\n",
        "        lenghts_of_texts = []\n",
        "        lingustic_features_of_texts = []\n",
        "        y_tokenized = None if y is None else np.empty((len(y), self.max_seq_length), dtype=np.int32)\n",
        "        n_samples = len(X)\n",
        "        shapes_of_texts = []\n",
        "        shapes_dict = dict()\n",
        "        if not hasattr(self, 'universal_pos_tags_dict_'):\n",
        "            self.universal_pos_tags_dict_ = dict(zip(UNIVERSAL_POS_TAGS, range(len(UNIVERSAL_POS_TAGS))))\n",
        "        if not hasattr(self, 'universal_dependencies_dict_'):\n",
        "            self.universal_dependencies_dict_ = dict(zip(UNIVERSAL_DEPENDENCIES, range(len(UNIVERSAL_DEPENDENCIES))))\n",
        "        if y is None:\n",
        "            for sample_idx in range(n_samples):\n",
        "                source_text = X[sample_idx]\n",
        "                if not hasattr(self, 'nlp_'):\n",
        "                    self.nlp_ = create_udpipe_pipeline(self.udpipe_lang)\n",
        "                spacy_doc = self.nlp_(source_text)\n",
        "                tokenized_text = []\n",
        "                pos_tags = []\n",
        "                dependencies = []\n",
        "                for spacy_token in spacy_doc:\n",
        "                    tokenized_text.append(spacy_token.text)\n",
        "                    pos_tags.append(spacy_token.pos_)\n",
        "                    dependencies.append(spacy_token.dep_)\n",
        "                del spacy_doc\n",
        "                shapes_of_text = [self.get_shape_of_string(cur) for cur in tokenized_text]\n",
        "                if shapes_vocabulary is None:\n",
        "                    for cur_shape in shapes_of_text:\n",
        "                        if cur_shape != '':\n",
        "                            shapes_dict[cur_shape] = shapes_dict.get(cur_shape, 0) + 1\n",
        "                ndiff = len(tokenized_text) - self.max_seq_length\n",
        "                if ndiff > 0:\n",
        "                    tokenized_text = tokenized_text[:self.max_seq_length]\n",
        "                    shapes_of_text = shapes_of_text[:self.max_seq_length]\n",
        "                    pos_tags = pos_tags[:self.max_seq_length]\n",
        "                    dependencies = dependencies[:self.max_seq_length]\n",
        "                    lenghts_of_texts.append(len(tokenized_text))\n",
        "                elif ndiff < 0:\n",
        "                    lenghts_of_texts.append(len(tokenized_text))\n",
        "                    tokenized_text += ['' for _ in range(-ndiff)]\n",
        "                else:\n",
        "                    lenghts_of_texts.append(len(tokenized_text))\n",
        "                tokens_of_texts.append(tokenized_text)\n",
        "                shapes_of_texts.append(shapes_of_text)\n",
        "                lingustic_features_of_texts.append(tuple(zip(pos_tags, dependencies)))\n",
        "                del pos_tags, dependencies, tokenized_text\n",
        "        else:\n",
        "            for sample_idx in range(n_samples):\n",
        "                source_text = X[sample_idx]\n",
        "                if not hasattr(self, 'nlp_'):\n",
        "                    self.nlp_ = create_udpipe_pipeline(self.udpipe_lang)\n",
        "                spacy_doc = self.nlp_(source_text)\n",
        "                tokenized_text = []\n",
        "                pos_tags = []\n",
        "                dependencies = []\n",
        "                for spacy_token in spacy_doc:\n",
        "                    tokenized_text.append(spacy_token.text)\n",
        "                    pos_tags.append(spacy_token.pos_)\n",
        "                    dependencies.append(spacy_token.dep_)\n",
        "                del spacy_doc\n",
        "                shapes_of_text = [self.get_shape_of_string(cur) for cur in tokenized_text]\n",
        "                if shapes_vocabulary is None:\n",
        "                    for cur_shape in shapes_of_text:\n",
        "                        if cur_shape != '':\n",
        "                            shapes_dict[cur_shape] = shapes_dict.get(cur_shape, 0) + 1\n",
        "                bounds_of_tokens = self.calculate_bounds_of_tokens(source_text, tokenized_text)\n",
        "                indices_of_named_entities, labels_IDs = self.calculate_indices_of_named_entities(\n",
        "                    source_text, self.classes_list_, y[sample_idx])\n",
        "                y_tokenized[sample_idx] = self.detect_token_labels(\n",
        "                    bounds_of_tokens, indices_of_named_entities, labels_IDs, self.max_seq_length\n",
        "                )\n",
        "                ndiff = len(tokenized_text) - self.max_seq_length\n",
        "                if ndiff > 0:\n",
        "                    tokenized_text = tokenized_text[:self.max_seq_length]\n",
        "                    shapes_of_text = shapes_of_text[:self.max_seq_length]\n",
        "                    pos_tags = pos_tags[:self.max_seq_length]\n",
        "                    dependencies = dependencies[:self.max_seq_length]\n",
        "                    lenghts_of_texts.append(len(tokenized_text))\n",
        "                elif ndiff < 0:\n",
        "                    lenghts_of_texts.append(len(tokenized_text))\n",
        "                    tokenized_text += ['' for _ in range(-ndiff)]\n",
        "                else:\n",
        "                    lenghts_of_texts.append(len(tokenized_text))\n",
        "                tokens_of_texts.append(tokenized_text)\n",
        "                shapes_of_texts.append(shapes_of_text)\n",
        "                lingustic_features_of_texts.append(tuple(zip(pos_tags, dependencies)))\n",
        "                del pos_tags, dependencies, tokenized_text\n",
        "        assert len(X) == len(tokens_of_texts), '{0} != {1}'.format(len(X), len(tokens_of_texts))\n",
        "        assert len(tokens_of_texts) == len(lenghts_of_texts), '{0} != {1}'.format(\n",
        "            len(tokens_of_texts), len(lenghts_of_texts))\n",
        "        assert len(lenghts_of_texts) == len(lingustic_features_of_texts), '{0} != {1}'.format(\n",
        "            len(lenghts_of_texts), len(lingustic_features_of_texts))\n",
        "        assert len(lenghts_of_texts) == len(shapes_of_texts), '{0} != {1}'.format(\n",
        "            len(lenghts_of_texts), len(shapes_of_texts))\n",
        "        if shapes_vocabulary is None:\n",
        "            shapes_vocabulary_ = list(map(\n",
        "                lambda it2: it2[0],\n",
        "                filter(\n",
        "                    lambda it1: it1[1] >= 3,\n",
        "                    [(cur_shape, shapes_dict[cur_shape]) for cur_shape in sorted(list(shapes_dict.keys()))]\n",
        "                )\n",
        "            ))\n",
        "            shapes_vocabulary_ = tuple(shapes_vocabulary_)\n",
        "        else:\n",
        "            shapes_vocabulary_ = shapes_vocabulary\n",
        "        shapes_ = np.zeros((len(X), self.max_seq_length, len(shapes_vocabulary_) + 3), dtype=np.float32)\n",
        "        for sample_idx in range(n_samples):\n",
        "            for token_idx, cur_shape in enumerate(shapes_of_texts[sample_idx]):\n",
        "                if cur_shape in shapes_vocabulary_:\n",
        "                    shape_ID = shapes_vocabulary_.index(cur_shape)\n",
        "                else:\n",
        "                    shape_ID = len(shapes_vocabulary_)\n",
        "                shapes_[sample_idx][token_idx][shape_ID] = 1.0\n",
        "            shapes_[sample_idx][0][len(shapes_vocabulary_) + 1] = 1.0\n",
        "            shapes_[sample_idx][len(shapes_of_texts[sample_idx]) - 1][len(shapes_vocabulary_) + 2] = 1.0\n",
        "        del shapes_of_texts\n",
        "        linguistic_features = np.zeros((len(X), self.max_seq_length, len(self.universal_pos_tags_dict_) +\n",
        "                                        len(self.universal_dependencies_dict_)), dtype=np.float32)\n",
        "        for sample_idx in range(n_samples):\n",
        "            for token_idx in range(len(lingustic_features_of_texts[sample_idx])):\n",
        "                pos_tag, dependency_tag = lingustic_features_of_texts[sample_idx][token_idx]\n",
        "                pos_tag_id = self.universal_pos_tags_dict_.get(pos_tag, -1)\n",
        "                if pos_tag_id >= 0:\n",
        "                    linguistic_features[sample_idx][token_idx][pos_tag_id] = 1.0\n",
        "                else:\n",
        "                    raise ValueError('Part-of-speech tag `{0}` is unknown!'.format(pos_tag))\n",
        "                ok = False\n",
        "                for dependency_tag_part in prepare_dependency_tag(dependency_tag):\n",
        "                    dependency_id = self.universal_dependencies_dict_.get(dependency_tag_part, -1)\n",
        "                    if dependency_id >= 0:\n",
        "                        linguistic_features[sample_idx][token_idx][dependency_id + len(UNIVERSAL_POS_TAGS)] = 1.0\n",
        "                        ok = True\n",
        "                if not ok:\n",
        "                    raise ValueError('Dependency tag `{0}` is unknown!'.format(dependency_tag))\n",
        "        if self.use_additional_features:\n",
        "            X = [np.array(tokens_of_texts, dtype=np.str), np.array(lenghts_of_texts, dtype=np.int32), shapes_,\n",
        "                 linguistic_features]\n",
        "        else:\n",
        "            X = [np.array(tokens_of_texts, dtype=np.str), np.array(lenghts_of_texts, dtype=np.int32)]\n",
        "        return X, (None if y is None else np.array(y_tokenized)), shapes_vocabulary_\n",
        "\n",
        "    def get_params(self, deep=True) -> dict:\n",
        "        return {'elmo_hub_module_handle': self.elmo_hub_module_handle, 'finetune_elmo': self.finetune_elmo,\n",
        "                'batch_size': self.batch_size, 'max_seq_length': self.max_seq_length, 'lr': self.lr,\n",
        "                'l2_reg': self.l2_reg, 'max_epochs': self.max_epochs, 'patience': self.patience,\n",
        "                'validation_fraction': self.validation_fraction, 'gpu_memory_frac': self.gpu_memory_frac,\n",
        "                'verbose': self.verbose, 'random_seed': self.random_seed, 'udpipe_lang': self.udpipe_lang,\n",
        "                'use_additional_features': self.use_additional_features}\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        for parameter, value in params.items():\n",
        "            self.__setattr__(parameter, value)\n",
        "        return self\n",
        "\n",
        "    def __copy__(self):\n",
        "        cls = self.__class__\n",
        "        result = cls.__new__(cls)\n",
        "        result.set_params(\n",
        "            elmo_hub_module_handle=self.elmo_hub_module_handle, finetune_elmo=self.finetune_elmo,\n",
        "            batch_size=self.batch_size, max_seq_length=self.max_seq_length, lr=self.lr, l2_reg=self.l2_reg,\n",
        "            validation_fraction=self.validation_fraction, max_epochs=self.max_epochs, patience=self.patience,\n",
        "            gpu_memory_frac=self.gpu_memory_frac, verbose=self.verbose, random_seed=self.random_seed,\n",
        "            udpipe_lang=self.udpipe_lang, use_additional_features=self.use_additional_features\n",
        "        )\n",
        "        try:\n",
        "            self.is_fitted()\n",
        "            is_fitted = True\n",
        "        except:\n",
        "            is_fitted = False\n",
        "        if is_fitted:\n",
        "            result.classes_list_ = self.classes_list_\n",
        "            result.shapes_list_ = self.shapes_list_\n",
        "            result.sess_ = self.sess_\n",
        "        return result\n",
        "\n",
        "    def __deepcopy__(self, memodict={}):\n",
        "        cls = self.__class__\n",
        "        result = cls.__new__(cls)\n",
        "        result.set_params(\n",
        "            elmo_hub_module_handle=self.elmo_hub_module_handle,  finetune_elmo=self.finetune_elmo,\n",
        "            batch_size=self.batch_size, max_seq_length=self.max_seq_length, lr=self.lr, l2_reg=self.l2_reg,\n",
        "            validation_fraction=self.validation_fraction, max_epochs=self.max_epochs, patience=self.patience,\n",
        "            gpu_memory_frac=self.gpu_memory_frac, verbose=self.verbose, random_seed=self.random_seed,\n",
        "            udpipe_lang=self.udpipe_lang, use_additional_features=self.use_additional_features\n",
        "        )\n",
        "        try:\n",
        "            self.is_fitted()\n",
        "            is_fitted = True\n",
        "        except:\n",
        "            is_fitted = False\n",
        "        if is_fitted:\n",
        "            result.classes_list_ = self.classes_list_\n",
        "            result.shapes_list_ = self.shapes_list_\n",
        "            result.sess_ = self.sess_\n",
        "        return result\n",
        "\n",
        "    def __getstate__(self):\n",
        "        return self.dump_all()\n",
        "\n",
        "    def __setstate__(self, state: dict):\n",
        "        self.load_all(state)\n",
        "\n",
        "    def update_random_seed(self):\n",
        "        if self.random_seed is None:\n",
        "            self.random_seed = int(round(time.time()))\n",
        "        random.seed(self.random_seed)\n",
        "        np.random.seed(self.random_seed)\n",
        "        tf.random.set_random_seed(self.random_seed)\n",
        "\n",
        "    def dump_all(self):\n",
        "        try:\n",
        "            self.is_fitted()\n",
        "            is_fitted = True\n",
        "        except:\n",
        "            is_fitted = False\n",
        "        params = self.get_params(True)\n",
        "        if is_fitted:\n",
        "            params['classes_list_'] = copy.copy(self.classes_list_)\n",
        "            params['shapes_list_'] = copy.copy(self.shapes_list_)\n",
        "            model_file_name = self.get_temp_model_name()\n",
        "            try:\n",
        "                params['model_name_'] = os.path.basename(model_file_name)\n",
        "                self.save_model(model_file_name)\n",
        "                for cur_name in self.find_all_model_files(model_file_name):\n",
        "                    with open(cur_name, 'rb') as fp:\n",
        "                        model_data = fp.read()\n",
        "                    params['model.' + os.path.basename(cur_name)] = model_data\n",
        "                    del model_data\n",
        "            finally:\n",
        "                for cur_name in self.find_all_model_files(model_file_name):\n",
        "                    os.remove(cur_name)\n",
        "        return params\n",
        "\n",
        "    def load_all(self, new_params: dict):\n",
        "        if not isinstance(new_params, dict):\n",
        "            raise ValueError('`new_params` is wrong! Expected `{0}`, got `{1}`.'.format(type({0: 1}), type(new_params)))\n",
        "        self.check_params(**new_params)\n",
        "        if hasattr(self, 'classes_list_'):\n",
        "            del self.classes_list_\n",
        "        if hasattr(self, 'shapes_list_'):\n",
        "            del self.shapes_list_\n",
        "        self.finalize_model()\n",
        "        is_fitted = ('classes_list_' in new_params) and ('model_name_' in new_params) and ('shapes_list_' in new_params)\n",
        "        model_files = list(\n",
        "            filter(\n",
        "                lambda it3: len(it3) > 0,\n",
        "                map(\n",
        "                    lambda it2: it2[len('model.'):].strip(),\n",
        "                    filter(\n",
        "                        lambda it1: it1.startswith('model.') and (len(it1) > len('model.')),\n",
        "                        new_params.keys()\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        if is_fitted and (len(model_files) == 0):\n",
        "            is_fitted = False\n",
        "        if is_fitted:\n",
        "            tmp_dir_name = tempfile.gettempdir()\n",
        "            tmp_file_names = [os.path.join(tmp_dir_name, cur) for cur in model_files]\n",
        "            for cur in tmp_file_names:\n",
        "                if os.path.isfile(cur):\n",
        "                    raise ValueError('File `{0}` exists, and so it cannot be used for data transmission!'.format(cur))\n",
        "            self.set_params(**new_params)\n",
        "            self.classes_list_ = copy.copy(new_params['classes_list_'])\n",
        "            self.shapes_list_ = copy.copy(new_params['shapes_list_'])\n",
        "            self.update_random_seed()\n",
        "            try:\n",
        "                for idx in range(len(model_files)):\n",
        "                    with open(tmp_file_names[idx], 'wb') as fp:\n",
        "                        fp.write(new_params['model.' + model_files[idx]])\n",
        "                self.load_model(os.path.join(tmp_dir_name, new_params['model_name_']))\n",
        "            finally:\n",
        "                for cur in tmp_file_names:\n",
        "                    if os.path.isfile(cur):\n",
        "                        os.remove(cur)\n",
        "        else:\n",
        "            self.set_params(**new_params)\n",
        "        return self\n",
        "\n",
        "    def build_model(self):\n",
        "        config = tf.ConfigProto()\n",
        "        config.gpu_options.per_process_gpu_memory_fraction = self.gpu_memory_frac\n",
        "        config.gpu_options.allow_growth = True\n",
        "        self.sess_ = tf.Session(config=config)\n",
        "        input_tokens = tf.placeholder(shape=(self.batch_size, self.max_seq_length), dtype=tf.string, name='tokens')\n",
        "        sequence_lengths = tf.placeholder(shape=(self.batch_size,), dtype=tf.int32, name='sequence_len')\n",
        "        y_ph = tf.placeholder(shape=(self.batch_size, self.max_seq_length), dtype=tf.int32, name='y_ph')\n",
        "        elmo_inputs = dict(\n",
        "            tokens=input_tokens,\n",
        "            sequence_len=sequence_lengths\n",
        "        )\n",
        "        elmo_module = tfhub.Module(self.elmo_hub_module_handle, trainable=self.finetune_elmo)\n",
        "        sequence_output = elmo_module(inputs=elmo_inputs, signature='tokens', as_dict=True)['elmo']\n",
        "        sequence_output = tf.reshape(sequence_output, [self.batch_size, self.max_seq_length, 1024])\n",
        "        if self.verbose:\n",
        "            elmo_ner_logger.info('The ELMo model has been loaded from the TF-Hub.')\n",
        "        n_tags = len(self.classes_list_) * 2 + 1\n",
        "        he_init = tf.contrib.layers.variance_scaling_initializer(seed=self.random_seed)\n",
        "        if self.use_additional_features:\n",
        "            shape_features = tf.placeholder(\n",
        "                shape=(self.batch_size, self.max_seq_length, len(self.shapes_list_) + 3), dtype=tf.float32,\n",
        "                name='shape_features'\n",
        "            )\n",
        "            linguistic_features = tf.placeholder(\n",
        "                shape=(self.batch_size, self.max_seq_length, len(UNIVERSAL_DEPENDENCIES) + len(UNIVERSAL_POS_TAGS)),\n",
        "                dtype=tf.float32,\n",
        "                name='linguistic_features'\n",
        "            )\n",
        "            if self.finetune_elmo:\n",
        "                logits = tf.layers.dense(tf.concat([sequence_output, shape_features, linguistic_features], axis=-1),\n",
        "                                         n_tags, activation=None, kernel_regularizer=tf.nn.l2_loss,\n",
        "                                         kernel_initializer=he_init, name='outputs_of_NER')\n",
        "            else:\n",
        "                sequence_output_stop = tf.stop_gradient(sequence_output)\n",
        "                logits = tf.layers.dense(\n",
        "                    tf.concat([sequence_output_stop, shape_features, linguistic_features], axis=-1),\n",
        "                    n_tags, activation=None, kernel_regularizer=tf.nn.l2_loss,\n",
        "                    kernel_initializer=he_init, name='outputs_of_NER')\n",
        "        else:\n",
        "            if self.finetune_elmo:\n",
        "                logits = tf.layers.dense(sequence_output,\n",
        "                                         n_tags, activation=None, kernel_regularizer=tf.nn.l2_loss,\n",
        "                                         kernel_initializer=he_init, name='outputs_of_NER')\n",
        "            else:\n",
        "                sequence_output_stop = tf.stop_gradient(sequence_output)\n",
        "                logits = tf.layers.dense(\n",
        "                    sequence_output_stop,\n",
        "                    n_tags, activation=None, kernel_regularizer=tf.nn.l2_loss,\n",
        "                    kernel_initializer=he_init, name='outputs_of_NER')\n",
        "        log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(logits, y_ph, sequence_lengths)\n",
        "        loss_tensor = -log_likelihood\n",
        "        base_loss = tf.reduce_mean(loss_tensor)\n",
        "        regularization_loss = self.l2_reg * tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
        "        final_loss = base_loss + regularization_loss\n",
        "        with tf.name_scope('train'):\n",
        "            optimizer = tf.train.RMSPropOptimizer(learning_rate=self.lr, momentum=0.9, decay=0.9, epsilon=1e-10)\n",
        "            train_op = optimizer.minimize(final_loss)\n",
        "        with tf.name_scope('eval'):\n",
        "            log_likelihood_eval_, _ = tf.contrib.crf.crf_log_likelihood(logits, y_ph,\n",
        "                                                                        sequence_lengths, transition_params)\n",
        "            seq_norm_eval = tf.contrib.crf.crf_log_norm(logits, sequence_lengths, transition_params)\n",
        "            log_likelihood_eval = tf.reduce_mean(tf.cast(log_likelihood_eval_, tf.float32) /\n",
        "                                                 tf.cast(seq_norm_eval, tf.float32))\n",
        "        return train_op, log_likelihood_eval, logits, transition_params\n",
        "\n",
        "    def finalize_model(self):\n",
        "        if hasattr(self, 'sess_'):\n",
        "            for k in list(self.sess_.graph.get_all_collection_keys()):\n",
        "                self.sess_.graph.clear_collection(k)\n",
        "            self.sess_.close()\n",
        "            del self.sess_\n",
        "        tf.reset_default_graph()\n",
        "\n",
        "    def save_model(self, file_name: str):\n",
        "        saver = tf.train.Saver()\n",
        "        saver.save(self.sess_, file_name)\n",
        "\n",
        "    def load_model(self, file_name: str):\n",
        "        if not hasattr(self, 'sess_'):\n",
        "            config = tf.ConfigProto()\n",
        "            config.gpu_options.per_process_gpu_memory_fraction = self.gpu_memory_frac\n",
        "            config.gpu_options.allow_growth = True\n",
        "            self.sess_ = tf.Session(config=config)\n",
        "        saver = tf.train.import_meta_graph(file_name + '.meta', clear_devices=True)\n",
        "        saver.restore(self.sess_, file_name)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_temp_model_name() -> str:\n",
        "        with tempfile.NamedTemporaryFile(mode='w', suffix='elmo_crf.ckpt', delete=True) as fp:\n",
        "            res = fp.name\n",
        "        return res\n",
        "\n",
        "    @staticmethod\n",
        "    def find_all_model_files(model_name: str) -> List[str]:\n",
        "        model_files = []\n",
        "        if os.path.isfile(model_name):\n",
        "            model_files.append(model_name)\n",
        "        dir_name = os.path.dirname(model_name)\n",
        "        base_name = os.path.basename(model_name)\n",
        "        for cur in filter(lambda it: it.lower().find(base_name.lower()) >= 0, os.listdir(dir_name)):\n",
        "            model_files.append(os.path.join(dir_name, cur))\n",
        "        return sorted(model_files)\n",
        "\n",
        "    @staticmethod\n",
        "    def check_params(**kwargs):\n",
        "        if 'udpipe_lang' not in kwargs:\n",
        "            raise ValueError('`udpipe_lang` is not specified!')\n",
        "        if not isinstance(kwargs['udpipe_lang'], str):\n",
        "            raise ValueError('`udpipe_lang` is wrong! Expected `{0}`, got `{1}`.'.format(\n",
        "                type('abc'), type(kwargs['udpipe_lang'])))\n",
        "        if len(kwargs['udpipe_lang']) < 1:\n",
        "            raise ValueError('`udpipe_lang` is wrong! Expected a nonepty string.')\n",
        "        if 'batch_size' not in kwargs:\n",
        "            raise ValueError('`batch_size` is not specified!')\n",
        "        if (not isinstance(kwargs['batch_size'], int)) and (not isinstance(kwargs['batch_size'], np.int32)) and \\\n",
        "                (not isinstance(kwargs['batch_size'], np.uint32)):\n",
        "            raise ValueError('`batch_size` is wrong! Expected `{0}`, got `{1}`.'.format(\n",
        "                type(3), type(kwargs['batch_size'])))\n",
        "        if kwargs['batch_size'] < 1:\n",
        "            raise ValueError('`batch_size` is wrong! Expected a positive integer value, '\n",
        "                             'but {0} is not positive.'.format(kwargs['batch_size']))\n",
        "        if 'lr' not in kwargs:\n",
        "            raise ValueError('`lr` is not specified!')\n",
        "        if (not isinstance(kwargs['lr'], float)) and (not isinstance(kwargs['lr'], np.float32)) and \\\n",
        "                (not isinstance(kwargs['lr'], np.float64)):\n",
        "            raise ValueError('`lr` is wrong! Expected `{0}`, got `{1}`.'.format(type(3.5), type(kwargs['lr'])))\n",
        "        if kwargs['lr'] <= 0.0:\n",
        "            raise ValueError('`lr` is wrong! Expected a positive floating-point value, '\n",
        "                             'but {0} is not positive.'.format(kwargs['lr']))\n",
        "        if 'l2_reg' not in kwargs:\n",
        "            raise ValueError('`l2_reg` is not specified!')\n",
        "        if (not isinstance(kwargs['l2_reg'], float)) and (not isinstance(kwargs['l2_reg'], np.float32)) and \\\n",
        "                (not isinstance(kwargs['l2_reg'], np.float64)):\n",
        "            raise ValueError('`l2_reg` is wrong! Expected `{0}`, got `{1}`.'.format(type(3.5), type(kwargs['l2_reg'])))\n",
        "        if kwargs['l2_reg'] < 0.0:\n",
        "            raise ValueError('`l2_reg` is wrong! Expected a non-negative floating-point value, '\n",
        "                             'but {0} is negative.'.format(kwargs['l2_reg']))\n",
        "        if 'elmo_hub_module_handle' not in kwargs:\n",
        "            raise ValueError('`elmo_hub_module_handle` is not specified!')\n",
        "        if kwargs['elmo_hub_module_handle'] is not None:\n",
        "            if not isinstance(kwargs['elmo_hub_module_handle'], str):\n",
        "                raise ValueError('`elmo_hub_module_handle` is wrong! Expected `{0}`, got `{1}`.'.format(\n",
        "                    type('abc'), type(kwargs['elmo_hub_module_handle'])))\n",
        "            if len(kwargs['elmo_hub_module_handle']) < 1:\n",
        "                raise ValueError('`elmo_hub_module_handle` is wrong! Expected a nonepty string.')\n",
        "        if 'finetune_elmo' not in kwargs:\n",
        "            raise ValueError('`finetune_elmo` is not specified!')\n",
        "        if (not isinstance(kwargs['finetune_elmo'], int)) and (not isinstance(kwargs['finetune_elmo'], np.int32)) and \\\n",
        "                (not isinstance(kwargs['finetune_elmo'], np.uint32)) and \\\n",
        "                (not isinstance(kwargs['finetune_elmo'], bool)) and (not isinstance(kwargs['finetune_elmo'], np.bool)):\n",
        "            raise ValueError('`finetune_elmo` is wrong! Expected `{0}`, got `{1}`.'.format(\n",
        "                type(True), type(kwargs['finetune_elmo'])))\n",
        "        if 'max_epochs' not in kwargs:\n",
        "            raise ValueError('`max_epochs` is not specified!')\n",
        "        if (not isinstance(kwargs['max_epochs'], int)) and (not isinstance(kwargs['max_epochs'], np.int32)) and \\\n",
        "                (not isinstance(kwargs['max_epochs'], np.uint32)):\n",
        "            raise ValueError('`max_epochs` is wrong! Expected `{0}`, got `{1}`.'.format(\n",
        "                type(3), type(kwargs['max_epochs'])))\n",
        "        if kwargs['max_epochs'] < 1:\n",
        "            raise ValueError('`max_epochs` is wrong! Expected a positive integer value, '\n",
        "                             'but {0} is not positive.'.format(kwargs['max_epochs']))\n",
        "        if 'patience' not in kwargs:\n",
        "            raise ValueError('`patience` is not specified!')\n",
        "        if (not isinstance(kwargs['patience'], int)) and (not isinstance(kwargs['patience'], np.int32)) and \\\n",
        "                (not isinstance(kwargs['patience'], np.uint32)):\n",
        "            raise ValueError('`patience` is wrong! Expected `{0}`, got `{1}`.'.format(\n",
        "                type(3), type(kwargs['patience'])))\n",
        "        if kwargs['patience'] < 1:\n",
        "            raise ValueError('`patience` is wrong! Expected a positive integer value, '\n",
        "                             'but {0} is not positive.'.format(kwargs['patience']))\n",
        "        if 'random_seed' not in kwargs:\n",
        "            raise ValueError('`random_seed` is not specified!')\n",
        "        if kwargs['random_seed'] is not None:\n",
        "            if (not isinstance(kwargs['random_seed'], int)) and (not isinstance(kwargs['random_seed'], np.int32)) and \\\n",
        "                    (not isinstance(kwargs['random_seed'], np.uint32)):\n",
        "                raise ValueError('`random_seed` is wrong! Expected `{0}`, got `{1}`.'.format(\n",
        "                    type(3), type(kwargs['random_seed'])))\n",
        "        if 'gpu_memory_frac' not in kwargs:\n",
        "            raise ValueError('`gpu_memory_frac` is not specified!')\n",
        "        if (not isinstance(kwargs['gpu_memory_frac'], float)) and \\\n",
        "                (not isinstance(kwargs['gpu_memory_frac'], np.float32)) and \\\n",
        "                (not isinstance(kwargs['gpu_memory_frac'], np.float64)):\n",
        "            raise ValueError('`gpu_memory_frac` is wrong! Expected `{0}`, got `{1}`.'.format(\n",
        "                type(3.5), type(kwargs['gpu_memory_frac'])))\n",
        "        if (kwargs['gpu_memory_frac'] <= 0.0) or (kwargs['gpu_memory_frac'] > 1.0):\n",
        "            raise ValueError('`gpu_memory_frac` is wrong! Expected a floating-point value in the (0.0, 1.0], '\n",
        "                             'but {0} is not proper.'.format(kwargs['gpu_memory_frac']))\n",
        "        if 'max_seq_length' not in kwargs:\n",
        "            raise ValueError('`max_seq_length` is not specified!')\n",
        "        if (not isinstance(kwargs['max_seq_length'], int)) and \\\n",
        "                (not isinstance(kwargs['max_seq_length'], np.int32)) and \\\n",
        "                (not isinstance(kwargs['max_seq_length'], np.uint32)):\n",
        "            raise ValueError('`max_seq_length` is wrong! Expected `{0}`, got `{1}`.'.format(\n",
        "                type(3), type(kwargs['max_seq_length'])))\n",
        "        if kwargs['max_seq_length'] < 1:\n",
        "            raise ValueError('`max_seq_length` is wrong! Expected a positive integer value, '\n",
        "                             'but {0} is not positive.'.format(kwargs['max_seq_length']))\n",
        "        if 'validation_fraction' not in kwargs:\n",
        "            raise ValueError('`validation_fraction` is not specified!')\n",
        "        if (not isinstance(kwargs['validation_fraction'], float)) and \\\n",
        "                (not isinstance(kwargs['validation_fraction'], np.float32)) and \\\n",
        "                (not isinstance(kwargs['validation_fraction'], np.float64)):\n",
        "            raise ValueError('`validation_fraction` is wrong! Expected `{0}`, got `{1}`.'.format(\n",
        "                type(3.5), type(kwargs['validation_fraction'])))\n",
        "        if kwargs['validation_fraction'] < 0.0:\n",
        "            raise ValueError('`validation_fraction` is wrong! Expected a positive floating-point value greater than or '\n",
        "                             'equal to 0.0, but {0} is not positive.'.format(kwargs['validation_fraction']))\n",
        "        if kwargs['validation_fraction'] >= 1.0:\n",
        "            raise ValueError('`validation_fraction` is wrong! Expected a positive floating-point value less than 1.0, '\n",
        "                             'but {0} is not less than 1.0.'.format(kwargs['validation_fraction']))\n",
        "        if 'verbose' not in kwargs:\n",
        "            raise ValueError('`verbose` is not specified!')\n",
        "        if (not isinstance(kwargs['verbose'], int)) and (not isinstance(kwargs['verbose'], np.int32)) and \\\n",
        "                (not isinstance(kwargs['verbose'], np.uint32)) and \\\n",
        "                (not isinstance(kwargs['verbose'], bool)) and (not isinstance(kwargs['verbose'], np.bool)):\n",
        "            raise ValueError('`verbose` is wrong! Expected `{0}`, got `{1}`.'.format(\n",
        "                type(True), type(kwargs['verbose'])))\n",
        "        if 'use_additional_features' not in kwargs:\n",
        "            raise ValueError('`use_additional_features` is not specified!')\n",
        "        if (not isinstance(kwargs['use_additional_features'], int)) and \\\n",
        "                (not isinstance(kwargs['use_additional_features'], np.int32)) and \\\n",
        "                (not isinstance(kwargs['use_additional_features'], np.uint32)) and \\\n",
        "                (not isinstance(kwargs['use_additional_features'], bool)) and \\\n",
        "                (not isinstance(kwargs['use_additional_features'], np.bool)):\n",
        "            raise ValueError('`use_additional_features` is wrong! Expected `{0}`, got `{1}`.'.format(\n",
        "                type(True), type(kwargs['use_additional_features'])))\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_bounds_of_tokens(source_text: str, tokenized_text: List[str]) -> List[Tuple[int, int]]:\n",
        "        bounds_of_tokens = []\n",
        "        start_pos = 0\n",
        "        for cur_token in tokenized_text:\n",
        "            found_idx = source_text[start_pos:].find(cur_token)\n",
        "            n = len(cur_token)\n",
        "            if found_idx < 0:\n",
        "                raise ValueError('Text `{0}` cannot be tokenized! Token `{1}` cannot be found! Tokens are: {2}'.format(\n",
        "                    source_text, cur_token, tokenized_text))\n",
        "            bounds_of_tokens.append((start_pos + found_idx, start_pos + found_idx + n))\n",
        "            start_pos += (found_idx + n)\n",
        "        return bounds_of_tokens\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_bounds_of_named_entities(bounds_of_tokens: List[Tuple[int, int]], classes_list: tuple,\n",
        "                                           token_labels: List[int]) -> Dict[str, List[Tuple[int, int]]]:\n",
        "        named_entities_for_text = dict()\n",
        "        ne_start = -1\n",
        "        ne_type = ''\n",
        "        n_tokens = len(bounds_of_tokens)\n",
        "        for token_idx in range(n_tokens):\n",
        "            class_id = token_labels[token_idx]\n",
        "            if (class_id > 0) and ((class_id - 1) // 2 < len(classes_list)):\n",
        "                if ne_start < 0:\n",
        "                    ne_start = token_idx\n",
        "                    ne_type = classes_list[(class_id - 1) // 2]\n",
        "                else:\n",
        "                    if class_id % 2 == 0:\n",
        "                        if ne_type in named_entities_for_text:\n",
        "                            named_entities_for_text[ne_type].append(\n",
        "                                (bounds_of_tokens[ne_start][0], bounds_of_tokens[token_idx - 1][1])\n",
        "                            )\n",
        "                        else:\n",
        "                            named_entities_for_text[ne_type] = [\n",
        "                                (bounds_of_tokens[ne_start][0], bounds_of_tokens[token_idx - 1][1])\n",
        "                            ]\n",
        "                        ne_start = token_idx\n",
        "                        ne_type = classes_list[(class_id - 1) // 2]\n",
        "                    else:\n",
        "                        if classes_list[(class_id - 1) // 2] != ne_type:\n",
        "                            if ne_type in named_entities_for_text:\n",
        "                                named_entities_for_text[ne_type].append(\n",
        "                                    (bounds_of_tokens[ne_start][0], bounds_of_tokens[token_idx - 1][1])\n",
        "                                )\n",
        "                            else:\n",
        "                                named_entities_for_text[ne_type] = [\n",
        "                                    (bounds_of_tokens[ne_start][0], bounds_of_tokens[token_idx - 1][1])\n",
        "                                ]\n",
        "                            ne_start = token_idx\n",
        "                            ne_type = classes_list[(class_id - 1) // 2]\n",
        "            else:\n",
        "                if ne_start >= 0:\n",
        "                    if ne_type in named_entities_for_text:\n",
        "                        named_entities_for_text[ne_type].append(\n",
        "                            (bounds_of_tokens[ne_start][0], bounds_of_tokens[token_idx - 1][1])\n",
        "                        )\n",
        "                    else:\n",
        "                        named_entities_for_text[ne_type] = [\n",
        "                            (bounds_of_tokens[ne_start][0], bounds_of_tokens[token_idx - 1][1])\n",
        "                        ]\n",
        "                    ne_start = -1\n",
        "                    ne_type = ''\n",
        "        if ne_start >= 0:\n",
        "            if ne_type in named_entities_for_text:\n",
        "                named_entities_for_text[ne_type].append(\n",
        "                    (bounds_of_tokens[ne_start][0], bounds_of_tokens[-1][1])\n",
        "                )\n",
        "            else:\n",
        "                named_entities_for_text[ne_type] = [\n",
        "                    (bounds_of_tokens[ne_start][0], bounds_of_tokens[-1][1])\n",
        "                ]\n",
        "        return named_entities_for_text\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_indices_of_named_entities(source_text: str, classes_list: tuple,\n",
        "                                            named_entities: Dict[str, List[tuple]]) -> \\\n",
        "            Tuple[np.ndarray, Dict[int, int]]:\n",
        "        indices_of_named_entities = np.zeros((len(source_text),), dtype=np.int32)\n",
        "        labels_to_classes = dict()\n",
        "        label_ID = 1\n",
        "        for ne_type in sorted(list(named_entities.keys())):\n",
        "            class_id = classes_list.index(ne_type) + 1\n",
        "            for ne_bounds in named_entities[ne_type]:\n",
        "                for char_idx in range(ne_bounds[0], ne_bounds[1]):\n",
        "                    indices_of_named_entities[char_idx] = label_ID\n",
        "                labels_to_classes[label_ID] = class_id\n",
        "                label_ID += 1\n",
        "        return indices_of_named_entities, labels_to_classes\n",
        "\n",
        "    @staticmethod\n",
        "    def detect_token_labels(bounds_of_tokens: List[tuple], indices_of_named_entities: np.ndarray, label_ids: dict,\n",
        "                            max_seq_length: int) -> np.ndarray:\n",
        "        res = np.zeros((max_seq_length,), dtype=np.int32)\n",
        "        n = min(len(bounds_of_tokens), max_seq_length)\n",
        "        for token_idx, cur in enumerate(bounds_of_tokens[:n]):\n",
        "            distr = np.zeros((len(label_ids) + 1,), dtype=np.int32)\n",
        "            for char_idx in range(cur[0], cur[1]):\n",
        "                distr[indices_of_named_entities[char_idx]] += 1\n",
        "            label_id = distr.argmax()\n",
        "            if label_id > 0:\n",
        "                res[token_idx] = label_id\n",
        "            del distr\n",
        "        prev_label_id = 0\n",
        "        for token_idx in range(max_seq_length):\n",
        "            cur_label_id = res[token_idx]\n",
        "            if cur_label_id > 0:\n",
        "                ne_id = label_ids[res[token_idx]]\n",
        "                if cur_label_id == prev_label_id:\n",
        "                    res[token_idx] = ne_id * 2 - 1\n",
        "                else:\n",
        "                    res[token_idx] = ne_id * 2\n",
        "            prev_label_id = cur_label_id\n",
        "        return res\n",
        "\n",
        "    @staticmethod\n",
        "    def get_shape_of_string(src: str) -> str:\n",
        "        shape = ''\n",
        "        for idx in range(len(src)):\n",
        "            if src[idx] in {'_', chr(11791)}:\n",
        "                new_char = '_'\n",
        "            elif src[idx].isalpha():\n",
        "                if src[idx].isupper():\n",
        "                    new_char = 'A'\n",
        "                else:\n",
        "                    new_char = 'a'\n",
        "            elif src[idx].isdigit():\n",
        "                new_char = 'D'\n",
        "            elif src[idx] in {'.', ',', ':', ';', '-', '+', '!', '?', '#', '@', '$', '&', '=', '^', '`', '~', '*', '/',\n",
        "                              '\\\\', '(', ')', '[', ']', '{', '}', \"'\", '\"', '|', '<', '>'}:\n",
        "                new_char = 'P'\n",
        "            elif src[idx] in {chr(8213), chr(8212), chr(8211), chr(8210), chr(8209), chr(8208), chr(11834), chr(173),\n",
        "                              chr(8722), chr(8259)}:\n",
        "                new_char = '-'\n",
        "            elif src[idx] in {chr(8220), chr(8221), chr(11842), chr(171), chr(187), chr(128631), chr(128630),\n",
        "                              chr(128632), chr(12318), chr(12317), chr(12319)}:\n",
        "                new_char = '\"'\n",
        "            elif src[idx] in {chr(39), chr(8216), chr(8217), chr(8218)}:\n",
        "                new_char = \"'\"\n",
        "            else:\n",
        "                new_char = 'U'\n",
        "            if len(shape) == 0:\n",
        "                shape += new_char\n",
        "            elif shape[-1] != new_char:\n",
        "                shape += new_char\n",
        "        return shape\n",
        "\n",
        "    @staticmethod\n",
        "    def check_X(X: Union[list, tuple, np.array], X_name: str):\n",
        "        if (not hasattr(X, '__len__')) or (not hasattr(X, '__getitem__')):\n",
        "            raise ValueError('`{0}` is wrong, because it is not list-like object!'.format(X_name))\n",
        "        if isinstance(X, np.ndarray):\n",
        "            if len(X.shape) != 1:\n",
        "                raise ValueError('`{0}` is wrong, because it is not 1-D list!'.format(X_name))\n",
        "        n = len(X)\n",
        "        for idx in range(n):\n",
        "            if (not hasattr(X[idx], '__len__')) or (not hasattr(X[idx], '__getitem__')) or \\\n",
        "                    (not hasattr(X[idx], 'strip')) or (not hasattr(X[idx], 'split')):\n",
        "                raise ValueError('Item {0} of `{1}` is wrong, because it is not string-like object!'.format(\n",
        "                    idx, X_name))\n",
        "\n",
        "    @staticmethod\n",
        "    def check_Xy(X: Union[list, tuple, np.array], X_name: str, y: Union[list, tuple, np.array], y_name: str) -> tuple:\n",
        "        ELMo_NER.check_X(X, X_name)\n",
        "        if (not hasattr(y, '__len__')) or (not hasattr(y, '__getitem__')):\n",
        "            raise ValueError('`{0}` is wrong, because it is not a list-like object!'.format(y_name))\n",
        "        if isinstance(y, np.ndarray):\n",
        "            if len(y.shape) != 1:\n",
        "                raise ValueError('`{0}` is wrong, because it is not 1-D list!'.format(y_name))\n",
        "        n = len(y)\n",
        "        if n != len(X):\n",
        "            raise ValueError('Length of `{0}` does not correspond to length of `{1}`! {2} != {3}'.format(\n",
        "                X_name, y_name, len(X), len(y)))\n",
        "        classes_list = set()\n",
        "        for idx in range(n):\n",
        "            if (not hasattr(y[idx], '__len__')) or (not hasattr(y[idx], 'items')) or (not hasattr(y[idx], 'keys')) or \\\n",
        "                    (not hasattr(y[idx], 'values')):\n",
        "                raise ValueError('Item {0} of `{1}` is wrong, because it is not a dictionary-like object!'.format(\n",
        "                    idx, y_name))\n",
        "            for ne_type in sorted(list(y[idx].keys())):\n",
        "                if (not hasattr(ne_type, '__len__')) or (not hasattr(ne_type, '__getitem__')) or \\\n",
        "                        (not hasattr(ne_type, 'strip')) or (not hasattr(ne_type, 'split')):\n",
        "                    raise ValueError('Item {0} of `{1}` is wrong, because its key `{2}` is not a string-like '\n",
        "                                     'object!'.format(idx, y_name, ne_type))\n",
        "                if (ne_type == 'O') or (ne_type == 'o') or (ne_type == 'О') or (ne_type == 'о'):\n",
        "                    raise ValueError('Item {0} of `{1}` is wrong, because its key `{2}` incorrectly specifies a named '\n",
        "                                     'entity!'.format(idx, y_name, ne_type))\n",
        "                if (not ne_type.isalpha()) or (not ne_type.isupper()):\n",
        "                    raise ValueError('Item {0} of `{1}` is wrong, because its key `{2}` incorrectly specifies a named '\n",
        "                                     'entity!'.format(idx, y_name, ne_type))\n",
        "                classes_list.add(ne_type)\n",
        "                if (not hasattr(y[idx][ne_type], '__len__')) or (not hasattr(y[idx][ne_type], '__getitem__')):\n",
        "                    raise ValueError('Item {0} of `{1}` is wrong, because its value `{2}` is not a list-like '\n",
        "                                     'object!'.format(idx, y_name, y[idx][ne_type]))\n",
        "                for ne_bounds in y[idx][ne_type]:\n",
        "                    if (not hasattr(ne_bounds, '__len__')) or (not hasattr(ne_bounds, '__getitem__')):\n",
        "                        raise ValueError('Item {0} of `{1}` is wrong, because named entity bounds `{2}` are not '\n",
        "                                         'specified as list-like object!'.format(idx, y_name, ne_bounds))\n",
        "                    if len(ne_bounds) != 2:\n",
        "                        raise ValueError('Item {0} of `{1}` is wrong, because named entity bounds `{2}` are not '\n",
        "                                         'specified as 2-D list!'.format(idx, y_name, ne_bounds))\n",
        "                    if (ne_bounds[0] < 0) or (ne_bounds[1] > len(X[idx])) or (ne_bounds[0] >= ne_bounds[1]):\n",
        "                        raise ValueError('Item {0} of `{1}` is wrong, because named entity bounds `{2}` are '\n",
        "                                         'incorrect!'.format(idx, y_name, ne_bounds))\n",
        "        return tuple(sorted(list(classes_list)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C95PekQrXJTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset_from_json(file_name: str) -> Tuple[List[str], List[Dict[str, List[Tuple[int, int]]]]]:\n",
        "\n",
        "    def prepare_bounds(source_named_entities: Dict[str, List[List[int]]]) -> Dict[str, List[Tuple[int, int]]]:\n",
        "        prepared_named_entities = dict()\n",
        "        for cur_ne in source_named_entities:\n",
        "            new_list = []\n",
        "            prev_idx_ = -1\n",
        "            for old_bounds in sorted(source_named_entities[cur_ne]):\n",
        "                if prev_idx_ < 0:\n",
        "                    new_list.append((old_bounds[0], old_bounds[1]))\n",
        "                else:\n",
        "                    if prev_idx_ >= old_bounds[0]:\n",
        "                        new_list[-1] = (new_list[-1][0], old_bounds[1])\n",
        "                    else:\n",
        "                        new_list.append((old_bounds[0], old_bounds[1]))\n",
        "                prev_idx_ = old_bounds[1]\n",
        "            prepared_named_entities[cur_ne] = new_list\n",
        "            del new_list\n",
        "        return prepared_named_entities\n",
        "\n",
        "    if not os.path.isfile(file_name):\n",
        "        raise ValueError('The file `{0}` does not exist!'.format(file_name))\n",
        "    X = []\n",
        "    y = []\n",
        "    with codecs.open(file_name, mode='r', encoding='utf-8', errors='ignore') as fp:\n",
        "        data = json.load(fp)\n",
        "    if not isinstance(data, list):\n",
        "        raise ValueError('The file `{0}` contains incorrect data! Expected a `{1}`, but got a `{2}`.'.format(\n",
        "            file_name, type([1, 2]), type(data)))\n",
        "    for sample_idx, sample_value in enumerate(data):\n",
        "        if not isinstance(sample_value, dict):\n",
        "            raise ValueError('{0} sample in the file `{1}` contains incorrect data! Expected a `{2}`, but got a '\n",
        "                             '`{3}`.'.format(sample_idx, file_name, type({'a': 1, 'b': 2}), type(sample_value)))\n",
        "        if 'text' not in sample_value:\n",
        "            raise ValueError('{0} sample in the file `{1}` contains incorrect data! '\n",
        "                             'The key `text` is not found!'.format(sample_idx, file_name))\n",
        "        if 'named_entities' not in sample_value:\n",
        "            raise ValueError('{0} sample in the file `{1}` contains incorrect data! '\n",
        "                             'The key `named_entities` is not found!'.format(sample_idx, file_name))\n",
        "        if 'paragraph_bounds' in sample_value:\n",
        "            bounds_of_paragraphs = sample_value['paragraph_bounds']\n",
        "            if len(sample_value) > 3:\n",
        "                excess_keys = sorted(list(set(sample_value.keys()) - {'text', 'named_entities', 'paragraph_bounds',\n",
        "                                                                      'base_name'}))\n",
        "                if len(excess_keys) > 0:\n",
        "                    raise ValueError('{0} sample in the file `{1}` contains incorrect data! Keys {2} are '\n",
        "                                     'excess!'.format(sample_idx, file_name, excess_keys))\n",
        "            if not isinstance(sample_value['paragraph_bounds'], list):\n",
        "                raise ValueError(\n",
        "                    '{0} sample in the file `{1}` contains incorrect data! Value of `paragraph_bounds` must be '\n",
        "                    'a `{2}`, but it is a `{3}`.'.format(sample_idx, file_name, type([1, 2, 3]),\n",
        "                                                         type(sample_value['text'])))\n",
        "        else:\n",
        "            bounds_of_paragraphs = None\n",
        "            if len(sample_value) > 2:\n",
        "                excess_keys = sorted(list(set(sample_value.keys()) - {'text', 'named_entities', 'base_name'}))\n",
        "                if len(excess_keys) > 0:\n",
        "                    raise ValueError('{0} sample in the file `{1}` contains incorrect data! Keys {2} are '\n",
        "                                     'excess!'.format(sample_idx, file_name, excess_keys))\n",
        "        if not isinstance(sample_value['text'], str):\n",
        "            raise ValueError('{0} sample in the file `{1}` contains incorrect data! Value of `text` must be a `{2}`, '\n",
        "                             'but it is a `{3}`.'.format(sample_idx, file_name, type('123'),\n",
        "                                                         type(sample_value['text'])))\n",
        "        if not isinstance(sample_value['named_entities'], dict):\n",
        "            raise ValueError('{0} sample in the file `{1}` contains incorrect data! Value of `named_entities` must be '\n",
        "                             'a `{2}`, but it is a `{3}`.'.format(sample_idx, file_name, type({'a': 1, 'b': 2}),\n",
        "                                                                  type(sample_value['text'])))\n",
        "        for entity_type in sample_value['named_entities']:\n",
        "            if not isinstance(entity_type, str):\n",
        "                raise ValueError(\n",
        "                    '{0} sample in the file `{1}` contains incorrect data! Entity type `{2}` is wrong! Expected a '\n",
        "                    '`{3}`, but got a `{4}`.'.format(sample_idx, file_name, entity_type, type('123'),\n",
        "                                                     type(entity_type)))\n",
        "            for entity_bounds in sample_value['named_entities'][entity_type]:\n",
        "                if not isinstance(entity_bounds, list):\n",
        "                    raise ValueError('{0} sample in the file `{1}` contains incorrect data! {2} is wrong value for '\n",
        "                                     'entity bounds.'.format(sample_idx, file_name, entity_bounds))\n",
        "                if len(entity_bounds) != 2:\n",
        "                    raise ValueError('{0} sample in the file `{1}` contains incorrect data! {2} is wrong value for '\n",
        "                                     'entity bounds.'.format(sample_idx, file_name, entity_bounds))\n",
        "                if (entity_bounds[0] < 0) or (entity_bounds[0] >= len(sample_value['text'])):\n",
        "                    raise ValueError('{0} sample in the file `{1}` contains incorrect data! {2} is wrong value for '\n",
        "                                     'entity bounds.'.format(sample_idx, file_name, entity_bounds))\n",
        "                if (entity_bounds[1] <= entity_bounds[0]) or (entity_bounds[1] > len(sample_value['text'])):\n",
        "                    raise ValueError('{0} sample in the file `{1}` contains incorrect data! {2} is wrong value for '\n",
        "                                     'entity bounds.'.format(sample_idx, file_name, entity_bounds))\n",
        "        if bounds_of_paragraphs is not None:\n",
        "            for paragraph_bounds in bounds_of_paragraphs:\n",
        "                if not isinstance(paragraph_bounds, list):\n",
        "                    raise ValueError(\n",
        "                        '{0} sample in the file `{1}` contains incorrect data! {2} is wrong value for paragraph '\n",
        "                        'bounds.'.format(sample_idx, file_name, paragraph_bounds))\n",
        "                if len(paragraph_bounds) != 2:\n",
        "                    raise ValueError(\n",
        "                        '{0} sample in the file `{1}` contains incorrect data! {2} is wrong value for paragraph '\n",
        "                        'bounds.'.format(sample_idx, file_name, paragraph_bounds))\n",
        "                if (paragraph_bounds[0] < 0) or (paragraph_bounds[0] >= len(sample_value['text'])):\n",
        "                    raise ValueError(\n",
        "                        '{0} sample in the file `{1}` contains incorrect data! {2} is wrong value for paragraph '\n",
        "                        'bounds.'.format(sample_idx, file_name, paragraph_bounds))\n",
        "                if (paragraph_bounds[1] <= paragraph_bounds[0]) or (paragraph_bounds[1] > len(sample_value['text'])):\n",
        "                    raise ValueError(\n",
        "                        '{0} sample in the file `{1}` contains incorrect data! {2} is wrong value for paragraph '\n",
        "                        'bounds.'.format(sample_idx, file_name, paragraph_bounds))\n",
        "            bounds_of_paragraphs = [tuple(cur) for cur in bounds_of_paragraphs]\n",
        "            text_by_paragraphs = list()\n",
        "            entities_by_paragraphs = list()\n",
        "            for paragraph_start, paragraph_end in bounds_of_paragraphs:\n",
        "                text_by_paragraphs.append(sample_value['text'][paragraph_start:paragraph_end])\n",
        "                entities_by_paragraphs.append(dict())\n",
        "            for entity_type in sample_value['named_entities']:\n",
        "                for entity_bounds in sorted(sample_value['named_entities'][entity_type]):\n",
        "                    paragraph_idx = find_paragraph(bounds_of_paragraphs, entity_bounds[0], entity_bounds[1])\n",
        "                    if paragraph_idx < 0:\n",
        "                        raise ValueError('{0} sample in the file `{1}` contains incorrect data! {2} is wrong value for '\n",
        "                                         'entity bounds.'.format(sample_idx, file_name, entity_bounds))\n",
        "                    paragraph_start = bounds_of_paragraphs[paragraph_idx][0]\n",
        "                    if entity_type in entities_by_paragraphs[paragraph_idx]:\n",
        "                        entities_by_paragraphs[paragraph_idx][entity_type].append(\n",
        "                            (entity_bounds[0] - paragraph_start, entity_bounds[1] - paragraph_start)\n",
        "                        )\n",
        "                    else:\n",
        "                        entities_by_paragraphs[paragraph_idx][entity_type] = [\n",
        "                            (entity_bounds[0] - paragraph_start, entity_bounds[1] - paragraph_start)\n",
        "                        ]\n",
        "            for paragraph_idx in range(len(bounds_of_paragraphs)):\n",
        "                X.append(text_by_paragraphs[paragraph_idx])\n",
        "                entities_by_paragraphs_ = dict()\n",
        "                for entity_type in entities_by_paragraphs[paragraph_idx]:\n",
        "                    entities_list = []\n",
        "                    prev_idx = -1\n",
        "                    for entity_bounds in sorted(entities_by_paragraphs[paragraph_idx][entity_type]):\n",
        "                        if prev_idx < 0:\n",
        "                            entities_list.append(entity_bounds)\n",
        "                        else:\n",
        "                            if prev_idx >= entity_bounds[0]:\n",
        "                                entities_list[-1] = (entities_list[-1][0], entity_bounds[1])\n",
        "                            else:\n",
        "                                entities_list.append(entity_bounds)\n",
        "                        prev_idx = entity_bounds[1]\n",
        "                    entities_by_paragraphs_[entity_type] = entities_list\n",
        "                    del entities_list\n",
        "                y.append(entities_by_paragraphs_)\n",
        "                del entities_by_paragraphs_\n",
        "        else:\n",
        "            X.append(sample_value['text'])\n",
        "            y.append(prepare_bounds(sample_value['named_entities']))\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWne2lxdYiii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def factrueval2016_to_json(src_dir_name: str, dst_json_name: str, split_by_paragraphs: bool=True):\n",
        "    factrueval_files = dict()\n",
        "    for cur_file_name in os.listdir(src_dir_name):\n",
        "        if cur_file_name.endswith('.objects'):\n",
        "            base_name = cur_file_name[:-len('.objects')]\n",
        "        elif cur_file_name.endswith('.spans'):\n",
        "            base_name = cur_file_name[:-len('.spans')]\n",
        "        elif cur_file_name.endswith('.tokens'):\n",
        "            base_name = cur_file_name[:-len('.tokens')]\n",
        "        else:\n",
        "            base_name = None\n",
        "        if base_name is not None:\n",
        "            if base_name in factrueval_files:\n",
        "                assert cur_file_name not in factrueval_files[base_name]\n",
        "                factrueval_files[base_name].append(cur_file_name)\n",
        "            else:\n",
        "                factrueval_files[base_name] = [cur_file_name]\n",
        "    for base_name in factrueval_files:\n",
        "        if len(factrueval_files[base_name]) != 3:\n",
        "            raise ValueError('Files list for `{0}` is wrong!'.format(base_name))\n",
        "        text_file_name = os.path.join(src_dir_name, base_name + '.txt')\n",
        "        if not os.path.isfile(text_file_name):\n",
        "            raise ValueError('File `{0}` does not exist!'.format(text_file_name))\n",
        "        factrueval_files[base_name].append(text_file_name)\n",
        "        factrueval_files[base_name] = sorted(factrueval_files[base_name])\n",
        "    train_data = []\n",
        "    for base_name in sorted(list(factrueval_files.keys())):\n",
        "        if split_by_paragraphs:\n",
        "            tokens, text, paragraphs = load_tokens_from_factrueval2016_by_paragraphs(\n",
        "                os.path.join(src_dir_name, base_name + '.txt'), os.path.join(src_dir_name, base_name + '.tokens')\n",
        "            )\n",
        "        else:\n",
        "            tokens, text, paragraphs = load_tokens_from_factrueval2016_by_sentences(\n",
        "                os.path.join(src_dir_name, base_name + '.tokens')\n",
        "            )\n",
        "        spans = load_spans_from_factrueval2016(os.path.join(src_dir_name, base_name + '.spans'), tokens)\n",
        "        objects = load_objects_from_factrueval2016(os.path.join(src_dir_name, base_name + '.objects'), spans)\n",
        "        named_entities = dict()\n",
        "        if len(objects) > 0:\n",
        "            for object_ID in objects:\n",
        "                ne_type = objects[object_ID][0]\n",
        "                tokens_of_ne = set()\n",
        "                spans_of_ne = objects[object_ID][1]\n",
        "                for span_ID in spans_of_ne:\n",
        "                    tokens_of_ne |= set(spans[span_ID])\n",
        "                tokens_of_ne = sorted(list(tokens_of_ne))\n",
        "                if len(tokens_of_ne) > 0:\n",
        "                    token_ID = tokens_of_ne[0]\n",
        "                    ne_start = tokens[token_ID][0]\n",
        "                    ne_end = tokens[token_ID][1]\n",
        "                    for token_ID in tokens_of_ne[1:]:\n",
        "                        if tokens[token_ID][0] < ne_start:\n",
        "                            ne_start = tokens[token_ID][0]\n",
        "                        if tokens[token_ID][1] > ne_end:\n",
        "                            ne_end = tokens[token_ID][1]\n",
        "                    if ne_type in named_entities:\n",
        "                        named_entities[ne_type].append((ne_start, ne_end))\n",
        "                    else:\n",
        "                        named_entities[ne_type] = [(ne_start, ne_end)]\n",
        "        train_data.append({'text': text, 'named_entities': named_entities, 'paragraph_bounds': paragraphs,\n",
        "                           'base_name': base_name})\n",
        "    with codecs.open(dst_json_name, mode='w', encoding='utf-8', errors='ignore') as fp:\n",
        "        json.dump(train_data, fp, indent=4, ensure_ascii=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWo3XoRvd7JQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_tokens_from_factrueval2016_by_paragraphs(text_file_name: str, tokens_file_name: str) -> \\\n",
        "        Tuple[Dict[int, Tuple[int, int, str]], str, tuple]:\n",
        "    source_text = ''\n",
        "    start_pos = 0\n",
        "    tokens_and_their_bounds = dict()\n",
        "    line_idx = 1\n",
        "    bounds_of_paragraphs = []\n",
        "    texts_of_paragraphs = []\n",
        "    with codecs.open(text_file_name, mode='r', encoding='utf-8', errors='ignore') as fp:\n",
        "        cur_line = fp.readline()\n",
        "        while len(cur_line) > 0:\n",
        "            prep_line = cur_line.strip()\n",
        "            if len(prep_line) > 0:\n",
        "                texts_of_paragraphs.append(prep_line.lower())\n",
        "            cur_line = fp.readline()\n",
        "    paragraph_idx = 0\n",
        "    paragraph_pos = 0\n",
        "    with codecs.open(tokens_file_name, mode='r', encoding='utf-8', errors='ignore') as fp:\n",
        "        cur_line = fp.readline()\n",
        "        while len(cur_line) > 0:\n",
        "            prep_line = cur_line.strip()\n",
        "            if len(prep_line) > 0:\n",
        "                err_msg = 'File `{0}`: line {1} is wrong!'.format(tokens_file_name, line_idx)\n",
        "                parts_of_line = prep_line.split()\n",
        "                if len(parts_of_line) != 4:\n",
        "                    raise ValueError(err_msg)\n",
        "                try:\n",
        "                    token_id = int(parts_of_line[0])\n",
        "                except:\n",
        "                    token_id = -1\n",
        "                if token_id < 0:\n",
        "                    raise ValueError(err_msg)\n",
        "                try:\n",
        "                    token_start = int(parts_of_line[1])\n",
        "                except:\n",
        "                    token_start = -1\n",
        "                if token_start < len(source_text):\n",
        "                    raise ValueError(err_msg)\n",
        "                try:\n",
        "                    token_len = int(parts_of_line[2])\n",
        "                except:\n",
        "                    token_len = -1\n",
        "                if token_len < 0:\n",
        "                    raise ValueError(err_msg)\n",
        "                token_text = parts_of_line[3].strip()\n",
        "                if len(token_text) != token_len:\n",
        "                    raise ValueError(err_msg)\n",
        "                if token_id in tokens_and_their_bounds:\n",
        "                    raise ValueError(err_msg)\n",
        "                while len(source_text) < token_start:\n",
        "                    source_text += ' '\n",
        "                source_text += token_text\n",
        "                tokens_and_their_bounds[token_id] = (\n",
        "                    token_start, token_start + token_len,\n",
        "                    token_text\n",
        "                )\n",
        "                found_idx_in_paragraph = texts_of_paragraphs[paragraph_idx][paragraph_pos:].find(token_text.lower())\n",
        "                if found_idx_in_paragraph < 0:\n",
        "                    paragraph_idx += 1\n",
        "                    paragraph_pos = 0\n",
        "                    while paragraph_idx < len(texts_of_paragraphs):\n",
        "                        if len(bounds_of_paragraphs) == 0:\n",
        "                            bounds_of_paragraphs.append((0, start_pos))\n",
        "                        else:\n",
        "                            bounds_of_paragraphs.append((bounds_of_paragraphs[-1][1], start_pos))\n",
        "                        found_idx_in_paragraph = texts_of_paragraphs[paragraph_idx].find(token_text.lower())\n",
        "                        if found_idx_in_paragraph >= 0:\n",
        "                            break\n",
        "                        paragraph_idx += 1\n",
        "                    if paragraph_idx >= len(texts_of_paragraphs):\n",
        "                        raise ValueError(err_msg)\n",
        "                else:\n",
        "                    paragraph_pos += (found_idx_in_paragraph + len(token_text))\n",
        "                start_pos = len(source_text)\n",
        "            cur_line = fp.readline()\n",
        "            line_idx += 1\n",
        "    if len(texts_of_paragraphs) > 0:\n",
        "        if len(bounds_of_paragraphs) > 0:\n",
        "            bounds_of_paragraphs.append((bounds_of_paragraphs[-1][1], start_pos))\n",
        "        else:\n",
        "            bounds_of_paragraphs.append((0, start_pos))\n",
        "    bounds_of_paragraphs_after_strip = []\n",
        "    for cur_bounds in bounds_of_paragraphs:\n",
        "        if cur_bounds[0] < cur_bounds[1]:\n",
        "            source_paragraph_text = source_text[cur_bounds[0]:cur_bounds[1]]\n",
        "            paragraph_text_after_strip = source_paragraph_text.strip()\n",
        "            found_idx = source_paragraph_text.find(paragraph_text_after_strip)\n",
        "            if found_idx > 0:\n",
        "                paragraph_start = cur_bounds[0] + found_idx\n",
        "            else:\n",
        "                paragraph_start = cur_bounds[0]\n",
        "            paragraph_end = paragraph_start + len(paragraph_text_after_strip)\n",
        "            bounds_of_paragraphs_after_strip.append((paragraph_start, paragraph_end))\n",
        "        else:\n",
        "            bounds_of_paragraphs_after_strip.append(cur_bounds)\n",
        "    return tokens_and_their_bounds, source_text, tuple(bounds_of_paragraphs_after_strip)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKULpmqEeLiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_spans_from_factrueval2016(spans_file_name: str,\n",
        "                                   tokens_dict: Dict[int, Tuple[int, int, str]]) -> Dict[int, List[int]]:\n",
        "    spans = dict()\n",
        "    line_idx = 1\n",
        "    with codecs.open(spans_file_name, mode='r', encoding='utf-8', errors='ignore') as fp:\n",
        "        cur_line = fp.readline()\n",
        "        while len(cur_line) > 0:\n",
        "            prep_line = cur_line.strip()\n",
        "            if len(prep_line) > 0:\n",
        "                err_msg = 'File `{0}`: line {1} is wrong!'.format(spans_file_name, line_idx)\n",
        "                parts_of_line = prep_line.split()\n",
        "                if len(parts_of_line) < 9:\n",
        "                    raise ValueError(err_msg)\n",
        "                try:\n",
        "                    span_id = int(parts_of_line[0])\n",
        "                except:\n",
        "                    span_id = -1\n",
        "                if span_id < 0:\n",
        "                    raise ValueError(err_msg)\n",
        "                if span_id not in spans:\n",
        "                    try:\n",
        "                        found_idx = parts_of_line.index('#')\n",
        "                    except:\n",
        "                        found_idx = -1\n",
        "                    if found_idx < 0:\n",
        "                        raise ValueError(err_msg)\n",
        "                    if (len(parts_of_line) - 1 - found_idx) < 2:\n",
        "                        raise ValueError(err_msg)\n",
        "                    if (len(parts_of_line) - 1 - found_idx) % 2 != 0:\n",
        "                        raise ValueError(err_msg)\n",
        "                    n = (len(parts_of_line) - 1 - found_idx) // 2\n",
        "                    token_IDs = []\n",
        "                    try:\n",
        "                        for idx in range(found_idx + 1, found_idx + n + 1):\n",
        "                            new_token_ID = int(parts_of_line[idx])\n",
        "                            if new_token_ID in token_IDs:\n",
        "                                token_IDs = []\n",
        "                                break\n",
        "                            if new_token_ID not in tokens_dict:\n",
        "                                token_IDs = []\n",
        "                                break\n",
        "                            token_IDs.append(new_token_ID)\n",
        "                            if token_IDs[-1] < 0:\n",
        "                                token_IDs = []\n",
        "                                break\n",
        "                    except:\n",
        "                        token_IDs = []\n",
        "                    if len(token_IDs) == 0:\n",
        "                        raise ValueError(err_msg)\n",
        "                    spans[span_id] = token_IDs\n",
        "                    del token_IDs\n",
        "            cur_line = fp.readline()\n",
        "            line_idx += 1\n",
        "    return spans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmsc3BhWeVi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_objects_from_factrueval2016(objects_file_name: str,\n",
        "                                     spans_dict: Dict[int, List[int]]) -> Dict[int, Tuple[str, List[int]]]:\n",
        "    objects = dict()\n",
        "    line_idx = 1\n",
        "    with codecs.open(objects_file_name, mode='r', encoding='utf-8', errors='ignore') as fp:\n",
        "        cur_line = fp.readline()\n",
        "        while len(cur_line) > 0:\n",
        "            prep_line = cur_line.strip()\n",
        "            if len(prep_line) > 0:\n",
        "                err_msg = 'File `{0}`: line {1} is wrong!'.format(objects_file_name, line_idx)\n",
        "                parts_of_line = prep_line.split()\n",
        "                if len(parts_of_line) < 5:\n",
        "                    raise ValueError(err_msg)\n",
        "                try:\n",
        "                    object_id = int(parts_of_line[0])\n",
        "                    if object_id in objects:\n",
        "                        object_id = -1\n",
        "                except:\n",
        "                    object_id = -1\n",
        "                if object_id < 0:\n",
        "                    raise ValueError(err_msg)\n",
        "                ne_type = parts_of_line[1].upper()\n",
        "                if ne_type in {'PERSON', 'LOCATION', 'ORG', 'LOCORG'}:\n",
        "                    if ne_type == 'LOCORG':\n",
        "                        ne_type = 'LOCATION'\n",
        "                    try:\n",
        "                        found_idx = parts_of_line.index('#')\n",
        "                    except:\n",
        "                        found_idx = -1\n",
        "                    if found_idx < 3:\n",
        "                        raise ValueError(err_msg)\n",
        "                    span_IDs = []\n",
        "                    try:\n",
        "                        for idx in range(2, found_idx):\n",
        "                            new_span_ID = int(parts_of_line[idx])\n",
        "                            if new_span_ID < 0:\n",
        "                                span_IDs = []\n",
        "                                break\n",
        "                            if new_span_ID not in spans_dict:\n",
        "                                span_IDs = []\n",
        "                                break\n",
        "                            if new_span_ID in span_IDs:\n",
        "                                span_IDs = []\n",
        "                                break\n",
        "                            span_IDs.append(new_span_ID)\n",
        "                    except:\n",
        "                        span_IDs = []\n",
        "                    if len(span_IDs) == 0:\n",
        "                        raise ValueError(err_msg)\n",
        "                    objects[object_id] = (ne_type, span_IDs)\n",
        "                    del span_IDs\n",
        "            cur_line = fp.readline()\n",
        "            line_idx += 1\n",
        "    return objects"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvtnAcZwgAhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_paragraph(bounds_of_paragraphs: List[Tuple[int, int]], entity_start_idx: int, entity_end_idx: int) -> int:\n",
        "    paragraph_idx = -1\n",
        "    for idx, bounds in enumerate(bounds_of_paragraphs):\n",
        "        if (entity_start_idx >= bounds[0]) and (entity_start_idx < bounds[1]):\n",
        "            if (entity_end_idx > entity_start_idx) and (entity_end_idx <= bounds[1]):\n",
        "                paragraph_idx = idx\n",
        "                break\n",
        "    return paragraph_idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKSHUGwmnGdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_dataset(y: Union[list, tuple, np.array], test_part: float, n_restarts: int=10,\n",
        "                  logger: Union[Logger, None]=None) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    if n_restarts < 2:\n",
        "        raise ValueError('{0} is too small value of restarts number. It must be greater than 1.'.format(n_restarts))\n",
        "    n_samples = len(y)\n",
        "    if n_samples < 2:\n",
        "        raise ValueError('There are too few samples in the data set! Minimal number of samples is 2.')\n",
        "    n_test = int(round(test_part * n_samples))\n",
        "    n_train = n_samples - n_test\n",
        "    if n_test < 1:\n",
        "        raise ValueError('{0} is too small value of the test part! There are no samples for '\n",
        "                         'testing subset!'.format(test_part))\n",
        "    if n_train < 1:\n",
        "        raise ValueError('{0} is too large value of the test part! There are no samples for '\n",
        "                         'training subset!'.format(test_part))\n",
        "    indices = np.arange(0, n_samples, 1, dtype=np.int32)\n",
        "    np.random.shuffle(indices)\n",
        "    set_of_classes_for_training = set()\n",
        "    set_of_classes_for_testing = set()\n",
        "    for idx in indices[0:n_train]:\n",
        "        set_of_classes_for_training |= set(y[idx].keys())\n",
        "    for idx in indices[n_train:]:\n",
        "        set_of_classes_for_testing |= set(y[idx].keys())\n",
        "    if set_of_classes_for_training == set_of_classes_for_testing:\n",
        "        train_index = indices[0:n_train]\n",
        "        test_index = indices[n_train:]\n",
        "    else:\n",
        "        if set_of_classes_for_testing < set_of_classes_for_training:\n",
        "            best_indices = np.copy(indices)\n",
        "        else:\n",
        "            best_indices = None\n",
        "        for restart in range(1, n_restarts):\n",
        "            np.random.shuffle(indices)\n",
        "            set_of_classes_for_training = set()\n",
        "            set_of_classes_for_testing = set()\n",
        "            for idx in indices[0:n_train]:\n",
        "                set_of_classes_for_training |= set(y[idx].keys())\n",
        "            for idx in indices[n_train:]:\n",
        "                set_of_classes_for_testing |= set(y[idx].keys())\n",
        "            if set_of_classes_for_training == set_of_classes_for_testing:\n",
        "                best_indices = np.copy(indices)\n",
        "                break\n",
        "            if set_of_classes_for_testing < set_of_classes_for_training:\n",
        "                best_indices = np.copy(indices)\n",
        "        if best_indices is None:\n",
        "            if logger is None:\n",
        "                warnings.warn('Data set cannot be splitted by stratified folds.')\n",
        "            else:\n",
        "                logger.warning('Data set cannot be splitted by stratified folds.')\n",
        "            train_index = indices[0:n_train]\n",
        "            test_index = indices[n_train:]\n",
        "        else:\n",
        "            set_of_classes_for_training = set()\n",
        "            set_of_classes_for_testing = set()\n",
        "            for idx in best_indices[0:n_train]:\n",
        "                set_of_classes_for_training |= set(y[idx].keys())\n",
        "            for idx in best_indices[n_train:]:\n",
        "                set_of_classes_for_testing |= set(y[idx].keys())\n",
        "            if set_of_classes_for_training != set_of_classes_for_testing:\n",
        "                if logger is None:\n",
        "                    warnings.warn('Data set cannot be splitted by stratified folds.')\n",
        "                else:\n",
        "                    logger.warning('Data set cannot be splitted by stratified folds.')\n",
        "            train_index = best_indices[0:n_train]\n",
        "            test_index = best_indices[n_train:]\n",
        "    return np.sort(train_index), np.sort(test_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILPuogTCZSce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip factRuEval-2016-master.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6ACykmRmL8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow==1.15.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6dCAqoipCu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install spacy_udpipe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMA4_f_XpYIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install pymorphy2==0.8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5GSLIfbYzk0",
        "colab_type": "code",
        "outputId": "62a51cfb-7130-40b9-968e-59ebc85267f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "factrueval2016_to_json(\"factRuEval-2016-master/devset\", \"factrueval2016devset_to_json.json\")\n",
        "X, y = load_dataset_from_json(\"factrueval2016devset_to_json.json\")\n",
        "\n",
        "recognizer = ELMo_NER(\n",
        "    \n",
        "            finetune_elmo=False, \n",
        "            batch_size=16, \n",
        "            l2_reg=1e-2, \n",
        "            max_seq_length=200,\n",
        "            elmo_hub_module_handle='http://files.deeppavlov.ai/deeppavlov_data/elmo_ru-news_wmt11-16_1.5M_steps.tar.gz', \n",
        "            validation_fraction=0.25, \n",
        "            max_epochs=1,\n",
        "            patience=10, \n",
        "            gpu_memory_frac=0.9, \n",
        "            verbose=True, \n",
        "            random_seed=42, \n",
        "            lr=1e-2, \n",
        "            udpipe_lang='ru',\n",
        "            use_additional_features=False\n",
        "\n",
        "        )"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 308 ms, sys: 15.1 ms, total: 323 ms\n",
            "Wall time: 327 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0GRgXhDncBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elmo_ner_logger = logging.getLogger(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDw0mxT-nyi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UNIVERSAL_POS_TAGS = ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'CONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON',\n",
        "                      'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc7hl1Vxn0xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UNIVERSAL_DEPENDENCIES = ['acl', 'advcl', 'advmod', 'amod', 'appos', 'aux', 'auxpass', 'case', 'cc', 'ccomp',\n",
        "                          'compound', 'conj', 'cop', 'csubj', 'csubjpass', 'dep', 'det', 'discourse', 'dislocated',\n",
        "                          'dobj', 'expl', 'fixed', 'flat', 'foreign', 'goeswith', 'gov', 'iobj', 'list', 'mark', 'mwe',\n",
        "                          'name', 'neg', 'nmod', 'nsubj', 'nsubjpass', 'nummod', 'obj', 'obl', 'orphan', 'parataxis',\n",
        "                          'pass', 'punct', 'relcl', 'remnant', 'reparandum', 'root', 'vocative', 'xcomp']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW0gSaFWn7wa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_udpipe_pipeline(lang: str) -> UDPipeLanguage:\n",
        "    try:\n",
        "        pipeline = spacy_udpipe.load(lang)\n",
        "    except:\n",
        "        spacy_udpipe.download(lang)\n",
        "        pipeline = spacy_udpipe.load(lang)\n",
        "    if pipeline is None:\n",
        "        del pipeline\n",
        "        raise ValueError('The `{0}` language cannot be loaded for the UDPipe!')\n",
        "    return pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPcVIZiJpyhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_dependency_tag(source_tag: str) -> Set[str]:\n",
        "    re_for_splitting = re.compile('[:\\-]+')\n",
        "    tags = {source_tag.lower().replace(':', '').replace('-', '')}\n",
        "    for cur in filter(lambda it2: len(it2) > 0, map(lambda it1: it1.strip().lower(),\n",
        "                                                    re_for_splitting.split(source_tag))):\n",
        "        tags.add(cur)\n",
        "    return tags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RzvABc74Jgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_prediction_quality(true_entities: Union[list, tuple, np.array],\n",
        "                                 predicted_entities: List[Dict[str, List[Tuple[int, int]]]], classes_list: tuple) -> \\\n",
        "        Tuple[float, float, float, Dict[str, Tuple[float, float, float]]]:\n",
        "    true_entities_ = []\n",
        "    predicted_entities_ = []\n",
        "    n_samples = len(true_entities)\n",
        "    quality_by_entity_classes = dict()\n",
        "    for sample_idx in range(n_samples):\n",
        "        instant_entities = dict()\n",
        "        for ne_class in true_entities[sample_idx]:\n",
        "            entities_list = []\n",
        "            for entity_bounds in true_entities[sample_idx][ne_class]:\n",
        "                entities_list.append((entity_bounds[0], entity_bounds[1]))\n",
        "            entities_list.sort()\n",
        "            instant_entities[ne_class] = entities_list\n",
        "            del entities_list\n",
        "        true_entities_.append(instant_entities)\n",
        "        del instant_entities\n",
        "        instant_entities = dict()\n",
        "        for ne_class in predicted_entities[sample_idx]:\n",
        "            entities_list = []\n",
        "            for entity_bounds in predicted_entities[sample_idx][ne_class]:\n",
        "                entities_list.append((entity_bounds[0], entity_bounds[1]))\n",
        "            entities_list.sort()\n",
        "            instant_entities[ne_class] = entities_list\n",
        "            del entities_list\n",
        "        predicted_entities_.append(instant_entities)\n",
        "        del instant_entities\n",
        "    tp_total = 0\n",
        "    fp_total = 0\n",
        "    fn_total = 0\n",
        "    for ne_class in classes_list:\n",
        "        tp_for_ne = 0\n",
        "        fp_for_ne = 0\n",
        "        fn_for_ne = 0\n",
        "        for sample_idx in range(n_samples):\n",
        "            if (ne_class in true_entities_[sample_idx]) and \\\n",
        "                    (ne_class in predicted_entities_[sample_idx]):\n",
        "                n1 = len(true_entities_[sample_idx][ne_class])\n",
        "                n2 = len(predicted_entities_[sample_idx][ne_class])\n",
        "                similarity_dict = dict()\n",
        "                for idx1, true_bounds in enumerate(true_entities_[sample_idx][ne_class]):\n",
        "                    for idx2, predicted_bounds in enumerate(predicted_entities_[sample_idx][ne_class]):\n",
        "                        similarity, tp, fp, fn = calc_similarity_between_entities(\n",
        "                            true_bounds, predicted_bounds\n",
        "                        )\n",
        "                        if tp > 0:\n",
        "                            similarity_dict[(idx1, idx2)] = (similarity, tp, fp, fn)\n",
        "                similarity, pairs = find_pairs_of_named_entities(list(range(n1)), list(range(n2)), similarity_dict)\n",
        "                tp_for_ne += sum(map(lambda it: similarity_dict[it][1], pairs))\n",
        "                fp_for_ne += sum(map(lambda it: similarity_dict[it][2], pairs))\n",
        "                fn_for_ne += sum(map(lambda it: similarity_dict[it][3], pairs))\n",
        "                unmatched_std = sorted(list(set(range(n1)) - set(map(lambda it: it[0], pairs))))\n",
        "                for idx1 in unmatched_std:\n",
        "                    fn_for_ne += (true_entities_[sample_idx][ne_class][idx1][1] -\n",
        "                                  true_entities_[sample_idx][ne_class][idx1][0])\n",
        "                unmatched_test = sorted(list(set(range(n2)) - set(map(lambda it: it[1], pairs))))\n",
        "                for idx2 in unmatched_test:\n",
        "                    fp_for_ne += (predicted_entities_[sample_idx][ne_class][idx2][1] -\n",
        "                                  predicted_entities_[sample_idx][ne_class][idx2][0])\n",
        "            elif ne_class in true_entities_[sample_idx]:\n",
        "                for entity_bounds in true_entities_[sample_idx][ne_class]:\n",
        "                    fn_for_ne += (entity_bounds[1] - entity_bounds[0])\n",
        "            elif ne_class in predicted_entities_[sample_idx]:\n",
        "                for entity_bounds in predicted_entities_[sample_idx][ne_class]:\n",
        "                    fp_for_ne += (entity_bounds[1] - entity_bounds[0])\n",
        "        tp_total += tp_for_ne\n",
        "        fp_total += fp_for_ne\n",
        "        fn_total += fn_for_ne\n",
        "        precision_for_ne = tp_for_ne / float(tp_for_ne + fp_for_ne) if tp_for_ne > 0 else 0.0\n",
        "        recall_for_ne = tp_for_ne / float(tp_for_ne + fn_for_ne) if tp_for_ne > 0 else 0.0\n",
        "        if (precision_for_ne + recall_for_ne) > 0.0:\n",
        "            f1_for_ne = 2 * precision_for_ne * recall_for_ne / (precision_for_ne + recall_for_ne)\n",
        "        else:\n",
        "            f1_for_ne = 0.0\n",
        "        quality_by_entity_classes[ne_class] = (f1_for_ne, precision_for_ne, recall_for_ne)\n",
        "    precision = tp_total / float(tp_total + fp_total) if tp_total > 0 else 0.0\n",
        "    recall = tp_total / float(tp_total + fn_total) if tp_total > 0 else 0.0\n",
        "    if (precision + recall) > 0.0:\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "    else:\n",
        "        f1 = 0.0\n",
        "    return f1, precision, recall, quality_by_entity_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5LXi_JH7WAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_similarity_between_entities(gold_entity: Tuple[int, int], predicted_entity: Tuple[int, int]) -> \\\n",
        "        Tuple[float, int, int, int]:\n",
        "    if gold_entity[1] <= predicted_entity[0]:\n",
        "        res = 0.0\n",
        "        tp = 0\n",
        "        fp = predicted_entity[1] - predicted_entity[0]\n",
        "        fn = gold_entity[1] - gold_entity[0]\n",
        "    elif predicted_entity[1] <= gold_entity[0]:\n",
        "        res = 0.0\n",
        "        tp = 0\n",
        "        fp = predicted_entity[1] - predicted_entity[0]\n",
        "        fn = gold_entity[1] - gold_entity[0]\n",
        "    else:\n",
        "        if (gold_entity[0] == predicted_entity[0]) and (gold_entity[1] == predicted_entity[1]):\n",
        "            tp = gold_entity[1] - gold_entity[0]\n",
        "            fp = 0\n",
        "            fn = 0\n",
        "            res = 1.0\n",
        "        elif gold_entity[0] == predicted_entity[0]:\n",
        "            if gold_entity[1] > predicted_entity[1]:\n",
        "                tp = predicted_entity[1] - predicted_entity[0]\n",
        "                fp = 0\n",
        "                fn = gold_entity[1] - predicted_entity[1]\n",
        "            else:\n",
        "                tp = gold_entity[1] - gold_entity[0]\n",
        "                fp = predicted_entity[1] - gold_entity[1]\n",
        "                fn = 0\n",
        "            res = tp / float(tp + fp + fn)\n",
        "        elif gold_entity[1] == predicted_entity[1]:\n",
        "            if gold_entity[0] < predicted_entity[0]:\n",
        "                tp = predicted_entity[1] - predicted_entity[0]\n",
        "                fp = 0\n",
        "                fn = predicted_entity[0] - gold_entity[0]\n",
        "            else:\n",
        "                tp = gold_entity[1] - gold_entity[0]\n",
        "                fp = gold_entity[0] - predicted_entity[0]\n",
        "                fn = 0\n",
        "            res = tp / float(tp + fp + fn)\n",
        "        elif gold_entity[0] < predicted_entity[0]:\n",
        "            if gold_entity[1] > predicted_entity[1]:\n",
        "                tp = predicted_entity[1] - predicted_entity[0]\n",
        "                fp = 0\n",
        "                fn = (predicted_entity[0] - gold_entity[0]) + (gold_entity[1] - predicted_entity[1])\n",
        "            else:\n",
        "                tp = gold_entity[1] - predicted_entity[0]\n",
        "                fp = predicted_entity[1] - gold_entity[1]\n",
        "                fn = predicted_entity[0] - gold_entity[0]\n",
        "            res = tp / float(tp + fp + fn)\n",
        "        else:\n",
        "            if gold_entity[1] < predicted_entity[1]:\n",
        "                tp = gold_entity[1] - gold_entity[0]\n",
        "                fp = (gold_entity[0] - predicted_entity[0]) + (predicted_entity[1] - gold_entity[1])\n",
        "                fn = 0\n",
        "            else:\n",
        "                tp = predicted_entity[1] - gold_entity[0]\n",
        "                fp = gold_entity[0] - predicted_entity[0]\n",
        "                fn = gold_entity[1] - predicted_entity[1]\n",
        "            res = tp / float(tp + fp + fn)\n",
        "    return res, tp, fp, fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvjrgeLXJu0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_pairs_of_named_entities(true_entities: List[int], predicted_entities: List[int],\n",
        "                                 similarity_dict: Dict[Tuple[int, int], Tuple[float, int, int, int]]) -> \\\n",
        "        Tuple[float, List[Tuple[int, int]]]:\n",
        "    best_similarity_sum = 0.0\n",
        "    n_true = len(true_entities)\n",
        "    n_predicted = len(predicted_entities)\n",
        "    best_pairs = []\n",
        "    if n_true == n_predicted:\n",
        "        best_pairs = list(filter(lambda it1: it1 in similarity_dict, map(lambda it2: (it2, it2), range(n_true))))\n",
        "        best_similarity_sum = sum(map(lambda it: similarity_dict[it][0], best_pairs))\n",
        "    else:\n",
        "        N_MAX_COMB = 10\n",
        "        counter = 1\n",
        "        if n_true < n_predicted:\n",
        "            for c in comb(n_predicted, n_true):\n",
        "                pairs = list(filter(\n",
        "                    lambda it1: it1 in similarity_dict,\n",
        "                    map(lambda it2: (it2, c[it2]), range(n_true))\n",
        "                ))\n",
        "                if len(pairs) > 0:\n",
        "                    similarity_sum = sum(map(lambda it: similarity_dict[it][0], pairs))\n",
        "                else:\n",
        "                    similarity_sum = 0.0\n",
        "                if similarity_sum > best_similarity_sum:\n",
        "                    best_similarity_sum = similarity_sum\n",
        "                    best_pairs = copy.deepcopy(pairs)\n",
        "                del pairs\n",
        "                counter += 1\n",
        "                if counter > N_MAX_COMB:\n",
        "                    break\n",
        "            pairs = []\n",
        "            used_indices = set()\n",
        "            for true_idx in range(n_true):\n",
        "                best_pred_idx = None\n",
        "                best_similarity = -1.0\n",
        "                for pred_idx in filter(lambda it: it not in used_indices, range(n_predicted)):\n",
        "                    pair_candidate = (true_idx, pred_idx)\n",
        "                    if pair_candidate in similarity_dict:\n",
        "                        if similarity_dict[pair_candidate][0] > best_similarity:\n",
        "                            best_similarity = similarity_dict[pair_candidate][0]\n",
        "                            best_pred_idx = pred_idx\n",
        "                if best_pred_idx is None:\n",
        "                    break\n",
        "                used_indices.add(best_pred_idx)\n",
        "                pairs.append((true_idx, best_pred_idx))\n",
        "            if len(pairs) > 0:\n",
        "                similarity_sum = sum(map(lambda it: similarity_dict[it][0], pairs))\n",
        "            else:\n",
        "                similarity_sum = 0.0\n",
        "            if similarity_sum > best_similarity_sum:\n",
        "                best_similarity_sum = similarity_sum\n",
        "                best_pairs = copy.deepcopy(pairs)\n",
        "            del pairs\n",
        "            del used_indices\n",
        "        else:\n",
        "            for c in comb(n_true, n_predicted):\n",
        "                pairs = list(filter(\n",
        "                    lambda it1: it1 in similarity_dict,\n",
        "                    map(lambda it2: (c[it2], it2), range(n_predicted))\n",
        "                ))\n",
        "                if len(pairs) > 0:\n",
        "                    similarity_sum = sum(map(lambda it: similarity_dict[it][0], pairs))\n",
        "                else:\n",
        "                    similarity_sum = 0.0\n",
        "                if similarity_sum > best_similarity_sum:\n",
        "                    best_similarity_sum = similarity_sum\n",
        "                    best_pairs = copy.deepcopy(pairs)\n",
        "                del pairs\n",
        "                counter += 1\n",
        "                if counter > N_MAX_COMB:\n",
        "                    break\n",
        "            pairs = []\n",
        "            used_indices = set()\n",
        "            for pred_idx in range(n_predicted):\n",
        "                best_true_idx = None\n",
        "                best_similarity = -1.0\n",
        "                for true_idx in filter(lambda it: it not in used_indices, range(n_true)):\n",
        "                    pair_candidate = (true_idx, pred_idx)\n",
        "                    if pair_candidate in similarity_dict:\n",
        "                        if similarity_dict[pair_candidate][0] > best_similarity:\n",
        "                            best_similarity = similarity_dict[pair_candidate][0]\n",
        "                            best_true_idx = true_idx\n",
        "                if best_true_idx is None:\n",
        "                    break\n",
        "                used_indices.add(best_true_idx)\n",
        "                pairs.append((best_true_idx, pred_idx))\n",
        "            if len(pairs) > 0:\n",
        "                similarity_sum = sum(map(lambda it: similarity_dict[it][0], pairs))\n",
        "            else:\n",
        "                similarity_sum = 0.0\n",
        "            if similarity_sum > best_similarity_sum:\n",
        "                best_similarity_sum = similarity_sum\n",
        "                best_pairs = copy.deepcopy(pairs)\n",
        "            del pairs\n",
        "            del used_indices\n",
        "    return best_similarity_sum, best_pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHQiOzM-NA3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def comb(n: int, k: int):\n",
        "    d = list(range(0, k))\n",
        "    yield d\n",
        "    while True:\n",
        "        i = k - 1\n",
        "        while i >= 0 and d[i] + k - i + 1 > n:\n",
        "            i -= 1\n",
        "        if i < 0:\n",
        "            return\n",
        "        d[i] += 1\n",
        "        for j in range(i + 1, k):\n",
        "            d[j] = d[j - 1] + 1\n",
        "        yield d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51Y7KYEugElI",
        "colab_type": "code",
        "outputId": "2513eabd-e5b3-4c2e-805d-cbdcbff54ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "recognizer.fit(X, y)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded pre-trained UDPipe model for 'ru' language\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-56e4bdeb5014>:676: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-56e4bdeb5014>:676: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py:2509: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py:2509: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmpe1284mr9elmo_crf.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmpe1284mr9elmo_crf.ckpt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 27min 54s, sys: 57.1 s, total: 28min 51s\n",
            "Wall time: 18min 17s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ELMo_NER(batch_size=16,\n",
              "         elmo_hub_module_handle='http://files.deeppavlov.ai/deeppavlov_data/elmo_ru-news_wmt11-16_1.5M_steps.tar.gz',\n",
              "         finetune_elmo=False, gpu_memory_frac=0.9, l2_reg=0.01, lr=0.01,\n",
              "         max_epochs=1, max_seq_length=200, patience=10, random_seed=42,\n",
              "         udpipe_lang='ru', use_additional_features=False,\n",
              "         validation_fraction=0.25, verbose=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCRFDLL7TQqX",
        "colab_type": "code",
        "outputId": "4bb6f56a-bc04-4422-b38d-a60c2369d124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "factrueval2016_to_json(\"factRuEval-2016-master/testset\", \"factrueval2016testset_to_json.json\")\n",
        "\n",
        "with open(\"factrueval2016testset_to_json.json\", 'r') as fp:\n",
        "  data_for_testing = json.load(fp)\n",
        "\n",
        "_, true_entities = load_dataset_from_json(\"factrueval2016testset_to_json.json\")\n",
        "\n",
        "texts = []\n",
        "additional_info = []\n",
        "for cur_document in data_for_testing:\n",
        "  base_name = os.path.join(\"FactRuEval2016_results/results_of_elmo_and_crf\", cur_document['base_name'] + '.task1')\n",
        "  for cur_paragraph in cur_document['paragraph_bounds']:\n",
        "    texts.append(cur_document['text'][cur_paragraph[0]:cur_paragraph[1]])\n",
        "    additional_info.append((base_name, cur_paragraph))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 604 ms, sys: 44.6 ms, total: 649 ms\n",
            "Wall time: 1.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWSMSSrkTXjD",
        "colab_type": "code",
        "outputId": "0b3fc033-c429-419d-87c4-479aff689f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "predicted_entities = recognizer.predict(texts)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 37min 24s, sys: 40.1 s, total: 38min 4s\n",
            "Wall time: 19min 53s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTNf8hRJYpXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!mkdir FactRuEval2016_results\n",
        "#!mkdir FactRuEval2016_results/results_of_elmo_and_crf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeKxxDjoTdwi",
        "colab_type": "code",
        "outputId": "db17c1e5-2e42-4c05-90e2-06fae753a584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "results_for_factrueval_2016 = dict()\n",
        "for sample_idx, cur_result in enumerate(predicted_entities):\n",
        "    base_name, paragraph_bounds = additional_info[sample_idx]\n",
        "    for entity_type in cur_result:\n",
        "        if entity_type == 'ORG':\n",
        "            prepared_entity_type = 'org'\n",
        "        elif entity_type == 'PERSON':\n",
        "            prepared_entity_type = 'per'\n",
        "        elif entity_type == 'LOCATION':\n",
        "            prepared_entity_type = 'loc'\n",
        "        else:\n",
        "            prepared_entity_type = None\n",
        "        \n",
        "        for entity_bounds in cur_result[entity_type]:\n",
        "            postprocessed_entity = (\n",
        "                prepared_entity_type,\n",
        "                entity_bounds[0] + paragraph_bounds[0],\n",
        "                entity_bounds[1] - entity_bounds[0]\n",
        "                )\n",
        "            if base_name in results_for_factrueval_2016:\n",
        "                results_for_factrueval_2016[base_name].append(postprocessed_entity)\n",
        "            else:\n",
        "                results_for_factrueval_2016[base_name] = [postprocessed_entity]\n",
        "\n",
        "for base_name in results_for_factrueval_2016:\n",
        "    with open(base_name, 'w+') as fp:\n",
        "        for cur_entity in sorted(results_for_factrueval_2016[base_name], key=lambda it: (it[1], it[2], it[0])):\n",
        "            fp.write('{0} {1} {2}\\n'.format(cur_entity[0], cur_entity[1], cur_entity[2]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.2 ms, sys: 8.97 ms, total: 19.1 ms\n",
            "Wall time: 19.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYibMxduQjVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Evaluator:\n",
        "    \"\"\"Response evaluator for the 1st track\"\"\"\n",
        "\n",
        "    def __init__(self, is_locorg_enabled=True):\n",
        "        \"\"\"Create an object with or without the support for locorg objects\"\"\"\n",
        "        self.is_locorg_enabled = is_locorg_enabled\n",
        "        if is_locorg_enabled:\n",
        "            self.tags = ['per', 'loc', 'org', 'locorg', 'overall']\n",
        "        else:\n",
        "            self.tags = ['per', 'loc', 'org', 'overall']\n",
        "\n",
        "        self.metrics_dict = None\n",
        "\n",
        "\n",
        "    def evaluate(self, std_path, test_path, output_path='', is_silent=False):\n",
        "        \"\"\"Run evaluation on all files in the given directories\n",
        "        If output_path is provided, evaluation reports will be written there.\n",
        "        is_silent determines if the result is printed to the output\"\"\"\n",
        "        std = loadAllStandard(std_path)\n",
        "        test = loadAllTest(test_path)\n",
        "\n",
        "        diff = set([x.name for x in std]).symmetric_difference(\n",
        "            set([y.name for y in test]))\n",
        "\n",
        "        if len(diff) > 0:\n",
        "            print('WARNING: missing files:')\n",
        "            print('\\n'.join(sorted(diff, key=lambda x: int(x[5:]))))\n",
        "\n",
        "        std_by_name = dict([(x.name, x) for x in std])\n",
        "        test_by_name = dict([(x.name, x) for x in test])\n",
        "        names = sorted(set([x.name for x in std]).intersection(\n",
        "            set([y.name for y in test])), key=lambda x: int(x[5:]))\n",
        "\n",
        "        res = dict((tag, Metrics()) for tag in self.tags)\n",
        "\n",
        "        for name in names:\n",
        "            s = std_by_name[name]\n",
        "            t = test_by_name[name]\n",
        "            m = self.evaluateDocument(s, t)\n",
        "            self.metrics_dict = dict((x, m[x]) for x in self.tags)\n",
        "            self.printReport(s.name, output_path)\n",
        "            for key in res:\n",
        "                res[key].add(self.metrics_dict[key])\n",
        "            \n",
        "        if not is_silent:\n",
        "            print(self.buildMetricsTable(res))\n",
        "\n",
        "        return res\n",
        "\n",
        "    def evaluateDocument(self, standard, test):\n",
        "        \"\"\"Run evaluation on the given standard and test markup\"\"\"\n",
        "        s = standard.makeTokenSets(self.is_locorg_enabled)\n",
        "        t = test.makeTokenSets(standard, self.is_locorg_enabled)\n",
        "\n",
        "        em = EvaluationMatrix(s, t, TokenSetQualityCalculator())\n",
        "        em.findSolution()\n",
        "        self.em = em\n",
        "\n",
        "        return em.metrics\n",
        "\n",
        "    # Metrics and reports\n",
        "\n",
        "    def buildMetricsTable(self, metrics_dict):\n",
        "        \"\"\"Build a table from the provided metrics for the output\"\"\"\n",
        "        assert(len(metrics_dict.keys()) == len(self.tags))\n",
        "        res = 'Type    ' + Metrics.header()\n",
        "        for tag in self.tags:\n",
        "            res += '\\n{:8} '.format(tag) + metrics_dict[tag].toLine()\n",
        "\n",
        "        return res\n",
        "\n",
        "    def buildReport(self):\n",
        "        \"\"\"Builds a detailed comparison report\"\"\"\n",
        "        res = ''\n",
        "        res += '------STANDARD------\\n'\n",
        "        res += self.em.describeMatchingStd() + '\\n\\n';\n",
        "        res += '--------TEST--------\\n'\n",
        "        res += self.em.describeMatchingTest() + '\\n\\n';\n",
        "        res += '-------METRICS------\\n'\n",
        "        res += self.buildMetricsTable(\n",
        "                self.metrics_dict\n",
        "            )\n",
        "\n",
        "        return res\n",
        "\n",
        "    def printReport(self, name, out_dir):\n",
        "        if len(out_dir) == 0:\n",
        "            return\n",
        "\n",
        "        is_perfect = self.em.metrics['overall'].f1 == 1.0\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "        filename = ('' if is_perfect else '_') +  name + '.report.txt'\n",
        "        with open(os.path.join(out_dir, filename), 'w', encoding='utf-8') as f:\n",
        "            f.write(self.buildReport())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7PhA3j_R5WD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadAllStandard(path):\n",
        "    \"\"\"Load all standard markup files from the provided directory. Returns a list.\"\"\"\n",
        "\n",
        "    names = set([x.split('.')[0] for x in os.listdir(path)])\n",
        "    res = []\n",
        "    for name in names:\n",
        "        if re.match('book_[0-9]+', name) == None:\n",
        "            continue\n",
        "        res.append(Standard(name, path))\n",
        "    \n",
        "    return sorted(res, key=lambda x: int(x.name[5:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLFQsVEqSF73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadAllTest(path):\n",
        "    \"\"\"Load all test markup files from the provided directory. Returns a list\"\"\"\n",
        "    names = set(x.split('.')[0] for x in os.listdir(path) if '.task1' in x)\n",
        "    res = [Test(name, path) for name in names]\n",
        "    \n",
        "    return sorted(res, key=lambda x: int(x.name[5:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kvh4htOSWAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Test:\n",
        "    \"\"\"Test data for the first track\"\"\"\n",
        "    \n",
        "    def __init__(self, name, dir='.'):\n",
        "        \"\"\"Load the data from the given document\n",
        "        \n",
        "        name - file to load the data from (without an extension)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.name = name\n",
        "            full_name = os.path.join(dir, name + '.task1')\n",
        "            self.load(full_name)\n",
        "        except Exception as e:\n",
        "            print('Failed to load \"{}\"'.format(full_name))\n",
        "            print(e)\n",
        "    \n",
        "\n",
        "    def load(self, filename):\n",
        "        \"\"\"Do the exception-prone loading\"\"\"\n",
        "        \n",
        "        # set the allowed tags for later\n",
        "        self.allowed_tags = set(['org', 'per', 'loc', 'locorg'])\n",
        "            \n",
        "        self.mentions = {}\n",
        "        for tag in self.allowed_tags:\n",
        "            self.mentions[tag] = []\n",
        "            \n",
        "        # read the file that should consist of lines like\n",
        "        # [TAG] [START_SYMBOL_INDEX] [LENGTH]\n",
        "        with safeOpen(filename) as f:\n",
        "            r = csv.reader(f, delimiter=' ', quotechar=Config.QUOTECHAR)\n",
        "            for index, parts in enumerate(r):\n",
        "                # skip the empty lines\n",
        "                if len(parts) == 0:\n",
        "                    continue\n",
        "                    \n",
        "                try:\n",
        "                    assert(len(parts) == 3)\n",
        "                    tag = normalize(parts[0])\n",
        "                    assert(tag in self.allowed_tags)\n",
        "                    self.mentions[tag].append(Interval(*parts[1:]))\n",
        "                except Exception as e:\n",
        "                    line_descr = '[{}] [START_SYMBOL_INDEX] [LENGTH]'.format(\n",
        "                                '/'.join(self.allowed_tags))\n",
        "                    raise Exception(\n",
        "                        'Error: \"{}\", line {}.\\nExpected: {}\\nReceived: {}\\nDetails: {}'.format(\n",
        "                            filename, index, line_descr, ' '.join(parts), str(e)))\n",
        "                    \n",
        "                    \n",
        "    def makeTokenSets(self, standard, is_locorg_allowed=True):\n",
        "        \"\"\"Create a dictionary of typed TokenSet objects corresponding to the mentions,\n",
        "        using the provided standard data to tokenize the intervals\"\"\"\n",
        "        \n",
        "        res = []\n",
        "        for key in self.allowed_tags:\n",
        "            for interval in self.mentions[key]:\n",
        "                ts = TokenSet([token\n",
        "                              for token in standard.tokens\n",
        "                                  if token.start >= interval.start\n",
        "                                      and token.end <= interval.end\n",
        "                                      and not token.isIgnored()],\n",
        "                             key, standard.text)\n",
        "\n",
        "                # save the interval within the token set\n",
        "                # to display it as-is in future\n",
        "                ts.interval = interval\n",
        "\n",
        "                if not is_locorg_allowed and key == 'locorg':\n",
        "                    ts.tag = 'loc'\n",
        "                res.append(ts)\n",
        "        \n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUfxesTVSktP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Metrics:\n",
        "    \"\"\"Commonly used evaluation metrics\"\"\"\n",
        "    \n",
        "    header_template = '{:8} {:8} {:8} {:8} {:8} {:8} {:8}'\n",
        "    line_template = '{:8.4f} {:8.4f} {:8.4f} {:8.2f} {:8.2f} {:8.0f} {:8.0f}'\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the empty metrics object\"\"\"\n",
        "        # True positive used in recall calculation\n",
        "        self.tp_std = 0.0\n",
        "        # True positive used in precision calculation\n",
        "        self.tp_test = 0.0\n",
        "        # Number of standard objects\n",
        "        self.n_std = 0\n",
        "        # Number of test objects\n",
        "        self.n_test = 0\n",
        "        # Precision\n",
        "        self.precision = 1.0\n",
        "        # Recall\n",
        "        self.recall = 1.0\n",
        "        # F1\n",
        "        self.f1 = 1.0\n",
        "\n",
        "    def recalculate(self):\n",
        "        self.precision = self.tp_test / self.n_test if self.n_test > 0 else 1.0\n",
        "        self.recall = self.tp_std / self.n_std if self.n_std > 0 else 1.0\n",
        "\n",
        "        if self.n_std + self.n_test == 0:\n",
        "            self.f1 = 1.0\n",
        "        else:\n",
        "            denominator = self.precision + self.recall\n",
        "            self.f1  = (\n",
        "                (2 * self.precision * self.recall / denominator)\n",
        "                    if denominator > 0 else 0.0\n",
        "            )\n",
        "\n",
        "        isValid = lambda x: x >= 0 and x <= 1\n",
        "        assert(isValid(self.precision))\n",
        "        assert(isValid(self.recall))\n",
        "        assert(isValid(self.f1))\n",
        "\n",
        "    def add(self, other):\n",
        "        self.tp_std += other.tp_std\n",
        "        self.tp_test += other.tp_test\n",
        "        self.n_std += other.n_std\n",
        "        self.n_test += other.n_test\n",
        "        self.recalculate()\n",
        "\n",
        "    def toLine(self):\n",
        "        \"\"\"Returns a line for the stats table\"\"\"\n",
        "        return Metrics.line_template.format(\n",
        "            self.precision, self.recall, self.f1,\n",
        "            self.tp_std, self.tp_test, self.n_std, self.n_test)\n",
        "\n",
        "    @classmethod\n",
        "    def header(cls):\n",
        "        \"\"\"Returns a header for the stats table\"\"\"\n",
        "        return Metrics.header_template.format(\n",
        "            'P', 'R', 'F1', 'TP1', 'TP2', 'In Std.', 'In Test.')\n",
        "\n",
        "    @classmethod\n",
        "    def createSimple(cls, tp, n_std, n_test):\n",
        "        \"\"\"Calculate metrics with single TruePositive value\"\"\"\n",
        "        m = cls()\n",
        "\n",
        "        m.tp_std = tp\n",
        "        m.tp_test = tp\n",
        "        m.n_std = n_std\n",
        "        m.n_test = n_test\n",
        "\n",
        "        m.recalculate()\n",
        "\n",
        "        return m\n",
        "    \n",
        "    @classmethod\n",
        "    def create(cls, tp_std, tp_test, n_std, n_test):\n",
        "        \"\"\"Calculate metrics with separate TruePositive values\"\"\"\n",
        "        m = cls()\n",
        "\n",
        "        m.tp_std = tp_std\n",
        "        m.tp_test = tp_test\n",
        "        m.n_std = n_std\n",
        "        m.n_test = n_test\n",
        "\n",
        "        m.recalculate()\n",
        "\n",
        "        return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OcYeFpEV62C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Standard:\n",
        "    \"\"\"Standard document data loaded from a set of export files.\n",
        "    \n",
        "    The set currently includes:\n",
        "     - 'NAME.txt'\n",
        "     - 'NAME.tokens'\n",
        "     - 'NAME.spans'\n",
        "     - 'NAME.objects'\n",
        "     - 'NAME.coref'\n",
        "     - 'NAME.facts'\n",
        "     \"\"\"\n",
        "    \n",
        "    def __init__(self, name, path='.'):\n",
        "        self.name = name\n",
        "        try:\n",
        "            self.has_coref = True\n",
        "            self.has_facts = True\n",
        "            full_name = os.path.join(path, name)\n",
        "            self.loadText(full_name + '.txt')\n",
        "            self.loadTokens(full_name + '.tokens')\n",
        "            self.loadSpans(full_name + '.spans')\n",
        "            self.loadMentions(full_name + '.objects')\n",
        "            self.loadCoreference(full_name + '.coref')\n",
        "            self.loadFacts(full_name + '.facts')\n",
        "        except Exception as e:\n",
        "            print('Failed to load the standard of {}:'.format(name))\n",
        "            print(e)\n",
        "            # reset the document so it has no impact on the comparison\n",
        "            self.mentions = []\n",
        "            self.entities = []\n",
        "            self.facts = []\n",
        "    \n",
        "    def loadTokens(self, filename):\n",
        "        \"\"\"Load the data from a file with the provided name\n",
        "        \n",
        "        Raw token data should be loaded from one of the system export '.tokens' file\"\"\"\n",
        "        self.tokens = []\n",
        "        \n",
        "        with open(filename, 'r', encoding='utf-8') as f:\n",
        "            rdr = csv.reader(f, delimiter=Config.DEFAULT_DELIMITER, quotechar=Config.QUOTECHAR)\n",
        "            \n",
        "            for index, line in enumerate(rdr):\n",
        "                if len(line) == 0:\n",
        "                    # skip the empty lines\n",
        "                    continue\n",
        "                \n",
        "                if len(line) != Config.TOKEN_LINE_LENGTH:\n",
        "                    # bad non-empty line\n",
        "                    raise Exception(\n",
        "                        'Wrong length in line {} of file {}'.format(\n",
        "                            index, filename))\n",
        "                \n",
        "                self.tokens.append(\n",
        "                    Token(*line) )\n",
        "\n",
        "        # fill the token dictionary\n",
        "        self._token_dict = dict([(x.id, x) for x in self.tokens])\n",
        "        \n",
        "        # set neighboor links in tokens\n",
        "        self.tokens = sorted(self.tokens, key=lambda x: x.start)\n",
        "        for i, token in enumerate(self.tokens):\n",
        "            if i != 0:\n",
        "                token.prev = self.tokens[i-1]\n",
        "            if i != len(self.tokens)-1:\n",
        "                token.next = self.tokens[i+1]\n",
        "\n",
        "                \n",
        "    def loadSpans(self, filename):\n",
        "        \"\"\"Load the data from a file with the provided name\n",
        "        \n",
        "        Raw span data should be loaded from one of the system export '.spans' file\n",
        "        \n",
        "        Expected format:\n",
        "        line = <left> SPAN_FILE_SEPARATOR <right>\n",
        "        left = <span_id> <tag_name> <start_pos> <nchars> <start_token> <ntokens>\n",
        "        right ::= [ <token>]+ [ <token_text>]+     // <ntokens> of each\n",
        "            \"\"\"\n",
        "        self.spans = []\n",
        "        \n",
        "        with open(filename, 'r', encoding='utf-8') as f:\n",
        "            for index, line in enumerate(f):\n",
        "                if len(line) == 0:\n",
        "                    # skip the empty lines\n",
        "                    continue\n",
        "                \n",
        "                parts = line.split(Config.SPAN_FILE_SEPARATOR)\n",
        "                if len(parts) != 2:\n",
        "                    # bad non-empty line\n",
        "                    raise Exception(\n",
        "                        'Expected symbol \"{}\" missing in line {} of file {}'.format(\n",
        "                            Config.SPAN_FILE_SEPARATOR, index, filename))\n",
        "                    \n",
        "                left = parts[0]\n",
        "                right = parts[1]\n",
        "                \n",
        "                filtered_left = [i\n",
        "                     for i in left.split(Config.DEFAULT_DELIMITER)\n",
        "                         if len(i) > 0]\n",
        "                \n",
        "                if len(filtered_left) < 6:\n",
        "                    raise Exception(\n",
        "                        'Missing left parts in line {} of file {}'.format(\n",
        "                            index, filename))\n",
        "                    \n",
        "                new_span = Span(*filtered_left)\n",
        "                \n",
        "                filtered_right = [i\n",
        "                      for i in right.split(Config.DEFAULT_DELIMITER)\n",
        "                            if len(i) > 0]\n",
        "                if len(filtered_right) != 2*new_span.ntokens:\n",
        "                    raise Exception(\n",
        "                        'Missing right parts in line {} of file {}'.format(\n",
        "                            index, filename))\n",
        "                \n",
        "                \n",
        "                token_ids = [x.strip() for x in filtered_right[:new_span.ntokens]]\n",
        "                new_span.tokens = sorted([self._token_dict[x] for x in token_ids],\n",
        "                                         key=lambda x: x.start)\n",
        "                new_span.text = normalize(' '.join(filtered_right[new_span.ntokens:]))\n",
        "                new_span.text = new_span.text.replace('\\n', '')\n",
        "                \n",
        "                self.spans.append(new_span)\n",
        "                \n",
        "        # fill the span dictionary\n",
        "        self._span_dict = dict([(x.id, x) for x in self.spans])\n",
        "\n",
        "    def loadMentions(self, filename):\n",
        "        \"\"\"Load the data from a given 'objects' file. Expected format:\n",
        "        \n",
        "        line = <object_id> <type> <span_id> # <comment>\n",
        "        \"\"\"\n",
        "        \n",
        "        self.mentions = []\n",
        "        with open(filename, 'r', encoding='utf-8') as f:\n",
        "            r = csv.reader(f, delimiter=' ', quotechar=Config.QUOTECHAR)\n",
        "            for index, line in enumerate(r):\n",
        "                if Config.COMMENT_SEPARATOR in line:\n",
        "                    comment_index = line.index(Config.COMMENT_SEPARATOR)\n",
        "                    line = line[:comment_index]\n",
        "\n",
        "                if len(line) == 0:\n",
        "                    continue\n",
        "                \n",
        "                if len(line) <= 2:\n",
        "                    raise Exception(\n",
        "                        'Missing spans in object description: line {} of file {}'.format(\n",
        "                            index, filename))\n",
        "                \n",
        "                try:\n",
        "                    mention_id = line[0].strip()\n",
        "                    span_indices = [descr.strip() for descr in line[2:]]\n",
        "                except Exception as e:\n",
        "                    raise Exception('Invalid mention or span id: line {} of file {}:\\n{}'.format(\n",
        "                        index, filename, e))\n",
        "\n",
        "                self.mentions.append(\n",
        "                    Mention(mention_id, line[1], span_indices, self._span_dict))\n",
        "                \n",
        "        # fill the mention dictionary\n",
        "        self._mention_dict = dict([(x.id, x) for x in self.mentions])\n",
        "        for m in self.mentions:\n",
        "            m.findParents(self.mentions)\n",
        "            m.setText(self.text)\n",
        "\n",
        "    def loadCoreference(self, filename):\n",
        "        \"\"\"Load coreference data from the associated file\"\"\"\n",
        "        self.entities = []\n",
        "\n",
        "        try:\n",
        "            open(filename, 'r', encoding='utf-8')\n",
        "        except:\n",
        "            # there are currently some documents with no .coref layer. This is temporary\n",
        "            self.has_coref = False\n",
        "            return\n",
        "        \n",
        "        with open(filename, 'r', encoding='utf-8') as f:\n",
        "            buffer = ''\n",
        "            for raw_line in f:\n",
        "                line = raw_line.strip(' \\t\\n\\r')\n",
        "                if len(line) == 0:\n",
        "                    if len(buffer) > 0:\n",
        "                        e = Entity.fromStandard(buffer, self._mention_dict, self._span_dict)\n",
        "                        self.entities.append(e)\n",
        "                        buffer = ''\n",
        "                else:\n",
        "                    buffer += line + '\\n'\n",
        "                \n",
        "            if len(buffer) > 0:\n",
        "                self.entities.append(Entity.fromStandard(buffer, self._mention_dict, self._span_dict))\n",
        "\n",
        "        self._entity_dict = {}\n",
        "        for ent in self.entities:\n",
        "            self._entity_dict[ent.id] = ent\n",
        "\n",
        "    def loadFacts(self, filename):\n",
        "        \"\"\"Load facts from the associated file\"\"\"\n",
        "        self.facts = []\n",
        "\n",
        "        try:\n",
        "            open(filename, 'r', encoding='utf-8')\n",
        "        except:\n",
        "            # there are currently some documents with no .coref layer. This is temporary\n",
        "            self.has_facts = False\n",
        "            return\n",
        "        \n",
        "        with open(filename, 'r', encoding='utf-8') as f:\n",
        "            buffer = ''\n",
        "            for raw_line in f:\n",
        "                line = raw_line.strip(' \\t\\n\\r')\n",
        "                if len(line) == 0:\n",
        "                    if len(buffer) > 0:\n",
        "                        e = Fact.fromStandard(buffer, self._entity_dict, self._span_dict)\n",
        "                        self.facts.append(e)\n",
        "                        buffer = ''\n",
        "                else:\n",
        "                    buffer += line + '\\n'\n",
        "\n",
        "            if len(buffer) > 0:\n",
        "                self.facts.append(Fact.fromStandard(buffer, self._entity_dict, self._span_dict))\n",
        "\n",
        "        part_of_facts = [f for f in self.facts if f.tag == 'ispartof']\n",
        "        for fact in self.facts:\n",
        "            fact.expandWithIsPartOf(part_of_facts)\n",
        "\n",
        "    def loadText(self, filename):\n",
        "        \"\"\"Load text from the associated text file\"\"\"\n",
        "        with open(filename, 'r', encoding='utf-8') as f:\n",
        "            self.text = safeNormalize(''.join( [line for line in f] ))\n",
        "            \n",
        "    def makeTokenSets(self, is_locorg_allowed=True):\n",
        "        \"\"\"Create a dictionary of typed TokenSet objects corresponding to the mentions\n",
        "        \n",
        "        is_locorg_allowed - enable/disable 'LocOrg' tag\"\"\"\n",
        "        \n",
        "        # determine what tags are allowed\n",
        "        allowed_tags = set(['org', 'per', 'loc'])\n",
        "        if is_locorg_allowed:\n",
        "            allowed_tags.add('locorg')\n",
        "            \n",
        "        res = []\n",
        "        for mention in self.mentions:\n",
        "            key = mention.tag\n",
        "            if key == 'locorg' and not is_locorg_allowed:\n",
        "                key = 'loc'\n",
        "            if not (key in allowed_tags):\n",
        "                continue\n",
        "            ts = TokenSet(\n",
        "                    [x for span in mention.spans for x in span.tokens],\n",
        "                    key, self.text)\n",
        "\n",
        "            ts.id = mention.id\n",
        "\n",
        "            for span in mention.spans:\n",
        "                for token in span.tokens:\n",
        "                    mark = Tables.getMark(ts.tag, span.tag)\n",
        "                    ts.setMark(token, mark)\n",
        "            res.append(ts)\n",
        "\n",
        "        # find and mark embedded objects\n",
        "        for obj in res:\n",
        "            obj.findParents(res)\n",
        "\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97QzSn6yWPOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def safeNormalize(string):\n",
        "    \"\"\"Run a number of normalization operations on the given string.\n",
        "    The string is normalized not in the linguistic sense, but rather in such a way that\n",
        "    captialization, e/ё and quote simbols become irrelevant in comparison\n",
        "    \n",
        "    All unique non-letter chars:  !\"$%()*+,-./0123456789:;<=>?«»–—’“”„•…№\n",
        "    \"\"\"\n",
        "\n",
        "    # force lower case\n",
        "    res = string.lower()\n",
        "\n",
        "    # trim the string\n",
        "    res =  res.strip(' \\r\\n\\t')\n",
        "\n",
        "    # unify all quote symbols\n",
        "    for s in '«»“”„':\n",
        "        res = res.replace(s, '\"')\n",
        "\n",
        "    # unify all single quotes\n",
        "    for s in '’`':\n",
        "        res = res.replace(s, \"'\")\n",
        "\n",
        "    # unify all ё/е\n",
        "    res = res.replace('ё', 'е')\n",
        "\n",
        "    # unify all dashes\n",
        "    for s in '-‐−‒–—―':\n",
        "        res = res.replace(s, '-')\n",
        "\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi0CW-tZWcUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EvaluationMatrix:\n",
        "    \"\"\"Matrix built out of object pair quality that finds an optimal matching\"\"\"\n",
        "\n",
        "    allowed_tags = ['per', 'loc', 'org', 'locorg']\n",
        "\n",
        "    def __init__(self, std, test, calc, mode='regular'):\n",
        "        \"\"\"Initialize the matrix.\n",
        "        \n",
        "        std and test must be lists of objects from standard and test respectively\n",
        "        mode must be either 'regular' or 'simple' and it determines whether locorgs are\n",
        "        matched with orgs and locs or not\n",
        "        calc must be a priority/quality calculator object used in the task at hand\"\"\"\n",
        "\n",
        "        assert(mode == 'regular' or mode == 'simple')\n",
        "        self.mode = mode\n",
        "        self.metrics = {}\n",
        "\n",
        "        self.s = {}\n",
        "        self.t = {}\n",
        "        for tag in EvaluationMatrix.allowed_tags:\n",
        "            self.s[tag] = TagData(tag, std)\n",
        "            self.t[tag] = TagData(tag, test)\n",
        "\n",
        "        # finalize the offsets\n",
        "        for i in range(1, len(EvaluationMatrix.allowed_tags)):\n",
        "            prev_tag = EvaluationMatrix.allowed_tags[i-1]\n",
        "            tag = EvaluationMatrix.allowed_tags[i]\n",
        "            self.s[tag]._start = self.s[prev_tag].end()\n",
        "            self.t[tag]._start = self.t[prev_tag].end()\n",
        "\n",
        "        self.std = []\n",
        "        self.test = []\n",
        "        for tag in EvaluationMatrix.allowed_tags:\n",
        "            self.std.extend(self.s[tag].objects)\n",
        "            self.test.extend(self.t[tag].objects)\n",
        "\n",
        "        self.n_std = len(self.std)\n",
        "        self.n_test = len(self.test)\n",
        "\n",
        "        self.m = np.zeros((self.n_std, self.n_test))\n",
        "        self.calc = calc\n",
        "\n",
        "        for i, x in enumerate(self.std):\n",
        "            for j, y in enumerate(self.test):\n",
        "                self.m[i][j] = self.calc.priority(x, y)\n",
        "\n",
        "    def findSolution(self):\n",
        "        \"\"\"Runs the recursive search to find an optimal matching\"\"\"\n",
        "        \n",
        "        q, pairs = self._recursiveSearch(\n",
        "            [i for i in range(self.n_std)],\n",
        "            [j for j in range(self.n_test)],\n",
        "            []\n",
        "            )\n",
        "\n",
        "        self.metrics['overall'] = self._evaluate(pairs)\n",
        "        for tag in EvaluationMatrix.allowed_tags:\n",
        "            self.metrics[tag] = self._evaluate(pairs, tag)\n",
        "\n",
        "        # save matching data\n",
        "        self.logMatching(pairs)\n",
        "\n",
        "        return pairs\n",
        "\n",
        "    def logMatching(self, pairs):\n",
        "        \"\"\"Saves matching data\"\"\"\n",
        "        self.matching = {}\n",
        "        self.matched_std = []\n",
        "        self.matched_test = []\n",
        "        for i, j in pairs:\n",
        "            s = self.std[i]\n",
        "            t = self.test[j]\n",
        "            self.matching[s] = t\n",
        "            self.matching[t] = s\n",
        "            self.matched_std.append(s)\n",
        "            self.matched_test.append(t)\n",
        "        self.unmatched_std = [s for s in self.std if not s in self.matched_std]\n",
        "        self.unmatched_test = [t for t in self.test if not t in self.matched_test]\n",
        "\n",
        "    def describeMatchingStd(self):\n",
        "        \"\"\"Builds a detailed matching description for standard objects\"\"\"\n",
        "        return self._doDescribeMatching(self.matched_std, self.unmatched_std, False)\n",
        "\n",
        "    def describeMatchingTest(self):\n",
        "        \"\"\"Builds a detailed matching description for test objects\"\"\"\n",
        "        return self._doDescribeMatching(self.matched_test, self.unmatched_test, True)\n",
        "\n",
        "    def _doDescribeMatching(self, matched, unmatched, is_swapped):\n",
        "        \"\"\"Builds a detailed matching description with the given lookup tables\"\"\"\n",
        "        res = ''\n",
        "        for x in matched:\n",
        "            y = self.matching[x]\n",
        "            pair = (y, x) if is_swapped else (x, y)\n",
        "            is_ignored = self.calc.isIgnored(pair[0], pair[1], self.matching)\n",
        "            q = self.calc.quality(*pair)\n",
        "            res += '{}\\t{}\\t=\\t{}\\n'.format('{:7.2f}'.format(q)\n",
        "                                            if not is_ignored\n",
        "                                            else 'IGNORED',\n",
        "                    x.toInlineString(), y.toInlineString())\n",
        "\n",
        "        res += '\\n'\n",
        "        for x in unmatched:\n",
        "            is_ignored = (self.calc.isTestIgnored(x, self.matching)\n",
        "                          if is_swapped\n",
        "                          else self.calc.isStandardIgnored(x, self.matching))\n",
        "            res += '{} {}\\n'.format('{:7.2f}'.format(0.0)\n",
        "                                    if not is_ignored\n",
        "                                    else 'IGNORED',\n",
        "                    x.toInlineString())\n",
        "\n",
        "        return res\n",
        "\n",
        "    def _recursiveSearch(self, std, test, pairs):\n",
        "        \"\"\"\n",
        "            Run a recursive search of the optimal matching.\n",
        "            Returns the following tuple: (overall quality, matching)\n",
        "            std - remaining standard indices list\n",
        "            test - remaining test indices list\n",
        "            pairs - current list of built pairs\n",
        "        \"\"\"\n",
        "        if len(std) == 0 or len(test) == 0:\n",
        "            # final step, evaluate the matching\n",
        "            metrics = self._evaluate(pairs)\n",
        "            return metrics.f1, pairs\n",
        "\n",
        "        curr = std[0]\n",
        "        max_res = None\n",
        "\n",
        "        possible_pairs_count = 0\n",
        "        pair_max_alternatives = 0\n",
        "\n",
        "        options, has_perfect_match = self._findMatches(curr, test)\n",
        "        for t in options:\n",
        "            i = test.index(t)\n",
        "\n",
        "            # let's see what other matching options does this test object have\n",
        "            # this is necessary to check conditions for the logic below\n",
        "            alt_count = 0\n",
        "            skip_test_object = False\n",
        "            for k in std[1:]:\n",
        "                if self.m[k, t] == 1.0 and self.m[curr, t] < 1.0:\n",
        "                    # test objects that have some other perfect matching must be skipped\n",
        "                    skip_test_object = True\n",
        "                if self.m[k, t] != 0.0:\n",
        "                    alt_count += 1\n",
        "                if alt_count > pair_max_alternatives:\n",
        "                    pair_max_alternatives = alt_count\n",
        "                \n",
        "            if skip_test_object:\n",
        "                continue\n",
        "            else:\n",
        "                possible_pairs_count += 1\n",
        "\n",
        "\n",
        "            # try to confirm the pair\n",
        "            res = self._recursiveSearch(\n",
        "                std[1:], test[:i] + test[i+1:],\n",
        "                pairs + [(curr, t)])\n",
        "            if max_res is None or res[0] > max_res[0]:\n",
        "                max_res = res\n",
        "\n",
        "        # check what would happen if this standard object were ignored\n",
        "        # this check is obviously performance-heavy and only necessary under\n",
        "        # these conditions\n",
        "        if (possible_pairs_count == 0\n",
        "                or possible_pairs_count == 1\n",
        "                    and pair_max_alternatives > 0\n",
        "                    and not has_perfect_match):\n",
        "            res = self._recursiveSearch(\n",
        "                std[1:], test,\n",
        "                pairs)\n",
        "            if max_res is None or res[0] > max_res[0]:\n",
        "                max_res = res\n",
        "\n",
        "        return max_res\n",
        "\n",
        "    def _findMatches(self, s_index, test):\n",
        "        \"\"\"Finds a list of possible matches for the standard object with the given index\n",
        "        within the list of available test objects.\n",
        "        \n",
        "        Returns a list of test object indices\n",
        "        \n",
        "        According to the documentation, any perfectly fitting objects MUST be matched\"\"\"\n",
        "        perfect_matches = [t for t in test if self.m[s_index, t] == 1.0]\n",
        "        matches = [t for t in test if self.m[s_index, t] > 0.0] \n",
        "        if len(perfect_matches) > 0:\n",
        "            return perfect_matches, True\n",
        "        else:\n",
        "            return matches, False\n",
        "\n",
        "    def _evaluate(self, pairs, tag_filter = ''):\n",
        "        matched_std = set(self.std[_s] for _s,_t in pairs)\n",
        "        matched_test = set(self.test[_t] for _s,_t in pairs)\n",
        "        \n",
        "        if tag_filter in EvaluationMatrix.allowed_tags:\n",
        "            subset = self._reduce(pairs, tag_filter)\n",
        "        else:\n",
        "            subset = pairs\n",
        "\n",
        "        unmatched_std = [s for s in self.std if not (s in matched_std)]\n",
        "        unmatched_test = [t for t in self.test if not (t in matched_test)]\n",
        "\n",
        "        # unmatched_test must contain all objects of the given tag that were not in ANY\n",
        "        # pair, including cases where a locorg was matched to an loc, for example\n",
        "        if tag_filter in EvaluationMatrix.allowed_tags:\n",
        "            unmatched_std = [s for s in unmatched_std if s.tag == tag_filter]\n",
        "            unmatched_test = [t for t in unmatched_test if t.tag == tag_filter]\n",
        "\n",
        "        # replace indices with actual objects for evaluation\n",
        "        actual_pairs = [(self.std[_s], self.test[_t]) for _s,_t in subset]\n",
        "\n",
        "        return self.calc.evaluate(actual_pairs, unmatched_std, unmatched_test)\n",
        "\n",
        "    def _reduce(self, matching, tag):\n",
        "        \"\"\"Returns a sub-matching corresponding to the given tag\"\"\"\n",
        "        res = []\n",
        "        for _s, _t in matching:\n",
        "            if _s >= self.s[tag].start() and _s < self.s[tag].end():\n",
        "                res.append((_s, _t))\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWGs385NW1rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TokenSetQualityCalculator:\n",
        "    \"\"\"Calculates preliminary and final quality for TokenSet objects\"\"\"\n",
        "\n",
        "    tag_table = {\n",
        "        ('per', 'per') : 1, ('per', 'org') : 0, ('per', 'loc') : 0, ('per', 'locorg') : 0,\n",
        "        ('org', 'per') : 0, ('org', 'org') : 1, ('org', 'loc') : 0, ('org', 'locorg') : 0,\n",
        "        ('loc', 'per') : 0, ('loc', 'org') : 0, ('loc', 'loc') : 1, ('loc', 'locorg') : 0,\n",
        "        ('locorg', 'per') : 0, ('locorg', 'org') : 0, ('locorg', 'loc') : 0, ('locorg', 'locorg') : 1\n",
        "    }\n",
        "\n",
        "    def tagMultiplier(self, s, t):\n",
        "        return TokenSetQualityCalculator.tag_table[(s.tag, t.tag)]\n",
        "    \n",
        "    def evaluate(self, pairs, unmatched_std, unmatched_test):\n",
        "        \"\"\"Evaluate the matching. Returns metrics\"\"\"\n",
        "        matching = {}\n",
        "        for s, t in pairs:\n",
        "            matching[s] = t\n",
        "            matching[t] = s\n",
        "\n",
        "        tp = 0\n",
        "        n_relevant_pairs = 0\n",
        "        matched_std_objects = set()\n",
        "        for s, t in pairs:\n",
        "            if not self.isIgnored(s, t, matching):\n",
        "                tp += self.quality(s, t)\n",
        "                matched_std_objects.add(s)\n",
        "                n_relevant_pairs += 1\n",
        "\n",
        "        # in this task no unmatched test object can be ignored\n",
        "        n_test = n_relevant_pairs + len(unmatched_test)\n",
        "\n",
        "        n_std = n_relevant_pairs\n",
        "        for obj in unmatched_std:\n",
        "            if not obj in matched_std_objects:\n",
        "                if not self.isStandardIgnored(obj, matching):\n",
        "                    n_std += 1\n",
        "\n",
        "        return Metrics.createSimple(tp, n_std, n_test)\n",
        "\n",
        "    def priority(self, s, t):\n",
        "        \"\"\"Calculate preliminary quality that goes into the optimization table\"\"\"\n",
        "        multiplier = self.tagMultiplier(s,t)\n",
        "        if multiplier == 0:\n",
        "            return 0\n",
        "\n",
        "        tp = len(s.tokens.intersection(t.tokens))\n",
        "        fn = len(s.tokens.difference(t.tokens))\n",
        "        fp = len(t.tokens.difference(s.tokens))\n",
        "        \n",
        "        summ = tp + fp + fn\n",
        "        assert(summ > 0)\n",
        "        return multiplier * tp / summ if summ > 0 else 0\n",
        "\n",
        "    def quality(self, s, t):\n",
        "        \"\"\"Calculate final quality that is maximized during the matching optimization\"\"\"\n",
        "        multiplier = self.tagMultiplier(s,t)\n",
        "        if multiplier == 0:\n",
        "            return 0\n",
        "\n",
        "        tokens_tp = s.tokens.intersection(t.tokens)\n",
        "        tokens_fn = s.tokens.difference(t.tokens)\n",
        "        \n",
        "        tp = 0.0\n",
        "        for token in tokens_tp:\n",
        "            tp += s.mark(token) # there can be no punctuation here\n",
        "\n",
        "        fn = 0.0\n",
        "        for token in tokens_fn:\n",
        "            # in case some punctuation did end up in the standard markup somehow\n",
        "            # (which apparently happens)\n",
        "            fn += s.mark(token) if not token.isPunctuation() else 0\n",
        "                \n",
        "        fp = len(t.tokens.difference(s.tokens))\n",
        "        \n",
        "        summ = tp + fp + fn\n",
        "\n",
        "        # summ can be equal to zero in cases when the mention has no 'priority' spans like\n",
        "        # org_name. In these cases, we will just compare the annotations with no weights\n",
        "        return multiplier * tp / summ if summ > 0 else self.priority(s,t)\n",
        "    \n",
        "    def isIgnored(self, s, t, matching):\n",
        "        \"\"\"Check if the matched pair of (s, t) should be ignored within the current\n",
        "        matching\"\"\"\n",
        "\n",
        "\n",
        "        return self.isStandardIgnored(s, matching)\n",
        "\n",
        "    def isStandardIgnored(self, s, matching):\n",
        "        \"\"\"Check if the given standard object should be ignored within the current\n",
        "        matching\"\"\"\n",
        "\n",
        "        # unnamed objects are ignored regardless of their matching status\n",
        "        if s.isUnnamed():\n",
        "            return True\n",
        "        \n",
        "        # embedded objects are ignored regardless of their matching status\n",
        "        if len(s.parents) > 0:\n",
        "            return True\n",
        "\n",
        "        # sibling object processing logic\n",
        "        assert(len(s.siblings) <= 1)\n",
        "        for sibling in s.siblings:\n",
        "#            assert(set([sibling.tag, s.tag]) == set(['org', 'loc']))\n",
        "            if (s in matching) == (sibling in matching):\n",
        "                # when both or neither are matched, ignore the non-organization\n",
        "                # in case of both being organizations, use any of them\n",
        "                if sibling.tag == s.tag:\n",
        "                    if s.is_ignored_sibling:\n",
        "                        return True\n",
        "                    else:\n",
        "                        sibling.is_ignored_sibling = True\n",
        "                        return False\n",
        "                else:\n",
        "                    assert('org' in [sibling.tag, s.tag])\n",
        "                    return s.tag != 'org'\n",
        "            else:\n",
        "                # otherwise ignore the unmatched sibling\n",
        "                return not (s in matching)\n",
        "\n",
        "\n",
        "        return False\n",
        "\n",
        "    def isTestIgnored(self, t, matching):\n",
        "        \"\"\"Check if the given standard object should be ignored within the current\n",
        "        matching\"\"\"\n",
        "\n",
        "        # in this track no test object can be ignored\n",
        "        return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvivXFM3XUFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TagData:\n",
        "    \"\"\"Utility object that contains data regarding a set of objects currently processed\n",
        "    by EvaluationMatrix\"\"\"\n",
        "\n",
        "    def __init__(self, tag, object_list):\n",
        "        \"\"\"Loads an object list with the given tag from the larger object_list\"\"\"\n",
        "        self.tag = tag\n",
        "        self.objects = sorted([x for x in object_list if x.tag == tag],\n",
        "                              key=lambda x: x.id)\n",
        "        self.size = len(self.objects)\n",
        "        self._start = 0\n",
        "\n",
        "    def start(self):\n",
        "        return self._start\n",
        "\n",
        "    def end(self):\n",
        "        return self._start + self.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meTDIi1cY_MG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "    \"\"\"Global configuration\"\"\"\n",
        "    DEFAULT_DELIMITER = ' '\n",
        "    QUOTECHAR = '|'\n",
        "    TOKEN_LINE_LENGTH = 4\n",
        "    SPAN_FILE_SEPARATOR = '  # '\n",
        "    COMMENT_SEPARATOR = '#'\n",
        "    STANDARD_TYPES = {\n",
        "        'Person' : 'per',\n",
        "        'Organization' : 'org',\n",
        "        'Org' : 'org',\n",
        "        'LocOrg' : 'locorg',\n",
        "        'Location' : 'loc',\n",
        "        'Project' : 'project'\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC-uq7kyZLbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Token:\n",
        "    \"\"\"Raw token\"\"\"\n",
        "    \n",
        "    def __init__(self, id, start, length, text):\n",
        "        \"\"\"Create a new token with the given parameters\"\"\"\n",
        "        self.id = id\n",
        "        self.start = int(start)\n",
        "        self.length = int(length)\n",
        "        self.end = self.start + self.length - 1\n",
        "        self.text = normalize(text)\n",
        "        self.next = None\n",
        "        self.prev = None        \n",
        "        \n",
        "    def __repr__(self):\n",
        "        return '{}[{}-{}, #{}]'.format(\n",
        "            self.text, self.start, self.end, self.id)\n",
        "\n",
        "    def __str__(self):\n",
        "        return repr(self)\n",
        "    \n",
        "    def isLetter(self):\n",
        "        \"\"\"Check if this token is a single letter\"\"\"\n",
        "        if len(self.text) > 1:\n",
        "            return False\n",
        "        return self.text.upper() != self.text or self.text.lower() != self.text\n",
        "\n",
        "    def isPunctuation(self):\n",
        "        \"\"\"Check if this token is punctuation. Only checks for a limited amount of\n",
        "        symbols because this method is only called to detect a small amount of special\n",
        "        occasions in standard markup\"\"\"\n",
        "        return len(self.text) == 1 and not self.isLetter()\n",
        "\n",
        "    def isIgnored(self):\n",
        "        \"\"\"Check if this token should be ignored during the comparison.\n",
        "        The comparison is supposed to ignore the punctuation tokens that are(presumably)\n",
        "        located directly next to their neighboors\"\"\"\n",
        "        \n",
        "        return self.length == 1 and not self.isLetter() and (\n",
        "            self.prev != None and self.start - self.prev.end == 1\n",
        "                or self.next != None and self.next.start - self.end == 1)\n",
        "\n",
        "    def isIgnoredFromLeft(self):\n",
        "        \"\"\"Check if this token should be ignored during the comparison. In this case the\n",
        "        token must be directly next to its prev. neighbour\"\"\"\n",
        "        return self.length == 1 and not self.isLetter() and (\n",
        "            self.prev != None and self.start - self.prev.end == 1)\n",
        "\n",
        "    def isIgnoredFromRight(self):\n",
        "        \"\"\"Check if this token should be ignored during the comparison. In this case the\n",
        "        token must be directly next to its next. neighbour\"\"\"\n",
        "        return self.length == 1 and not self.isLetter() and (\n",
        "            self.next != None and self.next.start - self.end == 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2Xt0bPbZQgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(string):\n",
        "    \"\"\"Run a number of normalization operations on the given string.\n",
        "    The string is normalized not in the linguistic sense, but rather in such a way that\n",
        "    captialization, e/ё and quote simbols become irrelevant in comparison\n",
        "    \n",
        "    Unlike safeNormalize, this function also attempts to get rid of extra spaces before\n",
        "    punctuation\"\"\"\n",
        "\n",
        "    res = safeNormalize(string)\n",
        "\n",
        "    # in standard strings are generated from tokens, and sometimes have 1 extra space\n",
        "    # before or after puntuation symbols\n",
        "\n",
        "    res = res.replace(' ,', ',')\n",
        "    res = res.replace(' .', '.')\n",
        "    res = res.replace(' -', '-')\n",
        "    res = res.replace('- ', '-')\n",
        "\n",
        "    res = res.replace('( ', '(')\n",
        "    res = res.replace(' )', ')')\n",
        "\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXvK41kEZd2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Span:\n",
        "    \"\"\"Raw span\"\"\"\n",
        "    \n",
        "    def __init__(self, id, tag, start, nchars, token_start, ntokens):\n",
        "        \"\"\"Create a new span with the given parameters\"\"\"\n",
        "        self.id = id\n",
        "        self.tag = tag\n",
        "        \n",
        "        self.start = int(start)\n",
        "        self.end = int(start) + int(nchars)\n",
        "        \n",
        "        self.token_start = int(token_start)\n",
        "        self.ntokens = int(ntokens)\n",
        "        \n",
        "        self.tokens = []\n",
        "        self.text = ''\n",
        "\n",
        "    def isInQuotes(self):\n",
        "        \"\"\"Check if the span is preceded by an opening quote and succeeded by a closing\n",
        "        one\"\"\"\n",
        "\n",
        "        lq = self.getLeftQuote()\n",
        "        rq = self.getRightQuote()\n",
        "\n",
        "        return (lq + rq) in ['\"\"', \"''\", '«»']\n",
        "\n",
        "        return self.getLeftQuote() != '' and self.getLeftQuote() == self.getRightQuote()\n",
        "\n",
        "    def getLeftQuote(self):\n",
        "        \"\"\"Find and return quote preceding the span. If there is no quote, returns ''\"\"\"\n",
        "        # tokens are always sorted\n",
        "        assert(len(self.tokens) > 0)\n",
        "        prev = self.tokens[0].prev\n",
        "        if prev != None and prev.text in ['\"', \"'\", \"«\"]:\n",
        "            return prev.text\n",
        "        else:\n",
        "            return ''\n",
        "\n",
        "    def getRightQuote(self):\n",
        "        \"\"\"Find and return quote succeeding the span. If there is no quote, returns ''\"\"\"\n",
        "        # tokens are always sorted\n",
        "        assert(len(self.tokens) > 0)\n",
        "        next = self.tokens[-1].next\n",
        "        if next != None and next.text in ['\"', \"'\", \"»\"]:\n",
        "            return next.text\n",
        "        else:\n",
        "            return ''\n",
        "\n",
        "        \n",
        "    def __repr__(self):\n",
        "        return '{}[{} #{}],  ntokens={}'.format(\n",
        "            self.text, self.tag, self.id, self.ntokens)\n",
        "\n",
        "    def __str__(self):\n",
        "        return repr(self)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6H1uc0TZtl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mention:\n",
        "    \"\"\"Mention consisting of spans\"\"\"\n",
        "    \n",
        "    def __init__(self, id, tag, span_ids, span_dict):\n",
        "        \"\"\"Create a new mention of a given type with the provided spans\"\"\"\n",
        "        self.id = id\n",
        "        self.parents = []\n",
        "        \n",
        "        if not tag in Config.STANDARD_TYPES:\n",
        "            raise Exception('Unknown mention tag: {}'.format(tag))\n",
        "        self.tag = Config.STANDARD_TYPES[tag]\n",
        "        \n",
        "        self.spans = []\n",
        "        self.text = ''\n",
        "        self.interval_text = ''\n",
        "        for id in span_ids:\n",
        "            self.spans.append(span_dict[id])\n",
        "        \n",
        "    def __repr__(self):\n",
        "        res = '{} #{}:\\n'.format(self.tag, self.id)\n",
        "        for span in self.spans:\n",
        "            res += '\\t{} : {}\\n'.format(span.tag, span.text)\n",
        "        res += '\\n'\n",
        "        return res\n",
        "\n",
        "    def isGeoAdj(self):\n",
        "        \"\"\"Checks if the mention only has geo_adj spans\"\"\"\n",
        "        non_geo_adj = [s for s in self.spans if s.tag != 'geo_adj']\n",
        "        return len(non_geo_adj) == 0\n",
        "\n",
        "    def isDescr(self):\n",
        "        \"\"\"Checks if the mention only has descriptor spans\"\"\"\n",
        "        non_descr = [s for s in self.spans if 'descr' not in s.tag]\n",
        "        return len(non_descr) == 0\n",
        "\n",
        "    def findParents(self, mentions):\n",
        "        \"\"\"Scans the given mention list for mentions embedding this one\"\"\"\n",
        "        self.parents = []\n",
        "        for m in [x for x in mentions if x.tag in Tables.PARENT_TAGS[self.tag]]:\n",
        "            s_int = self.toInterval()\n",
        "            m_int = m.toInterval()\n",
        "            if s_int.isIn(m_int):\n",
        "                self.parents.append(m)\n",
        "            else:\n",
        "                # organizations have priority over equally sized people and locations\n",
        "                if self.tag in ['per', 'loc'] and m.tag=='org' and s_int.isEqual(m_int):\n",
        "                    self.parents.append(m)\n",
        "\n",
        "    def toInterval(self):\n",
        "        assert(len(self.spans) > 0)\n",
        "        by_start = sorted(self.spans, key=lambda x: x.start)\n",
        "        by_end = sorted(self.spans, key=lambda x: x.end)\n",
        "        start = by_start[0].start\n",
        "        length = by_end[-1].end - by_start[0].start + 1\n",
        "        return Interval(start, length)\n",
        "\n",
        "    def setText(self, documentText):\n",
        "        \"\"\"Sets the text from the document corresponding to the mention\"\"\"\n",
        "        ts = TokenSet([t for s in self.spans for t in s.tokens], self.tag, documentText)\n",
        "        self.text = ' '.join([t.text for t in ts.sortedTokens()])\n",
        "        interval = ts.toInterval()\n",
        "        self.interval_text = documentText[interval.start:interval.end]\n",
        "\n",
        "    def __str__(self):\n",
        "        return repr(self)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa56lcSBZwxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Tables:\n",
        "    \"\"\"Tables with error weights\"\"\"\n",
        "\n",
        "    def getMark(mention_tag, span_tag, dfl_value = 0):\n",
        "        \"\"\"Lookup error weight of the provided pair.\n",
        "        \n",
        "        Returns default value if the pair is not in QUALITY table\"\"\"\n",
        "        if mention_tag in Tables.QUALITY and span_tag in Tables.QUALITY[mention_tag]:\n",
        "            return Tables.QUALITY[mention_tag][span_tag]\n",
        "        else:\n",
        "            return dfl_value\n",
        "\n",
        "    def getArgumentWeight(tag):\n",
        "        \"\"\"Lookup the given argument weight\"\"\"\n",
        "\n",
        "        if tag in Tables.ARG_WEIGHTS:\n",
        "            return Tables.ARG_WEIGHTS[tag]\n",
        "        else:\n",
        "            return 1.0\n",
        "\n",
        "    ARG_WEIGHTS = {\n",
        "        'position' : 0.5,\n",
        "        'фаза' : 0.5\n",
        "        }\n",
        "\n",
        "    # this table specifies weights of various spans in mention evaluation\n",
        "    QUALITY = {\n",
        "        'locorg' : {\n",
        "            'none' : 1,\n",
        "#            'loc_descr' : 1,\n",
        "            'org_name' : 1,\n",
        "#            'org_descr' : 1,\n",
        "#            'loc_descr' : 1,\n",
        "            'loc_name' : 1\n",
        "        },\n",
        "\n",
        "        'loc' : {\n",
        "            'none' : 1,\n",
        "#            'name' : 1,\n",
        "#            'org_descr' : 1,\n",
        "            'org_name' : 1,\n",
        "#            'loc_descr' : 1,\n",
        "#            'surname' : 1,\n",
        "            'loc_name' : 1,\n",
        "#            'nickname' : 1\n",
        "        },\n",
        "\n",
        "        'org' : {\n",
        "            'none' : 1,\n",
        "#            'org_descr' : 1,\n",
        "#            'surname' : 1,\n",
        "            'loc_name' : 1,\n",
        "#            'loc_descr' : 1,\n",
        "            'org_name' : 1,\n",
        "#            'job' : 1\n",
        "        },\n",
        "\n",
        "        'per' : {\n",
        "            'none' : 1,\n",
        "            'name' : 1,\n",
        "            'patronymic' : 1,\n",
        "            'nickname' : 1,\n",
        "            'surname' : 1\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # This table describes rules for mention and tokenset embedding, e.g.\n",
        "    # mentions with tag KEY can be embedded in mentions with tag VALUE\n",
        "    PARENT_TAGS = {\n",
        "        'per' : ['loc', 'org', 'locorg'],\n",
        "        'loc' : ['loc', 'org', 'locorg'],\n",
        "        'org' : ['org', 'locorg'],\n",
        "        'locorg' : ['org', 'locorg'],\n",
        "        'project' : ['org', 'locorg']\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9iQmukzaISH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def safeOpen(filename):\n",
        "    \"\"\"Open a utf-8 file with or without BOM in read mode\"\"\"\n",
        "    for enc in ['utf-8-sig', 'utf-8']:\n",
        "        try:\n",
        "            f = open(filename, 'r', encoding=enc)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            f = None\n",
        "\n",
        "        if f != None:\n",
        "            return f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8R5dBIMaSoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Interval:\n",
        "    \"\"\"Text interval\"\"\"\n",
        "    \n",
        "    def __init__(self, start, length):\n",
        "        \"\"\"Create an interval with the given starting position and length.\"\"\"\n",
        "        self.start = int(start)\n",
        "        self.length = int(length)\n",
        "        self.end = self.start + self.length - 1\n",
        "        \n",
        "    def isEqual(self, other):\n",
        "        \"\"\"Check if this interval is equal to the other one\"\"\"\n",
        "        return self.start == other.start and self.end == other.end\n",
        "\n",
        "    def isIn(self, other):\n",
        "        \"\"\"Check if this interval lies within the other one (but not equal)\"\"\"\n",
        "        return (self.start >= other.start\n",
        "                and self.end <= other.end\n",
        "                and not self.isEqual(other))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '<{}; {}>'.format(self.start, self.end)\n",
        "\n",
        "    def __str__(self):\n",
        "        return repr(self)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf5EM1OEacjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TokenSet:\n",
        "    \"\"\"A set of tokens corresponding to an object\"\"\"\n",
        "    \n",
        "    def __init__(self, token_list, tag, text):\n",
        "        self.id = -1\n",
        "        self.tokens = set(token_list)\n",
        "        self.tag = tag\n",
        "        self.parents = []\n",
        "        self.interval = None\n",
        "        self._span_marks = dict([(x, 0) for x in self.tokens])\n",
        "        self.text = text\n",
        "        self.is_ignored_sibling = False\n",
        "        \n",
        "    def __repr__(self):\n",
        "        return '<' + ' '.join([repr(x) for x in self.sortedTokens()]) + '>'\n",
        "\n",
        "    def __str__(self):\n",
        "        return repr(self)\n",
        "\n",
        "    def sortedTokens(self):\n",
        "        \"\"\"Make a list of tokens sorted by their starting position\"\"\"\n",
        "        return sorted(self.tokens, key=lambda x: x.start)\n",
        "    \n",
        "    def getHoles(self):\n",
        "        \"\"\"Return tokens not present in the set but located between\n",
        "        the included tokens in the text\"\"\"\n",
        "        \n",
        "        res = []\n",
        "        for i, token in enumerate(self.sortedTokens()):\n",
        "            if i != len(self.tokens) - 1:\n",
        "                t = token.next\n",
        "                hole = []\n",
        "                while not t in self.tokens:\n",
        "                    hole.append(t)\n",
        "                    t = t.next\n",
        "                if len(hole) > 0:\n",
        "                    res.append(hole)\n",
        "        return res\n",
        "    \n",
        "    def intersects(self, other):\n",
        "        \"\"\"Check for an intersection with the other TokenSet\"\"\"\n",
        "        return len(self.tokens.intersection(other.tokens)) > 0\n",
        "    \n",
        "    def toInterval(self):\n",
        "        \"\"\"Create an interval for the response generator\"\"\"\n",
        "        if self.interval != None:\n",
        "            return self.interval\n",
        "\n",
        "        t = self.sortedTokens()\n",
        "        \n",
        "        # try to include quotes on the left and any punctuation on the right\n",
        "        if len(t) == 0:\n",
        "            print(self)\n",
        "        start_token = t[0]\n",
        "        end_token = t[len(t)-1]\n",
        "        \n",
        "        while start_token.prev != None and start_token.prev.text == '\"':\n",
        "                start_token = start_token.prev\n",
        "        while end_token.next != None and end_token.next.text == '\"':\n",
        "                end_token = end_token.next\n",
        "        \n",
        "        start = start_token.start\n",
        "        end = end_token.end\n",
        "        length = end - start + 1\n",
        "        return Interval(start, length)\n",
        "\n",
        "    def isUnnamed(self):\n",
        "        \"\"\"Returns True if the object is unnamed and must be ignored.\n",
        "        In practice it means that no token of the set is marked with a span of value>0\"\"\"\n",
        "        for key in self._span_marks:\n",
        "            if self._span_marks[key] > 0:\n",
        "                return False\n",
        "        return True\n",
        "        \n",
        "    def mark(self, token):\n",
        "        \"\"\"Return the span mark for this token\"\"\"\n",
        "        if token not in self._span_marks:\n",
        "            return 0\n",
        "        else:\n",
        "            return self._span_marks[token]\n",
        "        \n",
        "    def setMark(self, token, mark):\n",
        "        \"\"\"Try to increase the mark of the given token\"\"\"\n",
        "        if(self._span_marks[token] < mark):\n",
        "            self._span_marks[token] = mark\n",
        "\n",
        "    def isEmbedded(self):\n",
        "        \"\"\"Only true if this object is embedded into another object\"\"\"\n",
        "        return len(self.parents)>0\n",
        "\n",
        "    def findParents(self, all_token_sets):\n",
        "        \"\"\"Fill the parent and sibling lists of the current token set\"\"\"\n",
        "        self.parents = []\n",
        "        self.siblings = []\n",
        "        for other in [x for x in all_token_sets\n",
        "                        if x.tag in Tables.PARENT_TAGS[self.tag]]:\n",
        "            if other is self:\n",
        "                # all_token_sets can include this set as well\n",
        "                continue\n",
        "\n",
        "            if self.tokens < other.tokens:\n",
        "                self.parents.append(other)\n",
        "            elif self.tokens == other.tokens:\n",
        "                self.siblings.append(other)\n",
        "\n",
        "    def toInlineString(self):\n",
        "        \"\"\"Make an inline representation using the tokensets interval\"\"\"\n",
        "        i = self.toInterval()\n",
        "        return (self.tag.upper()\n",
        "                + (' {}'.format(self.id) if self.id != -1 else '')\n",
        "                + ' {} \"{}\"'.format(i, self.text[i.start:i.end+1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0Pm5U4zal5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Entity:\n",
        "    \"\"\"Entity with a set of attributes, assembled from several mentions throughout the\n",
        "    document\"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Create a new object. Do not call this directly, use classmethods instead.\"\"\"\n",
        "        self.attributes = []\n",
        "        self.id = -1\n",
        "        self.tag = 'unknown'\n",
        "        self.spans = []\n",
        "        self.mentions = []\n",
        "        self.is_problematic = False\n",
        "\n",
        "\n",
        "    def processAttributes(self):\n",
        "        \"\"\"Merge attributes with similar names, remove suffixes from the names and create\n",
        "        alternatives\"\"\"\n",
        "        raw_attributes = self.attributes\n",
        "        self.attributes = []\n",
        "        names = set([x.name for x in raw_attributes])\n",
        "        descriptors = []\n",
        "\n",
        "        # Merge all attributes of the same name into alternatives, except descriptors\n",
        "        for name in names:\n",
        "            attr_by_name = [x for x in raw_attributes if x.name == name]\n",
        "            if name.endswith('descr') or name.endswith('descriptor'):\n",
        "                descriptors.extend(attr_by_name)\n",
        "            elif name != 'wikidata':\n",
        "                # wikidata must be ignored for all the tracks\n",
        "                if name == 'name':\n",
        "                    # extend names with qoutes if available\n",
        "                    added_attrs = [x.tryPutInQoutes(self) for x in attr_by_name]\n",
        "                    attr_by_name.extend(x for x in added_attrs if x != None)\n",
        "                self.attributes.append(Attribute.merge(attr_by_name, name))\n",
        "\n",
        "        # Add descriptors to the list of alternatives\n",
        "        if len(descriptors) > 0:\n",
        "            descr = Attribute.merge(descriptors, 'descr')\n",
        "            for attr in self.attributes:\n",
        "                attr.buildAlternatives(descr)\n",
        "\n",
        "        # Trim names ending with digits\n",
        "        for attr in self.attributes:\n",
        "            attr.trimName()\n",
        "\n",
        "\n",
        "    def toInlineString(self):\n",
        "        \"\"\"Creates an inline description of this entity\"\"\"\n",
        "        res = self.tag.upper()\n",
        "        res += ' ' + str(self.id) if self.id != -1 else ''\n",
        "        res += ' [' + ', '.join([str(x) for x in self.attributes]) + ']'\n",
        "\n",
        "        return res\n",
        "\n",
        "\n",
        "    def toTestString(self):\n",
        "        \"\"\"Creates a test representation of this entity\"\"\"\n",
        "        res = self.tag\n",
        "        for attr in self.attributes:\n",
        "            res += '\\n' + attr.toTestString()\n",
        "\n",
        "        return res\n",
        "\n",
        "\n",
        "    def _load_id_line(self, line, mention_dict, span_dict):\n",
        "        \"\"\"Load ids from the first line of the standard representation\"\"\"\n",
        "        str_ids = line.strip(' \\n\\r\\t').split(' ')\n",
        "        self.id = str_ids[0]\n",
        "\n",
        "        self.is_problematic = False\n",
        "        \n",
        "        for _some_id in str_ids[1:]:\n",
        "            some_id = _some_id\n",
        "            if some_id in mention_dict:\n",
        "                assert(not some_id in span_dict)\n",
        "                mention = mention_dict[some_id]\n",
        "                if not mention in self.mentions:\n",
        "                    self.mentions.append(mention)\n",
        "            elif some_id in span_dict:\n",
        "                assert(not some_id in mention_dict)\n",
        "                span = span_dict[some_id]\n",
        "                if not span in self.spans:\n",
        "                    self.spans.append(span)\n",
        "            else:\n",
        "                self.is_problematic = True\n",
        "                print('FOUND PROBLEMATIC ENTITY: {} has no {}'.format(self, some_id))\n",
        "\n",
        "        # it is not actually the case, at least for now\n",
        "        # but arguably it should be\n",
        "        # assert(len(self.mentions) > 0)\n",
        "        \n",
        "        tags = set([x.tag for x in self.mentions])\n",
        "        if len(tags) > 1 and ('locorg' in tags or 'loc' in tags):\n",
        "            # for this task all locorg objects are condidered loc\n",
        "            self.tag = 'loc'\n",
        "        else:\n",
        "            # there can be no other mutlitype entities\n",
        "            assert(len(tags)==1)\n",
        "            self.tag = tags.pop()\n",
        "            \n",
        "            if self.tag == 'locorg':\n",
        "                self.tag = 'loc'\n",
        "\n",
        "\n",
        "    def getAttr(self, name):\n",
        "        \"\"\"Return all values of the attribute with a given name\"\"\"\n",
        "        return [v for attr in self.attributes for v in attr.values if attr.name == name]\n",
        "\n",
        "    def __repr__(self):\n",
        "        res = ''\n",
        "        res += '{} #{}'.format(self.tag, self.id)\n",
        "        for attribute in self.attributes:\n",
        "            res += '\\n  {}'.format(attribute)\n",
        "        return res\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.__repr__()\n",
        "\n",
        "\n",
        "    # static build methods\n",
        "    @classmethod\n",
        "    def fromStandard(cls, text, mention_dict, span_dict):\n",
        "        \"\"\"Load the entity from a block of text of the following format\n",
        "        \n",
        "        [entity_id][ (span_id|mention_id)]+\n",
        "        [attr_name] [attr_value]\n",
        "        ...\n",
        "        [attr_name] [attr_value]\n",
        "        mention_dict - mention_id -> mention\n",
        "        span_dict - span_id -> span\n",
        "        \"\"\"\n",
        "\n",
        "        assert(len(text.strip('\\r\\n\\t ')) > 0)\n",
        "        lines = text.split('\\n')\n",
        "\n",
        "        instance = cls()\n",
        "        for line in lines[1:]:\n",
        "            if len(line) == 0:\n",
        "                continue\n",
        "            instance.attributes.append(Attribute.fromStandard([line]))\n",
        "\n",
        "        instance._load_id_line(lines[0], mention_dict, span_dict)\n",
        "        instance.processAttributes()\n",
        "\n",
        "        return instance\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def fromTest(cls, text):\n",
        "        \"\"\"Load the entity from a test file using a different format:\n",
        "        \n",
        "        [entity_type]\n",
        "        [attr_name]:[attr_value]\n",
        "        ...\n",
        "        [attr_name]:[attr_value]\n",
        "        \"\"\"\n",
        "\n",
        "        assert(len(text.strip('\\r\\n\\t ')) > 0)\n",
        "\n",
        "        instance = cls()\n",
        "\n",
        "        lines = text.split('\\n')\n",
        "        for line in lines[1:]:\n",
        "            if len(line) == 0:\n",
        "                continue\n",
        "            instance.attributes.append(Attribute.fromTest(line))\n",
        "        instance.tag = lines[0].lower().strip(' :\\r\\n\\t')\n",
        "        if instance.tag == 'locorg':\n",
        "            # all locorgs are considered locs for this task\n",
        "            instance.tag = 'loc'\n",
        "\n",
        "        return instance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuU200HHavJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attribute:\n",
        "    \"\"\"Entity attribute with one or several synonimous values\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Create a new object. Do not call this directly, use classmethods instead.\"\"\"\n",
        "        self.name = ''\n",
        "        self.values = set()\n",
        "\n",
        "    def buildAlternatives(self, descr):\n",
        "        \"\"\"Build full alternative list from current values and descriptors.\"\"\"\n",
        "        raw_values = self.values\n",
        "        self.values = set()\n",
        "        for x in raw_values:\n",
        "            for y in descr.values:\n",
        "                self.values.add(x)\n",
        "                if (' ' + y + ' ') in (' ' + x + ' '):\n",
        "                    # for those descriptors already included in a name\n",
        "                    # added spaces to do a full-word search\n",
        "                    continue\n",
        "\n",
        "                self.values.add(x + ' ' + y)\n",
        "                self.values.add(y + ' ' + x)\n",
        "\n",
        "    def tryPutInQoutes(self, entity):\n",
        "        \"\"\"Try to return a copy of this attribute surrounded with quotes.\n",
        "        This must only yield meaningful result if the entity this attribute belongs to\n",
        "        has a span marked as '**_name' surrounded by qoutes\"\"\"\n",
        "\n",
        "        # method must only be called before all other processing\n",
        "        assert(len(self.values) == 1)\n",
        "\n",
        "        if entity.tag == 'per':\n",
        "            return\n",
        "\n",
        "        val = list(self.values)[0]\n",
        "        all_spans = []\n",
        "        all_spans.extend(entity.spans)\n",
        "        for mention in entity.mentions:\n",
        "            all_spans.extend(mention.spans)\n",
        "        name_spans = [x for x in all_spans\n",
        "                      if x.text.lower().replace('ё', 'е') == val and 'name' in x.tag]\n",
        "\n",
        "        for span in name_spans:\n",
        "            if span.isInQuotes():\n",
        "                attr = Attribute()\n",
        "                attr.name = self.name\n",
        "                attr.values.add(span.getLeftQuote() + val + span.getRightQuote())\n",
        "                return attr\n",
        "\n",
        "        return\n",
        "\n",
        "    def trimName(self):\n",
        "        \"\"\"Removes any digits following the attribute name\"\"\"\n",
        "        self.name = self.name.strip('1234567890')\n",
        "        \n",
        "    def matches(self, other):\n",
        "        \"\"\"Returns true if a set of value of other corresponds to a set of values of this\"\"\"\n",
        "        if self.name != other.name:\n",
        "           return False\n",
        "      \n",
        "        for v1 in self.values:\n",
        "            for v2 in other.values:\n",
        "                if compareStrings(v1, v2):\n",
        "                    return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def isValid(self):\n",
        "        \"\"\"Checks if the attribute is valid (has non-empty values)\"\"\"\n",
        "        for value in self.values:\n",
        "            if len(value) > 0:\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def toTestString(self):\n",
        "        \"\"\"Creates a test representation of this attribute\"\"\"\n",
        "        return '\\n'.join(['{} : {}'.format(self.name, x) for x in self.values])\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{} : {}'.format(self.name, ' | '.join( self.values ))\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.__repr__()\n",
        "\n",
        "\n",
        "    # static build methods:\n",
        "    @classmethod\n",
        "    def fromStandard(cls, lines):\n",
        "        \"\"\"Load an attribute from the set of lines representing it.\n",
        "        This method corresponds to the standard format of representation\n",
        "        \n",
        "        Returns a new Attribute instance\"\"\"\n",
        "\n",
        "        assert(len(lines) == 1)\n",
        "\n",
        "        line = lines[0]\n",
        "        parts = line.split(' ')\n",
        "\n",
        "        instance = cls()\n",
        "        instance.name = parts[0].strip().lower()\n",
        "        value = normalize(' '.join(parts[1:]))\n",
        "        instance.values.add(value)\n",
        "\n",
        "        return instance\n",
        "\n",
        "    @classmethod\n",
        "    def fromTest(cls, line):\n",
        "        \"\"\"Load an attribute from the set of lines representing it.\n",
        "        This method corresponds to the test format of representation.\n",
        "        \n",
        "        Returns a new Attribute instance\"\"\"\n",
        "\n",
        "        parts = line.split(':')\n",
        "        assert(len(parts) >= 2)\n",
        "\n",
        "        instance = cls()\n",
        "        instance.name = parts[0].strip().lower()\n",
        "        value = normalize(':'.join(parts[1:]))\n",
        "        instance.values.add(value)\n",
        "\n",
        "        return instance\n",
        "\n",
        "    @classmethod\n",
        "    def merge(cls, attr_list, new_name):\n",
        "        \"\"\"Merge values from the list of attributes, and assign a new name. Returns a new\n",
        "        instance\"\"\"\n",
        "\n",
        "        instance = cls()\n",
        "        instance.name = new_name\n",
        "        for attr in attr_list:\n",
        "            instance.values.update(attr.values)\n",
        "\n",
        "        return instance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PBwmHvka-D0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Fact:\n",
        "    \"\"\"Fact extracted from a document\"\"\"\n",
        "    \n",
        "    # values of the 'модальность' property that make the fact eligible for the easy mode\n",
        "    # only\n",
        "    easymode_modality_values = [\n",
        "            'возможность',\n",
        "            'будущее',\n",
        "            'отрицание'\n",
        "        ]\n",
        "\n",
        "    # values of the 'сложность' property that make the fact eligible for the hard mode\n",
        "    # only\n",
        "    hardmode_difficulty_values = [\n",
        "            'повышенная'\n",
        "        ]\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the object (use Fact.fromStandard/Fact.fromTest instead)\"\"\"\n",
        "        self.tag = ''\n",
        "        self.id = ''\n",
        "        self.arguments = []\n",
        "        self.has_easymode_modality = False\n",
        "        self.has_hardmode_difficulty = False\n",
        "        self.is_ignored = False\n",
        "\n",
        "    def toTestString(self):\n",
        "        return '\\n'.join([self.tag]\n",
        "                         + [x.toTest() for x in self.arguments if not x.is_special]) + '\\n'\n",
        "\n",
        "    def toInlineString(self):\n",
        "        res = '[ ' + str(self.id) + ' '\n",
        "        if self.has_easymode_modality:\n",
        "            res += '(MODALITY) '\n",
        "        if self.has_hardmode_difficulty:\n",
        "            res += '(HARD) '\n",
        "        res += self.tag\n",
        "        for arg in self.arguments:\n",
        "            res += ' | {}'.format(arg)\n",
        "        res += ' ]'\n",
        "        return res\n",
        "\n",
        "    def _load_id_line(self, line):\n",
        "        \"\"\"Loads the first line of the fact description\"\"\"\n",
        "        parts = line.split(' ')\n",
        "        self.id = parts[0]\n",
        "        self.tag = parts[1].strip(' :\\n\\t\\r').lower()\n",
        "\n",
        "    def canMatch(self, other):\n",
        "        \"\"\"Determine if this fact can match the other in evaluation. In essense, returns\n",
        "        True only if at least one of the arguments has matching values\"\"\"\n",
        "\n",
        "        if self.tag != other.tag:\n",
        "            return False\n",
        "\n",
        "        for a in self.arguments:\n",
        "            for b in other.arguments:\n",
        "                if a.canMatch(b):\n",
        "                   if a.name=='position':\n",
        "                       continue\n",
        "                   return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def removePhase(self):\n",
        "        \"\"\"Remove phase argument, it one is present\"\"\"\n",
        "        phase_args = [a for a in self.arguments if a.name == 'фаза']\n",
        "        if len(phase_args) == 0:\n",
        "            return\n",
        "\n",
        "        # there should be no more than one phase per fact\n",
        "        assert(len(phase_args) == 1)\n",
        "        self.arguments.remove(phase_args[0])\n",
        "\n",
        "    def finalize(self):\n",
        "        \"\"\"Finalize the object for the evaluation\"\"\"\n",
        "        self._processModality()\n",
        "        self._processDifficulty()\n",
        "        for arg in self.arguments:\n",
        "            arg.finalize()\n",
        "\n",
        "    def _processModality(self):\n",
        "        modality_args = [a for a in self.arguments if a.name == 'модальность']\n",
        "        if len(modality_args) == 0:\n",
        "            self.has_easymode_modality = False\n",
        "            return\n",
        "\n",
        "        # Apparently there can be multiple modality values in the dataset\n",
        "        # And mutliple values per modality attribute\n",
        "        for modality in modality_args:\n",
        "            self.arguments.remove(modality)\n",
        "\n",
        "            assert(isinstance(modality.values[0], StringValue))\n",
        "            for value in modality.values:\n",
        "                self.has_easymode_modality = (\n",
        "                        self.has_easymode_modality\n",
        "                        or (value.descr in Fact.easymode_modality_values)\n",
        "                )\n",
        "\n",
        "    def _processDifficulty(self):\n",
        "        difficulty_args = [a for a in self.arguments if a.name == 'сложность']\n",
        "        if len(difficulty_args) == 0:\n",
        "            self.has_hardmode_difficulty = False\n",
        "            return\n",
        "\n",
        "        # there should be no more than one modality per fact\n",
        "        assert(len(difficulty_args) == 1)\n",
        "        difficulty = difficulty_args[0]\n",
        "        self.arguments.remove(difficulty)\n",
        "\n",
        "        assert(len(difficulty.values) == 1)\n",
        "\n",
        "        assert(isinstance(difficulty.values[0], StringValue))\n",
        "        value = difficulty.values[0].descr\n",
        "        self.has_hardmode_difficulty = value in Fact.hardmode_difficulty_values\n",
        "\n",
        "    def expandWithIsPartOf(self, facts):\n",
        "        if self.tag != 'occupation':\n",
        "            return\n",
        "\n",
        "        partof_dict = {}\n",
        "        for fact in facts:\n",
        "            for arg in fact.arguments:\n",
        "                for key in arg.values:\n",
        "                    assert(isinstance(key, EntityValue))\n",
        "                    for value in arg.values:\n",
        "                        if value == key:\n",
        "                            continue\n",
        "                        if not (key in partof_dict):\n",
        "                            partof_dict[key] = []\n",
        "                        partof_dict[key].append(value)\n",
        "\n",
        "        for arg in self.arguments:\n",
        "            if arg.name == 'where':\n",
        "                assert(len(arg.values) == 1)\n",
        "                assert(isinstance(arg.values[0], EntityValue))\n",
        "                arg.values[0].expandWithIsPartOf(partof_dict)\n",
        "\n",
        "    def __repr__(self):\n",
        "        res = self.tag + '\\n'\n",
        "        for arg in self.arguments:\n",
        "            res += str(arg) + '\\n'\n",
        "\n",
        "        return res\n",
        "\n",
        "    def __str__(self):\n",
        "        return repr(self)\n",
        "\n",
        "    # static build methods\n",
        "    @classmethod\n",
        "    def fromStandard(cls, text, entity_dict, span_dict):\n",
        "        \"\"\"\"\"\"\n",
        "        assert(len(text.strip('\\r\\n\\t ')) > 0)\n",
        "        lines = text.split('\\n')\n",
        "\n",
        "        builder = ArgumentBuilder(entity_dict, span_dict)\n",
        "\n",
        "        instance = cls()\n",
        "        for line in lines[1:]:\n",
        "            if len(line) == 0:\n",
        "                continue\n",
        "            arg = builder.build(line)\n",
        "            arg.fact = instance\n",
        "            instance.arguments.append(arg)\n",
        "\n",
        "        # instance.processAttributes()\n",
        "        instance._load_id_line(lines[0])\n",
        "        instance.finalize()\n",
        "\n",
        "        return instance\n",
        "\n",
        "    @classmethod\n",
        "    def fromTest(cls, text):\n",
        "        \"\"\"Load the entity from a test file using a different format:\n",
        "        \n",
        "        [fact_type]\n",
        "        [arg_name]:[arg_value]\n",
        "        ...\n",
        "        [arg_name]:[arg_value]\n",
        "        \"\"\"\n",
        "\n",
        "        assert(len(text.strip('\\r\\n\\t ')) > 0)\n",
        "\n",
        "        instance = cls()\n",
        "\n",
        "        lines = text.split('\\n')\n",
        "        instance.tag = lines[0].strip(' :\\n\\t\\r').lower()\n",
        "        lines = text.split('\\n')\n",
        "        for line in lines[1:]:\n",
        "            if len(line) == 0:\n",
        "                continue\n",
        "            arg = Argument.fromTest(line)\n",
        "            arg.fact = instance\n",
        "            instance.arguments.append(arg)\n",
        "\n",
        "        return instance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukM2eD9JbB1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ArgumentBuilder:\n",
        "    \"\"\"Creates an argument of a proper type from string\"\"\"\n",
        "\n",
        "    def __init__(self, entity_dict, span_dict):\n",
        "        self.entity_dict = entity_dict\n",
        "        self.span_dict = span_dict\n",
        "\n",
        "    def build(self, line):\n",
        "        parts = line.split(' ')\n",
        "        name = parts[0].lower()\n",
        "        alternatives = ' '.join(parts[1:]).split('|')\n",
        "        argument = Argument(name)\n",
        "\n",
        "        assert(len(alternatives)>0)\n",
        "\n",
        "        if parts[1].startswith('span'):\n",
        "            # spans have the following syntax:\n",
        "            # position spanXXXX somevalue | spanYYYY someothervalue\n",
        "            for alternative in alternatives:\n",
        "                parts = [x for x in alternative.split(' ') if x != '']\n",
        "                argument.values.append(\n",
        "                    SpanValue(argument, parts[0], ' '.join(parts[1:]), self.span_dict))\n",
        "        elif parts[1].startswith('obj'):\n",
        "            # objects have different syntax:\n",
        "            # who objXXX name1 | name2 | name3\n",
        "            # (all names refer to the same object)\n",
        "            argument.values.append(\n",
        "                EntityValue(parts[1], ' '.join(parts[2:]), self.entity_dict))\n",
        "        else:\n",
        "            # just a string value\n",
        "            for alternative in alternatives:\n",
        "                argument.values.append(StringValue(alternative))\n",
        "\n",
        "        return argument"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwawTT3pbL3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Argument:\n",
        "    \"\"\"Fact argument\"\"\"\n",
        "\n",
        "    # names of the special cyrillic attributes\n",
        "    special_names = ['сложность', 'модальность', 'фаза']\n",
        "\n",
        "    # normalized 'occupation:position' values dictionary\n",
        "    # loaded from a specific file\n",
        "    position_dict = None\n",
        "\n",
        "    def __init__(self, name):\n",
        "        \"\"\"Initialize\"\"\"\n",
        "        if Argument.position_dict == None:\n",
        "            Argument.loadPositionDict()\n",
        "\n",
        "        self.name = name.strip(' \\n\\r\\t').lower()\n",
        "        if self.name == 'job':\n",
        "            self.name = 'position'\n",
        "        self.is_special = self.name in Argument.special_names\n",
        "        self.values = []\n",
        "        self.fact = None\n",
        "\n",
        "    def toTest(self):\n",
        "        if(len(self.values) == 0):\n",
        "            print(self.fact)\n",
        "        return self.name + ' : ' + str(self.values[0])\n",
        "\n",
        "    def toInlineString(self):\n",
        "        return str(self.values[0])\n",
        "\n",
        "    def canMatch(self, other):\n",
        "        \"\"\"Check if the value of other is compatable with the arguments own values\"\"\"\n",
        "        assert(len(other.values) == 1) # other should be a test argument with only 1 value\n",
        "        if self.name != other.name:\n",
        "            return False\n",
        "\n",
        "        for x in self.values:\n",
        "            for y in other.values:\n",
        "                if x.equals(y):\n",
        "                    return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def finalize(self):\n",
        "        \"\"\"Finalize the argument for evaluation\"\"\"\n",
        "        for v in self.values:\n",
        "            v.finalize()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.name + ' : ' + ' | '.join([str(x) for x in self.values])\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.__repr__()\n",
        "\n",
        "    # classmethods\n",
        "\n",
        "    @classmethod\n",
        "    def loadPositionDict(cls):\n",
        "        \"\"\"Load the normalized 'occupation:position' values dictionary from the\n",
        "        associated file. This method should only be called once\"\"\"\n",
        "        cls.position_dict = {}\n",
        "        with open(jobs_file_path, encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                parts = [x.strip(' \\n\\r\\t') for x in line.split('|')]\n",
        "                assert(len(parts) == 2)\n",
        "                cls.position_dict[parts[0]] = parts[1]\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def fromTest(cls, line):\n",
        "        parts = line.split(':')\n",
        "        assert(len(parts) == 2)\n",
        "        arg = cls(parts[0])\n",
        "        arg.values.append(StringValue(parts[1]))\n",
        "\n",
        "        return arg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukKlOJehbUqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EntityValue:\n",
        "    \"\"\"Fact argument that is an entity\"\"\"\n",
        "\n",
        "    def __init__(self, full_id, descr, entity_dict):\n",
        "        \"\"\"Initialize the object\"\"\"\n",
        "        assert(full_id.startswith('obj'))\n",
        "        self.entity = entity_dict[full_id[3:]]\n",
        "        self.descr = descr.strip(' \\n\\r\\t').lower()\n",
        "        self.values = set([self.descr])\n",
        "\n",
        "        # special logic for different types of entities\n",
        "        assert( self.entity.tag != 'locorg' )\n",
        "        self.values = self.values.union(self._expandFromText())\n",
        "\n",
        "        if self.entity.tag == 'per':\n",
        "            self.values = self.values.union(self._expandPerson(self.entity))\n",
        "\n",
        "        if self.entity.tag in ['org', 'loc']:\n",
        "            self.values = self.values.union(self._expandWithDescr(self.entity))\n",
        "\n",
        "    def equals(self, other):\n",
        "        assert(isinstance(other, StringValue))\n",
        "        for val in self.values:\n",
        "            if compareStrings(val, other.value):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def finalize(self):\n",
        "        \"\"\"Finalize the value\"\"\"\n",
        "        self.values = [x.lower().strip(' \\n\\r\\t').replace('ё', 'е') for x in self.values]\n",
        "\n",
        "    def _expandFromText(self):\n",
        "        \"\"\"Returns a set of non-normalized values corresponding to each mention of the\n",
        "        entity\"\"\"\n",
        "        additional_values = []\n",
        "        for mention in self.entity.mentions:\n",
        "            additional_values.append(mention.text)\n",
        "            additional_values.append(mention.interval_text)\n",
        "        return set(additional_values)\n",
        "\n",
        "    def _expandPerson(self, per):\n",
        "        \"\"\"Create all possible values for a person\"\"\"\n",
        "        assert(per.tag == 'per')\n",
        "\n",
        "        firstnames = per.getAttr('firstname')\n",
        "        lastnames = per.getAttr('lastname')\n",
        "        patronymics = per.getAttr('patronymic')\n",
        "        nicknames = per.getAttr('nickname')\n",
        "\n",
        "        lists = [firstnames, lastnames, patronymics, nicknames]\n",
        "        combinations = ['lfp', 'fpl', 'fp', 'fl', 'lf', 'n', 'f', 'p', 'l', 'fn']\n",
        "            \n",
        "        values = []\n",
        "        for c in combinations:\n",
        "            values += self._buildPerValues(lists, c)\n",
        "        values.append(self.descr)\n",
        "        return set(values)\n",
        "\n",
        "    def _buildPerValues(self, lists, combination):\n",
        "        value_lists = []\n",
        "        for symbol in combination:\n",
        "            if symbol == 'f':\n",
        "                value_lists.append(lists[0])\n",
        "            elif symbol == 'l':\n",
        "                value_lists.append(lists[1])\n",
        "            elif symbol == 'p':\n",
        "                value_lists.append(lists[2])\n",
        "            elif symbol == 'n':\n",
        "                value_lists.append(lists[3])\n",
        "        return self._combine(value_lists)\n",
        "        \n",
        "    def _combine(self, value_lists):\n",
        "        options = ['']\n",
        "        new_options = []\n",
        "        for lst in value_lists:\n",
        "            for val in lst:\n",
        "                if val == '':\n",
        "                    continue\n",
        "                for opt in options:\n",
        "                    new_options.append(opt + ' ' + val if opt != '' else val)\n",
        "            options = new_options\n",
        "            new_options = []\n",
        "        return options\n",
        "\n",
        "    def _expandWithDescr(self, org):\n",
        "        \"\"\"Replace the value list with all possible organization/location names\"\"\"\n",
        "        assert(org.tag in ['org', 'loc'])\n",
        "        return set(org.getAttr('name'))\n",
        "        \n",
        "    def expandWithIsPartOf(self, ent_dict):\n",
        "        if not (self.entity in ent_dict):\n",
        "            return\n",
        "\n",
        "        for ent in ent_dict[self.entity]:\n",
        "            self.values = self.values.union(self._expandWithDescr(ent))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.descr\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.__repr__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWTNJ6bjbdx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SpanValue:\n",
        "    \"\"\"Fact argument that is a span\"\"\"\n",
        "\n",
        "    def __init__(self, owner, full_id, descr, span_dict):\n",
        "        \"\"\"Initialize the object\"\"\"\n",
        "        assert(full_id.startswith('span'))\n",
        "        self.owner = owner\n",
        "        self.span = span_dict[full_id[4:]]\n",
        "        self.values = [self.span.text]\n",
        "        self.descr = self.span.text\n",
        "\n",
        "    def equals(self, other):\n",
        "        for val in self.values:\n",
        "            if compareStrings(val, other.value):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def finalize(self):\n",
        "        \"\"\"Finalize the value\"\"\"\n",
        "        if self.owner.name == 'position':\n",
        "            if(self.values[0] in Argument.position_dict):\n",
        "                self.values.append(Argument.position_dict[self.values[0]])\n",
        "        self.values = [x.lower().strip(' \\n\\r\\t').replace('ё', 'е') for x in self.values]\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.descr\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.__repr__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eYNGqAobjCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StringValue:\n",
        "    \"\"\"String value for special cases\"\"\"\n",
        "\n",
        "    def __init__(self, value):\n",
        "        \"\"\"Initialie the object\"\"\"\n",
        "        self.value = value.strip(' \\n\\r\\t').lower()\n",
        "        self.descr = self.value\n",
        "\n",
        "    def equals(self, other):\n",
        "        # STUB\n",
        "        return compareStrings(self.value, other.value)\n",
        "\n",
        "    def finalize(self):\n",
        "        \"\"\"Finalize the value\"\"\"\n",
        "        self.value = self.value.lower().strip(' \\n\\r\\t').replace('ё', 'е')\n",
        "        # does nothing for now\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.descr\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.descr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUmeNsawQmSk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "35357a68-0855-44b5-b2fd-5f2f2b109dcc"
      },
      "source": [
        "is_locorg_allowed = False\n",
        "e = Evaluator(is_locorg_allowed)\n",
        "\n",
        "#-s /content/factRuEval-2016-master \n",
        "#-t /content/FactRuEval2016_results/results_of_elmo_and_crf2\n",
        "\n",
        "e.evaluate(std_path=\"/content/factRuEval-2016-master/testset\", test_path=\"/content/FactRuEval2016_results/results_of_elmo_and_crf\")"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Failed to load the standard of book_3954:\n",
            "Unknown mention tag: Facility\n",
            "Type    P        R        F1       TP1      TP2      In Std.  In Test.\n",
            "per        0.8598   0.9490   0.9022  1271.67  1271.67     1340     1479\n",
            "loc        0.7836   0.7498   0.7663   921.53   921.53     1229     1176\n",
            "org        0.5826   0.7477   0.6549  1176.93  1176.93     1574     2020\n",
            "overall    0.7209   0.8135   0.7644  3370.13  3370.13     4143     4675\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loc': <__main__.Metrics at 0x7f97c3ffb7f0>,\n",
              " 'org': <__main__.Metrics at 0x7f97c3ffbb70>,\n",
              " 'overall': <__main__.Metrics at 0x7f97c3fe8f28>,\n",
              " 'per': <__main__.Metrics at 0x7f97c3ffbac8>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAla0gCOR3jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python factRuEval-2016-master/scripts/t1_eval.py -t /content/FactRuEval2016_results/results_of_elmo_and_crf2 -s /content/factRuEval-2016-master/testset -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsW_Sd2QeWZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!zip -r /content/file.zip /content/FactRuEval2016_results"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}